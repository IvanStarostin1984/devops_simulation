# -*- coding: utf-8 -*-
"""openai19pm10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y8yjYrr1RQ2dCyFoEPMryscEZAzDJIWu
"""

# Place this near the very top of your Colab notebook (in a separate cell),
# so that *everything* printed afterwards will be captured.

import sys

class DualLogger:
    """
    A simple logger that prints console output normally
    AND writes the exact same output to a text file in the same order.
    """

    def __init__(self, file_path):
        # Keep track of Colab's original stdout so we can still see output in the notebook
        self.terminal = sys.stdout
        # Open your desired output file (overwrite mode). If you prefer appending, use "a".
        self.log_file = open(file_path, "w", encoding="utf-8")

    def write(self, message):
        # Write to the normal console
        self.terminal.write(message)
        # Also write to the file
        self.log_file.write(message)

    def flush(self):
        # Make sure both the terminal and the file are updated in real time
        self.terminal.flush()
        self.log_file.flush()

# Set sys.stdout to an instance of our DualLogger
sys.stdout = DualLogger("colab_console_output.txt")

# From here on, all print statements and any other stdout output will be logged
print("Hello! This line will go both to the notebook output AND to colab_console_output.txt")

# ====================================================================
#  SINGLE-CELL DEVOPS SIMULATION - WITH PHASES + MINI-ITERATIONS
# ====================================================================

# =========================================
# GLOBAL DEBUG FLAG TO CONTROL VERBOSITY
# =========================================
DEBUG_MODE = True  # Set True for very detailed LLM prompt/response prints, False to suppress

# =========================
# A) Environment Setup
# =========================
!pip install -q python-docx            # quieter output
!pip install -qU "openai>=1.77"        # v1.77.0 (2025-05-02) or newer
!pip install -qU nltk

import csv
import datetime
import time
import openai
from docx import Document
import json
import os
import uuid
from google.colab import files
from collections import OrderedDict
from collections import defaultdict
from collections import Counter
import numpy as np
import pandas as pd
import builtins
from typing import Dict, Any, Tuple
from openai import OpenAI, APIError, APIConnectionError, APIStatusError
import sys
import math, textwrap
from google.colab import userdata


# NLTK-specific setup
# ────────────────────────────────────────────────────────────────────
#  NLTK SETUP – bullet-proof for Colab (May 2025 JSON-model era)
# ────────────────────────────────────────────────────────────────────
import nltk, pathlib, sys

print("NLTK version:", nltk.__version__)

def ensure_nltk_resources() -> None:
    """Idempotent bootstrap for Colab:
       • 'punkt' + *JSON* 'averaged_perceptron_tagger_eng' downloaded if missing
       • phantom 'punkt_tab' transparently maps to 'punkt'
       • legacy english/ dir with 4 placeholder files is always present
    """
    # 1️⃣ alias 'punkt_tab' → 'punkt' for download & find
    _dl0, _find0 = nltk.download, nltk.data.find
    nltk.download = lambda pkg, *a, **k: _dl0("punkt" if pkg == "punkt_tab" else pkg, *a, **k)
    nltk.data.find = lambda name, *a, **k: _find0(
        name.replace("punkt_tab", "punkt", 1) if name.startswith("tokenizers/punkt_tab") else name,
        *a, **k)

    # 2️⃣ writable dir
    dl_dir = pathlib.Path("/root/nltk_data")
    dl_dir.mkdir(parents=True, exist_ok=True)

    # 3️⃣ download corpora if missing
    for path, pkg in (
        ("tokenizers/punkt", "punkt"),
        ("taggers/averaged_perceptron_tagger_eng", "averaged_perceptron_tagger_eng"),
    ):
        try:
            nltk.data.find(path)
        except LookupError:
            print(f"✏️  Downloading '{pkg}' …", file=sys.stderr)
            nltk.download(pkg, download_dir=str(dl_dir), quiet=True, raise_on_error=True)

    # 4️⃣ legacy punkt/english layout – ensure directory & 4 files exist
    eng_dir = dl_dir / "tokenizers" / "punkt" / "english"
    eng_dir.mkdir(parents=True, exist_ok=True)
    for fname in (
        "abbrev_types.txt",
        "collocations.tab",
        "sent_starters.txt",
        "ortho_context.tab",
    ):
        (eng_dir / fname).touch(exist_ok=True)

    # 5️⃣ add dl_dir to search path once
    if str(dl_dir) not in nltk.data.path:
        nltk.data.path.append(str(dl_dir))

    # 6️⃣ final assert
    nltk.data.find("tokenizers/punkt/english")
    nltk.data.find("taggers/averaged_perceptron_tagger_eng")

# bootstrap once
ensure_nltk_resources()

from nltk.tokenize import word_tokenize
from nltk import pos_tag


DESC_KEYS = ("canonicalDesc", "lastDesc", "aliases")


def jaccard(a: str, b: str) -> float:
    """
    Very small Jaccard similarity on word sets (case-insensitive).
    Returns a value in [0, 1] (1 = identical).
    """
    A, B = set(a.lower().split()), set(b.lower().split())
    return len(A & B) / max(1, len(A | B))


# ──────────────────────────────────────────────────────────────
# Helper – keep an issue's alias ring in sync
# ──────────────────────────────────────────────────────────────
def update_alias_ring(issue_rec: dict, new_desc: str, *, max_aliases: int = 2):
    """
    Keep the three drift-protection fields of *issue_rec* in sync.

    ── Behaviour ──────────────────────────────────────────────────────────
    • **Canonical initialisation**
        – Sets `canonicalDesc` on the very first *non-blank* wording.
        – If a gap was born with an empty description, the field is filled
          later as soon as either `lastDesc` or a later `new_desc` becomes
          non-blank (“late init” guard).

    • **Drift detection**
        – When Jaccard(new_desc, old_desc) < 0.5 **and** `old_desc` is
          non-blank, the previous wording is pushed into `aliases`.
        – Aliases are de-duplicated and bounded to *max_aliases* (default 2).

    • **Current wording** is always written to
        `lastDesc`  (new model) *and* `shortDescription` (legacy).

    Parameters
    ----------
    issue_rec   : dict   – mutable gap record
    new_desc    : str    – reviewer’s fresh wording (already stripped)
    max_aliases : int    – size of the alias ring (default 2)
    """
    # ------------------------------------------------------------------ #
    # Normalise inputs                                                   #
    # ------------------------------------------------------------------ #
    new_desc = (new_desc or "").strip()
    old_desc = (issue_rec.get("lastDesc")
                or issue_rec.get("shortDescription")
                or "").strip()

    # ------------------------------------------------------------------ #
    # 0.  INITIALISE canonicalDesc                                       #
    # ------------------------------------------------------------------ #
    if new_desc and not issue_rec.get("canonicalDesc", "").strip():
        issue_rec["canonicalDesc"] = new_desc
    elif old_desc and not issue_rec.get("canonicalDesc", "").strip():
        # late initialisation (gap was created with blank first wording)
        issue_rec["canonicalDesc"] = old_desc

    # ------------------------------------------------------------------ #
    # 1.  DRIFT → push previous wording into aliases                     #
    # ------------------------------------------------------------------ #
    if old_desc and new_desc and jaccard(new_desc, old_desc) < 0.5:
        aliases = issue_rec.setdefault("aliases", [])
        if old_desc not in aliases:               # avoid duplicates
            aliases.append(old_desc)
        # keep only the last *max_aliases* non-blank items
        issue_rec["aliases"] = [a for a in aliases if a.strip()][-max_aliases:]

    # ------------------------------------------------------------------ #
    # 2.  UPDATE current wording everywhere                              #
    # ------------------------------------------------------------------ #
    issue_rec["lastDesc"]         = new_desc
    issue_rec["shortDescription"] = new_desc    # ← legacy back-compat

    # No return – *issue_rec* is updated in place.



# ──────────────────────────────────────────────────────────────
# Helper – build drift-proof description union
# ──────────────────────────────────────────────────────────────
def build_desc_union(issue_rec: dict) -> str:
    """
    Build the drift-proof description union:

        canonicalDesc  ∥  aliases[]  ∥  lastDesc

    • Drops blank / whitespace-only segments
    • Removes duplicates while preserving order
    • Prints the canonical wording unconditionally for audit purposes
      (stdout line:  canonical="<first-ever wording>")

    Returns
    -------
    str  – the union string joined by " || "
    """
    # ── gather & normalise parts ──────────────────────────────────────────
    canonical = issue_rec.get("canonicalDesc", "").strip()
    aliases   = [a.strip() for a in issue_rec.get("aliases", []) if a.strip()]
    last_desc = issue_rec.get("lastDesc",
                              issue_rec.get("shortDescription", "")).strip()

    parts = [canonical, *aliases, last_desc]
    parts = [p for p in parts if p]           # drop blanks

    # ── de-duplicate whilst keeping first occurrences ─────────────────────
    seen = set()
    ordered = []
    for p in parts:
        if p not in seen:
            seen.add(p)
            ordered.append(p)

    union = " || ".join(ordered)

    if issue_rec.get("canonicalDesc", "").strip():      # only when set
        print(f'canonical="{issue_rec["canonicalDesc"]}"')

    return union






# =========================
# B) Helper Classes & Objects
# =========================

class IssueTracker:
    _issued_gap_ids: set[str] = set()
    _MAX_RETRIES = 12
    def __init__(
        self,
        issue_first_seen_iteration,
        llm_client,
        feedback_storage,
        phase_index_map,
        devops_sim
    ):
        self.issue_first_seen_iteration = issue_first_seen_iteration
        self.llm_client = llm_client
        self.issue_last_update = {}
        self.feedback_storage = feedback_storage
        self.phase_index_map = phase_index_map
        self.devops_sim = devops_sim  # critical for global mini index usage
        # ---------------- NEW STORAGE ------------------------------------
        # For each (gapID, artifactIndex) we keep:
        #   0) first_seen  -> (macro, phase, mini) or None
        #   1) last_snapshot -> (status, impact, macro, phase, mini) or None
        #
        # Nothing else reads this dict except the summariser helper,
        # so we can initialise it empty and fill it lazily.
        self._gap_artifact_tracker: dict[
            tuple[str, str],         # (gapID, artifactIndex)
            tuple[tuple | None, tuple | None]  # (first_seen, last_snapshot)
        ] = {}
        # -----------------------------------------------------------------
        # ------------- NEW: back-fill legacy blanks ------------------
        for gap in self.issue_first_seen_iteration.values():
            if isinstance(gap, dict) and not gap.get("canonicalDesc") and gap.get("lastDesc"):
                gap["canonicalDesc"] = gap["lastDesc"]
        # -------------------------------------------------------------

    @staticmethod
    def generate_unique_gap_id() -> str:
        """
        Return a 6‑hex‑digit ID that is guaranteed not to repeat within
        the current Python process.  Call sites remain unchanged.
        """
        import uuid, random

        # (1)  try up to _MAX_RETRIES random short UUID slices
        for _ in range(IssueTracker._MAX_RETRIES):
            cand = uuid.uuid4().hex[:6]
            if cand not in IssueTracker._issued_gap_ids:
                IssueTracker._issued_gap_ids.add(cand)
                return cand

        # (2)  extremely unlikely: still colliding after all retries
        #      → append two random hex chars (still “smallish”)
        while True:
            cand = uuid.uuid4().hex[:6] + random.choice("0123456789abcdef") * 2
            if cand not in IssueTracker._issued_gap_ids:
                IssueTracker._issued_gap_ids.add(cand)
                return cand

    @staticmethod
    def worse_impact(impact_a, impact_b):
        priority = {"Critical": 4, "High": 3, "Medium": 2, "Low": 1}
        return impact_a if priority[impact_a] >= priority[impact_b] else impact_b




    @staticmethod
    def merge_known_status(stat_a, stat_b):
        valid_statuses = {"NewIssue", "KnownIssue", "InProgress", "Resolved"}
        ranking = {"Resolved": 4, "InProgress": 3, "KnownIssue": 2, "NewIssue": 1}

        # Fallback if an invalid status (like "Critical" or "High") sneaks in
        if stat_a not in valid_statuses:
            print(f"WARNING: Unexpected status '{stat_a}' – defaulting to 'NewIssue'")
            stat_a = "NewIssue"
        if stat_b not in valid_statuses:
            print(f"WARNING: Unexpected status '{stat_b}' – defaulting to 'NewIssue'")
            stat_b = "NewIssue"

        # If both are identical, just return that status
        if stat_a == stat_b:
            return stat_a

        # If one is "Resolved" and the other is open, pick "InProgress" for partial resolution
        resolved_open_states = {"NewIssue", "KnownIssue", "InProgress"}
        if (stat_a == "Resolved" and stat_b in resolved_open_states):
            return "InProgress"
        if (stat_b == "Resolved" and stat_a in resolved_open_states):
            return "InProgress"

        # Otherwise, pick the status with the higher ranking
        return stat_a if ranking[stat_a] >= ranking[stat_b] else stat_b




    @staticmethod
    def add_issue_history(issue, field_name, old_value, new_value, reason=""):
        if "history" not in issue:
            issue["history"] = []
        issue["history"].append({
            "timestamp": datetime.datetime.now().isoformat(),
            "field": field_name,
            "old": old_value,
            "new": new_value,
            "reason": reason
        })

    _VALID_IMPACTS     = {"Critical", "High", "Medium", "Low"}
    _VALID_KNOWN       = {"NewIssue", "KnownIssue", "InProgress"}

    @staticmethod
    def _clean_impact(v: str | None) -> str:
         v = (v or "Medium").strip().title()
         return v if v in IssueTracker._VALID_IMPACTS else "Medium"

    @staticmethod
    def _clean_known(v: str | None) -> str:
         v = (v or "NewIssue").strip()
         return v if v in IssueTracker._VALID_KNOWN else "NewIssue"

    # ─────────────────────────────────────────────────────────────
    #  Minimal slice of *currently-open* issues
    #  • Includes extra context (canonicalDesc / lastDesc / aliases)
    #    so early-seeding records can still be matched reliably
    #  • Keeps legacy keys for downstream CSV compatibility
    # ─────────────────────────────────────────────────────────────
    def get_open_issues_minimal(self):
        """
        Return a compact list of records for prompts that only need
        basic information about *open* issues.

        Field policy
        ------------
        gapID, gapType, impact ..... unchanged
        shortDescription ............ pulled from **lastDesc** (fallback
                                      to legacy shortDescription if the record
                                      predates the migration)
        canonicalDesc, lastDesc,
        aliases ..................... NEW — supplies full match context
        recommendation .............. unchanged
        affectedArtifacts ........... always JSON-safe list (never a set)
        """
        results = []

        for gap_id, record in self.issue_first_seen_iteration.items():
            # skip non-dict legacy/malformed entries
            if not isinstance(record, dict):
                continue

            # include only still-open gaps
            if record.get("status") not in {"NewIssue", "KnownIssue", "InProgress"}:
                continue

            # normalise artifact membership to a list so downstream JSON
            # serialisation never yields a Python set (which broke .add())
            arts = record.get(
                "affectedArtifacts",
                {record.get("targetArtifactIndex")}   # fallback for pre-migration records
            )
            if isinstance(arts, set):
                arts = list(arts)
            elif arts is None:
                arts = []

            # drift-resistant description fields
            short_desc      = record.get("lastDesc", record.get("shortDescription", ""))
            canonical_desc  = record.get("canonicalDesc", short_desc)
            last_desc       = record.get("lastDesc",   short_desc)
            aliases         = record.get("aliases", [])
            if isinstance(aliases, str):
                aliases = [aliases] if aliases.strip() else []

            results.append({
                "gapID": gap_id,
                "gapType": record.get(
                    "finalGapType",
                    record.get("initialGapType", "Other")
                ),
                "impact": record.get(
                    "finalSeverity",
                    record.get("initialSeverity", "Medium")
                ),
                "shortDescription": short_desc,
                "canonicalDesc":    canonical_desc,
                "lastDesc":         last_desc,
                "aliases":          aliases,
                "recommendation":   record.get("recommendation", ""),
                "affectedArtifacts": arts,
                "knownIssue":       record.get("status", "KnownIssue")
            })

        return results





    def gather_resolved_issues_for_reopen(self,
                                          macro_iter_idx: int,
                                          phase_name: str,
                                          mini_iter_idx: int):
        """
        Return resolved gaps that might legitimately re‑appear in the current
        (macro_iter_idx, phase_name, mini_iter_idx).

        Selection rule
        ──────────────
        • Always include a gap resolved in any *earlier* macro/phase/mini
          → self._iteration_is_before() covers that.

        • Additionally include a gap resolved *earlier in the same macro* **iff**
            – it was closed in a strictly earlier phase,  or
            – it was closed in the same phase but an earlier mini.

        • Never include a gap that was resolved in *this* exact iteration
          (same macro, phase, mini) – that would reopen immediately.

        The trimmed records are used only for semantic matching by the LLM
        (`find_existing_issue_in_list`), so we omit recommendation/history.
        """

        resolved_issues = []
        cur_phase_idx = self.phase_index_map.get(phase_name, -1)

        for gap_id, record in self.issue_first_seen_iteration.items():
            if not isinstance(record, dict):
                continue                    # legacy / malformed entry
            if record.get("status") != "Resolved":
                continue

            resolved_iter_tuple = record.get("resolvedIn")
            if not resolved_iter_tuple:
                continue

            r_macro, r_phase, r_mini = resolved_iter_tuple

            # ---------- eligibility check ----------------------------------
            eligible = False

            # 1) globally earlier ⇒ always eligible
            if self._iteration_is_before((r_macro, r_phase, r_mini),
                                         (macro_iter_idx, phase_name, mini_iter_idx)):
                eligible = True
            else:
                # 2) same macro but earlier phase / mini
                if r_macro == macro_iter_idx:
                    r_phase_idx = self.phase_index_map.get(r_phase, -1)
                    if r_phase_idx < cur_phase_idx:
                        eligible = True
                    elif (r_phase == phase_name) and (r_mini < mini_iter_idx):
                        eligible = True
            # ----------------------------------------------------------------

            if not eligible:
                continue

            resolved_issues.append({
                "gapID":          gap_id,
                "gapType":        record.get("finalGapType",
                                             record.get("initialGapType", "Other")),
                "shortDescription": record.get("shortDescription", ""),
                "impact":         record.get("finalSeverity",
                                             record.get("initialSeverity", "Medium")),
                "knownIssue":     "Resolved",      # flag for the matcher
                "recommendation": ""
            })

        return resolved_issues


    def reopen_resolved_gap(
        self,
        matched_gap_id: str,
        new_issue_candidate: dict,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int
    ) -> dict | None:
        """
        Re-open a previously resolved gap so all activity stays under the
        original gapID.

        • Clears  resolvedIn / resolvedInGlobalMini
        • Resets   status  → "KnownIssue"
        • Updates  lastSeen / lastSeenGlobalMini  to the current iteration
        • Escalates (or downgrades) severity when incoming data is richer
        • Adds bookkeeping so invariants see the re-open
        • Returns the updated master record (or None on error)
        """
        # ── locate master record ──────────────────────────────────────────
        master_rec = self.issue_first_seen_iteration.get(matched_gap_id)
        if not isinstance(master_rec, dict):
            print(f"WARNING: Can't reopen gapID={matched_gap_id} – master record missing.")
            return None
        master_rec["gapID"] = matched_gap_id
        # Preserve routing: keep / add the artifact this gap belongs to
        # Preserve routing: merge artifact set
        new_set = set()
        if "affectedArtifacts" in new_issue_candidate:
            new_set.update(new_issue_candidate["affectedArtifacts"])
        elif new_issue_candidate.get("targetArtifactIndex"):
            new_set.add(new_issue_candidate["targetArtifactIndex"])

        if new_set:
            arts = master_rec.setdefault("affectedArtifacts", set())
            if isinstance(arts, list):
                arts = set(arts)
            arts.update(new_set)
            master_rec["affectedArtifacts"] = arts
        # ── 1) clear prior resolution fields ─────────────────────────────
        master_rec["resolvedIn"] = None
        master_rec["resolvedInGlobalMini"] = None

        # ── 2) mark as open again ────────────────────────────────────────
        master_rec["status"] = "KnownIssue"
        master_rec["knownIssue"] = "KnownIssue"
        master_rec["recurrenceCount"] = master_rec.get("recurrenceCount", 1) + 1

        # ── 3) update last-seen pointers ─────────────────────────────────
        master_rec["lastSeen"] = (macro_iter_idx, phase_name, mini_iter_idx)

        total_minis_per_macro = sum(
            ph.get("miniIterations", 1)
            for ph in self.devops_sim.sim_config.get("phases", [])
        )
        global_mini = (
            (macro_iter_idx - 1) * total_minis_per_macro +
            self.devops_sim.get_global_mini_index(phase_name, mini_iter_idx)
        )
        master_rec["lastSeenGlobalMini"] = global_mini

        # sync helper cache
        self.issue_last_update[matched_gap_id] = (macro_iter_idx, phase_name, mini_iter_idx)

        # ── 4) adjust severity (escalate or downgrade) / enrich description ──
        old_sev = (master_rec.get("finalSeverity") or
                  master_rec.get("initialSeverity", "Medium")).title()
        inc_sev = (new_issue_candidate.get("impact", "Medium") or "Medium").title()
        worse_sev = self.worse_impact(old_sev, inc_sev)

        if worse_sev != old_sev:                      # escalation
            self.add_issue_history(
                master_rec, "finalSeverity", old_sev, worse_sev,
                reason="Escalated severity upon reopening"
            )
            master_rec["finalSeverity"] = worse_sev
        elif inc_sev != old_sev:                      # downgrade
            self.add_issue_history(
                master_rec, "finalSeverity", old_sev, inc_sev,
                reason="Downgraded severity on reopen"
            )
            master_rec["finalSeverity"] = inc_sev
        # (no-change branch leaves finalSeverity as-is)

        # ➊ keep tracker-visible field in sync with final severity
        master_rec["impact"] = master_rec["finalSeverity"]

        # optionally enrich description / aliases
        new_desc = new_issue_candidate.get("shortDescription", "").strip()
        update_alias_ring(master_rec, new_desc)

        # ── 5) log the reopen itself ─────────────────────────────────────
        self.add_issue_history(
            master_rec, "status", "Resolved", "KnownIssue",
            reason="Re-opened; clearing previous resolution"
        )

        # ── 6) invariant bookkeeping (ID-1 / ID-2) ───────────────────────
        sim = self.devops_sim

        sim._carryover_open_ids.add(matched_gap_id)
        gtype = master_rec.get("finalGapType",
                              master_rec.get("initialGapType", "Other"))
        sim._carryover_by_type.setdefault(gtype, set()).add(matched_gap_id)
        sim.reopened_ids_per_macro.setdefault(macro_iter_idx, set()).add(matched_gap_id)

        return master_rec






    def get_first_seen_iteration(self, gap_id, default=None):
        """
        Retrieve the (macro_iter, phase_name, mini_iter) where this issue was first seen.
        Supports both new dict-based records (with 'firstSeen') and any older tuple-based records.
        Returns `default` if no record is found.
        """
        rec = self.issue_first_seen_iteration.get(gap_id)
        if rec is None:
            return default
        if isinstance(rec, dict):
            # New format -> rec['firstSeen'] is the triple (macro, phase, mini)
            return rec.get("firstSeen", default)
        elif isinstance(rec, tuple):
            # Old/legacy format -> entire record is a 3-tuple
            return rec
        else:
            # Unexpected format, just return default
            return default


    def _iteration_is_before(self, iterA, iterB):
        """
        Compare (macroA, phaseA, miniA) < (macroB, phaseB, miniB)
        using numeric phase indexing. Return True if A is strictly before B.
        """
        (macroA, phaseA, miniA) = iterA
        (macroB, phaseB, miniB) = iterB

        if macroA < macroB:
            return True
        elif macroA > macroB:
            return False

        # same macro => compare phase index
        idxA = self.phase_index_map.get(phaseA, -1)
        idxB = self.phase_index_map.get(phaseB, -1)

        if idxA < idxB:
            return True
        elif idxA > idxB:
            return False

        # same macro & same phase => compare mini
        return (miniA < miniB)


    def _track_issue_event(
            self,
            gap_id: str,
            artifact_index: str,
            status: str,
            impact: str,
            macro: int,
            phase: str,
            mini: int
    ) -> None:
        """Record the latest (status/impact) snapshot for a <gapID, artifactIndex> pair."""
        if not gap_id:
            return

        key = (gap_id, artifact_index)

        # ── decide the first-seen iteration (never overwritten) ─────────────
        first_seen, _ = self.devops_sim._gap_artifact_tracker.get(key, (None, None))
        if first_seen is None:
            first_seen = (macro, phase, mini)

        snapshot = (status, impact, macro, phase, mini)

        # ── update BOTH trackers so all call-sites stay happy ───────────────
        self._gap_artifact_tracker[key] = (first_seen, snapshot)
        self.devops_sim._gap_artifact_tracker[key] = (first_seen, snapshot)


    def deduplicate_issues_for_mini_iteration(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        artifact_index: str,
        new_issues_list: list
    ) -> tuple:
        """
        Deduplicate *new_issues_list* against
        1) every still-open issue from previous iterations (``merged_dict``)
        2) the pool of previously resolved issues that may legitimately re-open

        Returns
        -------
        (final_issues: list[dict], newly_created_ids: list[str])

        The implementation is fully updated for the
        *canonical + bounded-alias* drift-protection model:

          • every similarity path (embeddings + GPT) receives the 4-part
            union  canonicalDesc ∥ aliases ∥ lastDesc
          • legacy ``allDescriptions`` is **never** used for matching
          • write paths still maintain it for back-compat
        """

        # ----------------------------------------------------------
        # 0) Global-mini index bookkeeping
        # ----------------------------------------------------------
        local_gmini = self.devops_sim.get_global_mini_index(phase_name, mini_iter_idx)
        total_minis_per_macro = sum(ph.get("miniIterations", 1)
                                    for ph in self.devops_sim.sim_config["phases"])
        gmini_current = (macro_iter_idx - 1) * total_minis_per_macro + local_gmini

        # ----------------------------------------------------------
        # 1) Collect *open* issues up to now → merged_dict
        # ----------------------------------------------------------
        old_open_issues: list[dict] = []

        # 1a) earlier iterations
        for gap_id, (old_macro, old_phase, old_mini) in self.issue_last_update.items():
            if self._iteration_is_before((old_macro, old_phase, old_mini),
                                         (macro_iter_idx, phase_name, mini_iter_idx)):
                prev_issues_dict = (
                    self.feedback_storage
                        .get(old_macro, {})
                        .get(old_phase, {})
                        .get(old_mini, {})
                )
                for prev_art, prev_issues in prev_issues_dict.items():
                    for iss in prev_issues:
                        if (
                            iss.get("gapID") == gap_id
                            and iss.get("knownIssue") in {"NewIssue", "KnownIssue", "InProgress"}
                        ):
                            old_open_issues.append(iss)
                            break

        # 1b) issues already collected in this mini (any artifacts)
        current_phase_issues = (
            self.feedback_storage
                .setdefault(macro_iter_idx, {})
                .setdefault(phase_name, {})
                .setdefault(mini_iter_idx, {})
        )
        added_gaps: set[str] = {iss["gapID"] for iss in old_open_issues}

        for issues_in_this_mini in current_phase_issues.values():
            for iss in issues_in_this_mini:                        # pull **every** still-open gap
                if iss.get("knownIssue") not in {"NewIssue", "KnownIssue", "InProgress"}:
                    continue                                       # skip already-resolved ones
                gid = iss.get("gapID")
                if gid and gid not in added_gaps:
                    old_open_issues.append(iss)
                    added_gaps.add(gid)

        merged_dict: dict[str, dict] = {iss["gapID"]: iss for iss in old_open_issues}

        # hot-fix: pull in every globally open gap that might not be in merged_dict yet
        # EARLY global-pool seed – ensures the first artifact of a run
        # sees *all* still-open gaps before any matching occurs
        for stale in self.get_open_issues_minimal():
            if stale.get("knownIssue") not in {"NewIssue", "KnownIssue", "InProgress"}:
                continue                                     # ignore already-resolved gaps
            arts_raw = stale.get(
                "affectedArtifacts",
                {stale.get("targetArtifactIndex")}
            )
            stale["affectedArtifacts"] = (
                set(arts_raw) if isinstance(arts_raw, (list, set)) else {arts_raw}
            )
            # ensure minimal records hold the full description union
            if "canonicalDesc" not in stale:
                stale["canonicalDesc"] = stale.get("shortDescription", "")
            stale.setdefault("aliases", [])
            merged_dict.setdefault(stale["gapID"], stale)

        # ----------------------------------------------------------
        # 2) Candidate list of RESOLVED gaps that might reopen
        # ----------------------------------------------------------
        resolved_candidates_for_reopen = [
            ri
            for ri in self.gather_resolved_issues_for_reopen(
                macro_iter_idx, phase_name, mini_iter_idx
            )
        ]
        trimmed_resolved_list = []
        for ri in resolved_candidates_for_reopen:
            desc_union = build_desc_union(ri)
            trimmed_resolved_list.append({
                "gapID":            ri["gapID"],
                "gapType":          ri.get("gapType", ""),
                "shortDescription": desc_union,
                "impact":           ri.get("impact", "Medium"),
                "knownIssue":       "Resolved",
                "recommendation":   ""
            })

        # ══════════════════════════════════════════════════════════
        # Embedding fast-path – build once for the whole mini
        #   (canonical ∥ aliases ∥ lastDesc)
        # ══════════════════════════════════════════════════════════
        SIM_THRESHOLD = 0.85
        open_pool_ids:   list[str] = []
        open_pool_texts: list[str] = []

        for gid, oiss in merged_dict.items():
            arts_raw = oiss.get("affectedArtifacts",
                                {oiss.get("targetArtifactIndex")})
            oiss["affectedArtifacts"] = (
                set(arts_raw) if isinstance(arts_raw, (list, set)) else {arts_raw}
            )

            texts = [
                oiss.get("canonicalDesc", ""),
                oiss.get("lastDesc", oiss.get("shortDescription", ""))
            ] + oiss.get("aliases", [])
            for t in texts:
                if t:
                    open_pool_ids.append(gid)
                    open_pool_texts.append(t)

        open_pool_vecs = (
            self.llm_client.embed_many(open_pool_texts) if open_pool_texts else []
        )

        import numpy as _np
        def _cos(a, b):
            return float(_np.dot(a, b) /
                         (_np.linalg.norm(a) * _np.linalg.norm(b) + 1e-9))

        # ----------------------------------------------------------
        # 3) Single-pass over *new* issues
        # ----------------------------------------------------------
        newly_created_ids: list[str] = []
        valid_statuses = {"NewIssue", "KnownIssue", "InProgress", "Resolved"}

        for new_issue in new_issues_list:
            raw_status = new_issue.get("knownIssue", "NewIssue")
            if raw_status not in valid_statuses:
                raw_status = "NewIssue"

            candidate = {
                "gapType":          new_issue.get("gapType", "Other"),
                "shortDescription": new_issue.get("shortDescription", "").strip(),
                "impact":           self._clean_impact(new_issue.get("impact")),
                "recommendation":   new_issue.get("recommendation", "").strip(),
                "knownIssue":       self._clean_known(raw_status),
            }
            candidate["affectedArtifacts"] = {artifact_index}
            # ---------- 3a · embedding fast-override ---------------
            match_id = "NEW"
            if open_pool_vecs and candidate["shortDescription"]:
                cand_vec = self.llm_client.embed_one(candidate["shortDescription"])
                sims = [_cos(cand_vec, v) for v in open_pool_vecs]
                best_i = int(_np.argmax(sims)) if sims else -1
                if best_i >= 0 and sims[best_i] >= SIM_THRESHOLD:
                    match_id = open_pool_ids[best_i]
                    if __debug__:
                        print(f"DEBUG: embed-override matched → {match_id} (sim={sims[best_i]:.3f})")

            # ---------- 3b · GPT fallback --------------------------
            if match_id == "NEW":
                trimmed_open_list = []
                for gap_id, open_iss in merged_dict.items():
                    desc_union = build_desc_union(open_iss)
                    trimmed_open_list.append({
                        "gapID":            gap_id,
                        "gapType":          open_iss.get("gapType", ""),
                        "shortDescription": desc_union,
                        "impact":           open_iss.get("impact", "Medium"),
                        "knownIssue":       open_iss.get("knownIssue", "NewIssue"),
                        "recommendation":   open_iss.get("recommendation", "")
                    })
                match_data = self.llm_client.find_existing_issue_in_list(
                    trimmed_open_list, candidate
                )
                match_id = match_data.get("matchResult", "NEW")

            # ---------- 3c · merge / reopen / create ---------------
            if match_id != "NEW" and match_id in merged_dict:
                existing_issue = merged_dict[match_id]
                # ensure the artifact set is present and up-to-date
                # normalise to a set, then add the current artifact
                arts_raw = existing_issue.get("affectedArtifacts", set())
                arts = set(arts_raw) if isinstance(arts_raw, (list, set)) else {arts_raw}
                arts.add(artifact_index)
                existing_issue["affectedArtifacts"] = arts


                # gapType
                if not existing_issue.get("gapType"):
                    existing_issue["gapType"] = candidate.get("gapType", "Other")

                # status
                old_status = existing_issue.get("knownIssue", "NewIssue")
                new_status = self.merge_known_status(old_status, candidate["knownIssue"])
                if new_status != old_status:
                    self.add_issue_history(
                        existing_issue, "knownIssue",
                        old_status, new_status,
                        reason="Merged from single-pass candidate"
                    )
                    existing_issue["knownIssue"] = new_status

                # impact — always fall back to Medium if the key was never set
                old_imp  = self._clean_impact(existing_issue.get("impact"))
                cand_imp = candidate["impact"]          # already clean from step 2
                worse    = self.worse_impact(old_imp, cand_imp)

                if "impact" not in existing_issue:        # initialise missing field
                    existing_issue["impact"] = old_imp

                if worse != old_imp:
                    self.add_issue_history(
                        existing_issue, "impact",
                        old_imp, worse,
                        reason="Escalated impact"
                    )
                    existing_issue["impact"] = worse

                    master_rec = self.issue_first_seen_iteration.get(match_id)
                    if master_rec:
                        master_rec["finalSeverity"] = worse
                elif cand_imp != old_imp:
                    # NEW: allow severity to improve when evidence is better
                    self.add_issue_history(
                        existing_issue, "impact",
                        old_imp, cand_imp,
                        reason="Downgraded impact (better evidence)"
                    )
                    existing_issue["impact"] = cand_imp

                    master_rec = self.issue_first_seen_iteration.get(match_id)
                    if master_rec:
                        master_rec["finalSeverity"] = cand_imp



                # descriptions
                existing_issue.setdefault("allDescriptions", [])
                desc = candidate["shortDescription"]
                if desc and desc not in existing_issue["allDescriptions"]:
                    existing_issue["allDescriptions"].append(desc)
                update_alias_ring(existing_issue, desc)

                # recommendations
                existing_issue.setdefault("allRecommendations", [])
                rec = candidate["recommendation"]
                if rec and rec not in existing_issue["allRecommendations"]:
                    existing_issue["allRecommendations"].append(rec)
                if len(rec) > len(existing_issue.get("recommendation", "")):
                    self.add_issue_history(existing_issue, "recommendation",
                                           existing_issue.get("recommendation", ""), rec,
                                           reason="Replacing recommendation with newer text")
                    existing_issue["recommendation"] = rec
                # --- NEW: update per-artifact timeline tracker -------------
                # --- NEW: update per-artifact timeline tracker -------------
                # minimal records pulled from get_open_issues_minimal()
                # may lack these fields → set safe defaults
                existing_issue.setdefault("knownIssue", "KnownIssue")
                existing_issue.setdefault("impact", "Medium")

                self._track_issue_event(
                    gap_id=existing_issue["gapID"],
                    artifact_index=artifact_index,
                    status=existing_issue["knownIssue"],
                    impact=existing_issue["impact"],
                    macro=macro_iter_idx,
                    phase=phase_name,
                    mini=mini_iter_idx,
                )

            else:
                # 3d · reopen resolved or create brand-new
                if match_id == "NEW":
                    match_data_2 = self.llm_client.find_existing_issue_in_list(
                        trimmed_resolved_list, candidate
                    )
                    match_id_2 = match_data_2.get("matchResult", "NEW")
                else:
                    match_id_2 = "NEW"

                if match_id_2 != "NEW":
                    reopened_issue_dict = self.reopen_resolved_gap(
                        matched_gap_id       = match_id_2,
                        new_issue_candidate  = candidate,
                        macro_iter_idx       = macro_iter_idx,
                        phase_name           = phase_name,
                        mini_iter_idx        = mini_iter_idx,
                    )
                    if reopened_issue_dict:
                        merged_dict[match_id_2] = reopened_issue_dict
                        arts = reopened_issue_dict.setdefault("affectedArtifacts", set())
                        if isinstance(arts, list):
                            arts = set(arts)
                        arts.add(artifact_index)
                        reopened_issue_dict["affectedArtifacts"] = arts
                        # --- NEW: update per-artifact timeline tracker ----------
                        self._track_issue_event(
                            gap_id=reopened_issue_dict["gapID"],
                            artifact_index=artifact_index,
                            status=reopened_issue_dict["knownIssue"],
                            impact=reopened_issue_dict["impact"],
                            macro=macro_iter_idx,
                            phase=phase_name,
                            mini=mini_iter_idx
                        )
                else:
                    # ---- brand-new gapID ----------------------------------
                    new_gap_id = self.generate_unique_gap_id()
                    print(f"[DEBUG] New GapID assigned immediately: {new_gap_id}")

                    desc2 = candidate.get("shortDescription", "").strip()
                    rec2  = candidate.get("recommendation", "").strip()

                    # skeleton record
                    new_issue_rec = {
                        "gapID":              new_gap_id,
                        "gapType":            candidate.get("gapType", "Other"),
                        "impact":             self._clean_impact(candidate.get("impact")),
                        "knownIssue":         candidate.get("knownIssue", "NewIssue"),
                        "recommendation":     rec2,
                        "history":            [],
                        "allDescriptions":    [],
                        "allRecommendations": [],
                    }
                    new_issue_rec["affectedArtifacts"] = {artifact_index}
                    # unified initialisation of description fields
                    update_alias_ring(new_issue_rec, desc2)
                    if desc2:
                        new_issue_rec["allDescriptions"].append(desc2)
                    if rec2:
                        new_issue_rec["allRecommendations"].append(rec2)

                    merged_dict[new_gap_id] = new_issue_rec

                    # ---- master record bookkeeping -----------------------
                    self.issue_first_seen_iteration[new_gap_id] = {
                        "firstSeen":            (macro_iter_idx, phase_name, mini_iter_idx),
                        "lastSeen":             (macro_iter_idx, phase_name, mini_iter_idx),
                        "initialGapType":       new_issue_rec["gapType"],
                        "finalGapType":         new_issue_rec["gapType"],
                        "initialSeverity":      new_issue_rec["impact"],
                        "finalSeverity":        new_issue_rec["impact"],
                        "status":               new_issue_rec["knownIssue"],
                        "inProgressFrom":       None,
                        "resolvedIn":           None,
                        "history":              [],
                        "firstSeenGlobalMini":  gmini_current,
                        "recurrenceCount":      1,
                        "resolvedInArtifacts":  set(),
                        "shortDescription":     desc2,
                        "recommendation":       rec2,
                    }

                    newly_created_ids.append(new_gap_id)
                    # --- NEW: update per-artifact timeline tracker -------------
                    self._track_issue_event(
                        gap_id=new_gap_id,
                        artifact_index=artifact_index,
                        status=new_issue_rec["knownIssue"],
                        impact=new_issue_rec["impact"],
                        macro=macro_iter_idx,
                        phase=phase_name,
                        mini=mini_iter_idx
                    )

        # ----------------------------------------------------------
        # 4) Persist back into feedback_storage
        #    (convert any Python sets → lists so JSON serialisation works)
        # ----------------------------------------------------------
        import copy
        final_issues = []
        for _iss in merged_dict.values():
            safe = copy.deepcopy(_iss)

            # guarantee mandatory keys so downstream counters never raise
            safe.setdefault("knownIssue", "KnownIssue")
            safe["impact"] = self._clean_impact(safe.get("impact"))

            arts = safe.get("affectedArtifacts")
            if isinstance(arts, set):
                # drop falsy sentinels (None, "", etc.) before sorting
                safe["affectedArtifacts"] = sorted(a for a in arts if a)

            final_issues.append(safe)

        self.feedback_storage \
            .setdefault(macro_iter_idx, {}) \
            .setdefault(phase_name, {}) \
            .setdefault(mini_iter_idx, {})[artifact_index] = final_issues

        # keep lastSeen pointers fresh for *still-open* issues
        for iss in final_issues:
            if iss.get("knownIssue") in {"NewIssue", "KnownIssue", "InProgress"}:
                self.issue_last_update[iss["gapID"]] = (
                    macro_iter_idx, phase_name, mini_iter_idx
                )
                master_rec = self.issue_first_seen_iteration.get(iss["gapID"], {})
                if isinstance(master_rec, dict):
                    master_rec["lastSeen"]           = (
                        macro_iter_idx, phase_name, mini_iter_idx
                    )
                    master_rec["lastSeenGlobalMini"] = gmini_current

        return final_issues, newly_created_ids






class MetricsCalculator:
    @staticmethod
    def calculate_lexical_density(text):
        words = word_tokenize(text)
        tagged = pos_tag(words)
        content_count = sum(1 for (w, pos) in tagged if pos.startswith(('NN', 'VB', 'JJ', 'RB')))
        total_count = len(words)
        if total_count == 0:
            return 0
        return round(content_count / total_count, 3)

    @staticmethod
    def calculate_unique_term_ratio(text):
        tokens = word_tokenize(text.lower())
        unique_tokens = set(tokens)
        total_count = len(tokens)
        if total_count == 0:
            return 0
        return round(len(unique_tokens) / total_count, 3)

    @staticmethod
    def measure_table_complexity(artifact_json):
        num_cols = len(artifact_json.get("columns", []))
        num_rows = len(artifact_json.get("rows", []))
        return num_cols * num_rows

    @staticmethod
    def measure_traceability_coverage(artifact_dict, req_column="Related Reqs"):
        columns = artifact_dict.get("columns", [])
        if req_column not in columns:
            return None
        coverage_count = 0
        rows = artifact_dict.get("rows", [])
        for row in rows:
            val = row.get(req_column, "")
            if isinstance(val, list):
                val = " ".join(str(x) for x in val)
            val = str(val).strip()
            if val:
                coverage_count += 1
        total = len(rows)
        if total == 0:
            return None
        return round((coverage_count / total)*100, 2)

    @staticmethod
    def diff_artifacts(old_art, new_art, key_col="Req ID"):
        old_rows_map = {}
        new_rows_map = {}
        if "rows" in old_art and "rows" in new_art:
            for r in old_art["rows"]:
                if key_col in r:
                    old_rows_map[r[key_col]] = r
            for r in new_art["rows"]:
                if key_col in r:
                    new_rows_map[r[key_col]] = r
        added = [rid for rid in new_rows_map if rid not in old_rows_map]
        removed = [rid for rid in old_rows_map if rid not in new_rows_map]
        changed = []
        for rid in new_rows_map:
            if rid in old_rows_map and old_rows_map[rid] != new_rows_map[rid]:
                changed.append(rid)
        return {"added": added, "removed": removed, "changed": changed}


class LLMClient:
    """Thin wrapper around the OpenAI v1.77 SDK with prompt-level cache."""

    def __init__(self):
        self.response_cache: OrderedDict[str, str] = OrderedDict()
        self._client: OpenAI | None = None   # instantiated lazily


    # ---------- internal helper ------------------------------------ #
    def _get_client(self) -> OpenAI:
        """Instantiate once, after `openai.api_key` has been set elsewhere."""
        if self._client is None:
            self._client = OpenAI()          # picks up openai.api_key
        return self._client

    # --------------------  Embeddings  ----------------------------- #
    def embed_one(self, text: str) -> np.ndarray:
        cli = self._get_client()
        resp = cli.embeddings.create(
            model="text-embedding-3-small",
            input=[text]
        )
        return np.asarray(resp.data[0].embedding, dtype=np.float32)

    def embed_many(self, texts: list[str]) -> list[np.ndarray]:
        cli = self._get_client()
        resp = cli.embeddings.create(
            model="text-embedding-3-small",
            input=texts
        )
        return [np.asarray(item.embedding, dtype=np.float32) for item in resp.data]

    # --------------------  Chat  ----------------------------------- #
    # --------------------  Chat  ----------------------------------- #
    def openai_cheap_api(self, prompt: str) -> str:
        # 1️⃣ cache lookup
        if prompt in self.response_cache:
            if DEBUG_MODE:
                print("DEBUG: Using cached response for identical prompt.")
            return self.response_cache[prompt]

        if DEBUG_MODE:
            print("**************************************************")
            print("DEBUG (LLMClient): Calling OpenAI with prompt:\n", prompt)

        try:
            cli = self._get_client()

            reply = None
            # --- Preferred path: Responses API (modern) ---
            try:
                # Base params shared across attempts
                _resp_params = {
                    "model": "gpt-5-mini",
                    "input": prompt,
                    "max_output_tokens": 16384,
                    "reasoning": {"effort": "low"},
                }
                # Best-effort: set verbosity via `text` (requires newer SDK)
                try:
                    resp = cli.responses.create(**{**_resp_params, "text": {"verbosity": "low"}})
                except TypeError as e_text:
                    if DEBUG_MODE:
                        print("DEBUG (LLMClient): 'text' param unsupported; retrying without verbosity. Details:", e_text)
                    resp = cli.responses.create(**_resp_params)

                # Prefer the convenience accessor if present
                reply = getattr(resp, "output_text", None)

                # Defensive parse of response body if needed
                if not reply:
                    parts = []
                    for item in getattr(resp, "output", []) or []:
                        if getattr(item, "type", None) == "message":
                            for c in getattr(item, "content", []) or []:
                                if getattr(c, "type", None) == "output_text":
                                    parts.append(getattr(c, "text", ""))
                    reply = "".join(parts) if parts else None

            except Exception as e_responses:
                # --- Compatibility fallback: Chat Completions ---
                if DEBUG_MODE:
                    print("DEBUG (LLMClient): Responses API failed; falling back to Chat Completions. Details:", e_responses)

                resp = cli.chat.completions.create(
                    model="gpt-5-mini",
                    messages=[{"role": "user", "content": prompt}],
                    # Reasoning models on Chat Completions require this param name
                    max_completion_tokens=16384,
                    # Reasoning control (flat, not nested)
                    reasoning_effort="low"
                )
                reply = resp.choices[0].message.content  # same accessor you used

            # 2️⃣ update cache (FIFO, max 10)
            reply = reply if reply is not None else ""
            self.response_cache[prompt] = reply
            if len(self.response_cache) > 10:
                self.response_cache.popitem(last=False)

            if DEBUG_MODE:
                print("DEBUG (LLMClient): GPT Response:\n", reply)

            return reply

        except openai.OpenAIError as e:
            print(f"OpenAI API call failed: {e}")
            return f"Error: OpenAI API call failed ({e})"
        except Exception as e:
            print(f"Error calling OpenAI API: {e}")
            return f"Error: OpenAI API call failed ({e})"






    def find_existing_issue_in_list(
            self,
            known_issues_list: list,
            new_issue: dict
    ) -> dict:
        """
        Decide whether *new_issue* is the same fundamental problem as one of the
        issues in *known_issues_list*.

        Returns
        -------
        {
          "matchResult": "NEW" | <gapID>,
          "explanation": "<≤5-word reason>"
        }

        If the LLM reply is malformed we fall back to
        {"matchResult": "NEW", "explanation": "Error parsing LLM output"}.
        """
        import json

        # ──────────────────────────────────────────────────────────────
        # 1) Prepare KNOWN issues (union built by the single helper)
        # ──────────────────────────────────────────────────────────────
        trimmed_known_issues = []
        for issue in known_issues_list:
            desc_union = build_desc_union(issue)          # ← canonical ∥ aliases ∥ lastDesc

            trimmed_known_issues.append({
                "gapID":            issue["gapID"],
                "gapType":          issue.get("gapType", "Other"),
                "shortDescription": desc_union,
                "impact":           issue.get("impact", "Medium"),
                "recommendation":   issue.get("recommendation", ""),
                "knownIssue":       issue.get("knownIssue", "NewIssue")
            })

        # ──────────────────────────────────────────────────────────────
        # 2) Prepare the NEW candidate
        #    – main union via helper
        #    – optionally append extra alt descriptions (allDescriptions)
        # ──────────────────────────────────────────────────────────────
        cand_union = build_desc_union(new_issue)

        alt = new_issue.get("allDescriptions", []) or []
        if isinstance(alt, str):
            alt = [alt]
        alt = [a.strip() for a in alt if a.strip()]

        # de-duplicate while preserving order
        parts = list(dict.fromkeys((cand_union.split(" || ") if cand_union else []) + alt))
        cand_desc_union = " || ".join([p for p in parts if p])

        filtered_new_issue = {
            "gapType":          new_issue.get("gapType", "Other"),
            "shortDescription": cand_desc_union,
            "impact":           new_issue.get("impact", "Medium"),
            "recommendation":   new_issue.get("recommendation", ""),
            "knownIssue":       new_issue.get("knownIssue", "NewIssue")
        }

        # ──────────────────────────────────────────────────────────────
        # 3) Build the GPT prompt
        # ──────────────────────────────────────────────────────────────
        valid_ids = [iss["gapID"] for iss in trimmed_known_issues]
        ids_str   = ", ".join(valid_ids)

        prompt = f"""
    You are analyzing software issues for possible duplication.

    Your task is to follow STEP 1: normalise known unique (open/resolved) issues, then STEP 2 – Match logic, and finally STEP 3 – output valid JSON.

    STEP 1 – Normalise
    • For *every* issue (known & candidate) create a temporary field called **coreProblem** by:
      – Removing any leading numbering denoting artifact indexes, such as “1.1.4.2 ” or “1.1.1 ” or "2.3.1".
      – Lower-casing.
      – Stripping duplicate whitespace.
      – Split `shortDescription` at “||”; treat each part as an alias and normalise separately.
      – If a **row OR column token** (e.g., “Row M-06”, “FR-12”, “FB-02”, “SLA column”) is present, **prepend it to coreProblem** so that different rows/columns are not merged.
      – Treat obvious synonyms, abbreviations, and word-form variants as equivalent (e.g., “p95” ≈ “95th percentile”; “encrypt”, “encryption”, “encrypted”).  Do not invent far-fetched matches: use only clear, context-relevant synonyms.

    STEP 2 – Match logic
      • Does the candidate contain a **row/column token**?
        – **Yes** →
            ▸ If an existing coreProblem **with the same token** matches → duplicate (row → row).
            ▸ **Else**, strip the token from **both** the candidate *and* all known coreProblems, then compare.
                · If one matches → **return that gapID** and treat as a *row-to-row merge* (locator should widen, usually to `Whole artifact`).
                · If none match, compare the stripped candidate with token-less coreProblems
                  (earlier *Whole-artifact* gaps) → if match, scope-narrowing refinement.
                · Otherwise `"NEW"`.
        – **No**  → ▸ If a known coreProblem **without** row/column token already matches → duplicate into that (Whole-artifact wins).
                          ▸ **Else**, strip row/column tokens from known issues and compare.
                            · If one matches → **return its gapID** and treat this as a *scope-widening refinement*.
                            · Otherwise return `"NEW"`.
    • If a duplicate is found under these rules, return the first matching gapID in list order; otherwise return `"NEW"`.

    STEP 3 – Output
    Return **only**
    {{
      "matchResult": "NEW" | "<gapID>",
      "explanation": "≤ 5 words reason"
    }}


    We have a set of known unique (open/resolved) issues:
    {json.dumps(trimmed_known_issues, indent=2)}

    Now we have 1 new candidate issue:
    {json.dumps(filtered_new_issue, indent=2)}

    EDGE CASES
    • If several gapIDs share the same coreProblem, choose the one whose gapType matches the candidate; if still tied, choose the earliest gapID.
    • Treat plural/singular as the same.
    • If row/column tokens differ **but coreProblem matches**, merge into the existing gapID and widen the locator (usually to `Whole artifact`). Otherwise `"NEW"`.
    • If one issue has a token and the other doesn’t:
        – Merge into the existing gap **regardless of which side has the token**
          (row → whole or whole → row keeps the **same gapID**);
        – If no matching coreProblem exists, return `"NEW"`.
    • Edge case summary: if row/column tokens differ **and** `coreProblem` differs → `"NEW"`; otherwise merge per previous rule.

    ──────────────────────── EXAMPLES ──────────────────────────

    1.  Same words, different order
    Known issue:  gapID "78592b"  → "mobile OS compatibility not verified"
    Candidate issue:  "Compatibility with mobile OS is unverified at v1.1.5"
    {{
      "matchResult": "78592b",
      "explanation": "Same mobile-OS gap"
    }}

    2.  Synonym & section noise
    Known issue:  gapID "d7c2a6"  → "data encryption not explicitly detailed"
    Candidate issue: "1.1.4.2 NFR-03 encrypt user data, details missing"
    {{
      "matchResult": "d7c2a6",
      "explanation": "Encryption detail missing"
    }}

    3.  Plural ↔ singular, substring match
    Known issue:  gapID "32db4f"  → "payment processing security control not detailed"
    Candidate issue: "WF-07 lacks security controls list for payments"
    {{
      "matchResult": "32db4f",
      "explanation": "Same payment control"
    }}

    4.  Alias after “||” handled
    Known issue:  gapID "24ba4a"  → "…success metrics not confirmed || …success metrics not confirmed"
    Candidate issue: "INP-06 success metrics remain unconfirmed"
    {{
      "matchResult": "24ba4a",
      "explanation": "Matches alias text"
    }}

    5.  Overlap but gapType tie-break
    Known issue-A: gapID "9b97a8", PerformanceGap → "response time exceeds 400 ms"
    Known issue-B: gapID "24ba4a", UsabilityGap   → "success metrics not confirmed"
    Candidate issue: PerformanceGap               → "p95 response-time still above target"
    {{
      "matchResult": "9b97a8",
      "explanation": "Matches perf gap"
    }}

    6.  Truly unrelated topic
    Known issue list has no “avatar upload” problems at all.
    Candidate issue: "User avatar upload fails intermittently"
    {{
      "matchResult": "NEW",
      "explanation": "Completely new gap"
    }}

    7.  Same text, different row
    Known issue: gapID "de3cfe" → "Row M-06 missing trace links"
    Candidate issue: "Row FB-02 missing trace links"
    {{
      "matchResult": "de3cfe",
      "explanation": "Same trace gap"
    }}

    8.  Whole-artifact precedes row
    Known issue: gapID "aa11bb" → "Whole artifact missing KPI column"
    Candidate issue: "Row I-07 missing KPI column"
    {{
      "matchResult": "aa11bb",
      "explanation": "Merge into whole"
    }}

    9.  Row precedes whole (no whole gap yet)
    Known issue: gapID "bb22cc" → "Row I-07 missing KPI column"
    Candidate issue: "Whole artifact missing KPI column"
    {{
      "matchResult": "bb22cc",
      "explanation": "Merge into row gap"
    }}
    ──────────────────────────────────────────────────

    Return ONLY valid JSON with:
    {{
      "matchResult": "NEW" or one of the valid gapIDs: {ids_str},
      "explanation": "≤ 5 words reason"
    }}

    Keep each issue’s explanation very brief, but specific (one short sentence, not more than 5 words).
    No extra text outside JSON, no triple backticks or code fencing.
    """

        # ──────────────────────────────────────────────────────────────
        # 4) LLM call + parsing
        # ──────────────────────────────────────────────────────────────
        raw_resp = self.openai_cheap_api(prompt).strip()
        try:
            data = json.loads(raw_resp)
        except json.JSONDecodeError:
            return {"matchResult": "NEW", "explanation": "Error parsing LLM output"}

        match       = data.get("matchResult", "NEW")
        explanation = data.get("explanation", "")

        # ──────────────────────────────────────────────────────────────
        # 5) Sanity-check match; retry once if needed
        # ──────────────────────────────────────────────────────────────
        if match not in ("NEW", *valid_ids):
            retry_prompt = prompt + f"\n\nNOTE: choose exactly one of: {ids_str}, or NEW."
            try:
                retry_data = json.loads(self.openai_cheap_api(retry_prompt).strip())
                match       = retry_data.get("matchResult", "NEW")
                explanation = retry_data.get("explanation", "")
            except json.JSONDecodeError:
                return {"matchResult": "NEW", "explanation": "Error parsing LLM output"}

            if match not in ("NEW", *valid_ids):
                return {"matchResult": "NEW", "explanation": "Invalid gapID returned"}

        return {"matchResult": match, "explanation": explanation}







    def get_json_artifact_with_retries(self, prompt, max_retries=3):
        for attempt in range(max_retries):
            raw_res = self.openai_cheap_api(prompt).strip()
            try:
                parsed = json.loads(raw_res)
                if "columns" in parsed and "rows" in parsed:
                    return parsed
            except:
                pass
            time.sleep(0.1)
        return {
            "artifactIndex": "ERROR",
            "artifactName": "Error Artifact",
            "columns": [],
            "rows": [],
            "metadata": {
                "error": "Could not parse valid JSON after retries",
                "rawResponse": raw_res
            }
        }

    def review_artifact_with_teacher_one_question_at_a_time(
        self,
        issue_tracker,
        macro_iter_idx: int,
        phase_name,
        mini_iter_idx: int,
        artifact_index: str,
        artifact_text: str,
        dependency_text: str,
        unresolved_prev_issues: list,
        artifact_review_questions: dict
    ) -> list:
        """
        1) We now incorporate `unresolved_prev_issues` in each question prompt, so the LLM sees them.
        2) Then we gather new issues, pass them to issue_tracker for deduplication.
        """
        import re
        import json
        global_open_issues = issue_tracker.get_open_issues_minimal()

        if len(global_open_issues) <= 30:
            # Override: teacher sees entire open backlog
            unresolved_prev_issues = global_open_issues


        raw_collected_issues = []
        questions = artifact_review_questions.get(artifact_index, [])

        # We'll convert unresolved_prev_issues to a short string, for the LLM
        short_prev_issues_str = json.dumps([
            {
                "gapID": iss["gapID"],
                "gapType": iss["gapType"],
                "impact": iss.get("impact","Medium"),
                "desc": iss["shortDescription"]
            }
            for iss in unresolved_prev_issues
        ], indent=2)

        # ------------------------------------------------------------------
        # Helper: list the artifacts that follow the current artifact
        #         inside the *same* phase (deterministic order).
        # ------------------------------------------------------------------
        def _phase_downstream_overview(phase_name: str, current_art_idx: str) -> str:
            """
            Returns a bullet-list (markdown) of all artifacts that have not yet
            been reviewed in this phase. If current_art_idx is not in the phase
            table-list we simply return the full list for robustness.
            """
            # ---------- new guard ---------- #
            if not (hasattr(self, "sim_config") and hasattr(self, "tables")):
                return "• (context unavailable)"

            phase_tbls = next(
                (ph["tableList"] for ph in self.sim_config["phases"]
                if ph["phaseName"] == phase_name),
                []
            )
            try:
                start = phase_tbls.index(current_art_idx) + 1
            except ValueError:
                start = 0  # artifact not in list → show all

            downstream_ids = phase_tbls[start:]

            bullets = []
            for aid in downstream_ids:
                meta = next((t for t in self.tables
                            if t["Artifact_index"] == aid), {})
                bullets.append(
                    f"• {aid} — {meta.get('Artifact_name', '?')} "
                    f"({meta.get('Artifact_columns', '?')})"
                )
            return "\n".join(bullets) if bullets else "• (none)"


        # Build once, reuse for every question in this artifact
        phase_overview_md = _phase_downstream_overview(phase_name, artifact_index)

        # ------------------------------------------------------------------
        # fetch artifact-specific custom instructions for reviewer
        # ------------------------------------------------------------------
        custom_instructions = next(
            (t.get("custom_instructions", "")
             for t in self.tables
             if t.get("Artifact_index") == artifact_index),
            ""
        )

        if phase_overview_md == "• (context unavailable)":
            print("INFO: Downstream artifact context missing; falling back")

        for q_text in questions:
            prompt = f"""
(<start of instruction block:>)
# Agent Reminders
 • Produce only valid JSON output in this turn.
 • Think step-by-step privately before outputting JSON.
 • Validate enum tokens & word-limits **before** you emit JSON.
 • Minimise false-positives and false-negatives — raise only **evidence‑backed** issues; for AOB/CPI, prefer **one** Low `cross‑artifact` cluster over silence when uncertain.
 • **Evidence‑first (non‑overridable):** Run Rule‑3 with **semantic match** and the KnownIssue **resolution check** **before** any bias or Zero‑issues guard. Treat a match as satisfied **only** when it shows **primitive‑level sufficiency** and is **owner‑tier anchored**; **generic/category words do not count** as semantically equivalent. If remediation is visible, **do not raise**.
 • **Bias precedence (AOB/CPI/ghost/phase‑end) — after evidence‑first:** When unsure **and** applicability is **explicitly** evidenced, raise **one** Low `cross‑artifact` **cluster‑summary** item; **do not** also fire Zero‑issues guard; otherwise skip.
 • **Zero‑issues guard (safe):** Run **only if** Bias‑precedence did **not** fire. Fire when (a) a trigger has **explicit positive applicability evidence**; (b) no in‑artifact primitive‑sufficient match exists; and (c) Rule‑1/Rule‑2 do not defer. Emit **at most one** Low cluster‑summary item — **returning an empty list is permitted**.
 • **Owner‑tier anchoring (mandatory):** Anchor to the **owning tier** (Renderer / API‑Service / Auth‑Session / Data/Logging / Datastore). **Columns and category labels are not owners.** If the precise target is unclear, recommend by **owner‑tier** and mark `cross‑artifact`.

# Role: You are a senior software-engineering reviewer of documentation.

# Objective: Assess the current artifact against the client specifications, other dependencies and unresolved issues, apply the ABSOLUTE RULES + REVIEW-TRIGGER CHECKLIST, and return exactly one valid JSON object ("questionText", "identifiedIssues").

# Banners:
 🚫 NEVER raise traceability gaps for artifacts 1.1.0-1.1.4.
 ⚠️ Defer **only when** Rule‑1’s **two‑step test conclusively passes**; otherwise apply `cross‑artifact` (see 🔒 Baseline Non‑Deferral).
 🚫 Rule-1 banner – **Defer only if** the missing content is explicitly scheduled **and** the upcoming artifact names a **precise owner**; otherwise **raise** as `cross‑artifact` (AOB/CPI are non‑deferrable).

 🔒 Baseline Non‑Deferral — Do NOT defer ownerless baselines (AOB/CPI/ghost‑dependency set) based on generic categories or catch‑all placeholders.
     Deferral requires a **precise owner** in the same phase: a **named** mechanism/owner/section that can actually host the primitive; **category labels** or broad domains do **not** count.


 🟧 CUSTOM-INSTR banner – Treat every bullet in **Artifact-specific custom instructions**
     (see Project-data block §6) as binding scope for *this* artifact.
     • If the Current Artifact breaks a mandatory custom instruction ⇒ raise a gap.
     • If a custom instruction merely “encourages” something and you are uncertain,
       apply Rule-5 (Evidence threshold): raise **only** when you have clear evidence
       it will harm coverage or compliance; otherwise defer.

 🔖 Definitions (shorthands used below)
 • **AOB (Always‑On Baselines):** CSRF for state‑changing requests **in authenticated, cookie‑backed browser flows**; **throttling for public/unauthenticated write endpoints**; rate‑limit/lockout/backoff on auth; cookie flags; session rotation + idle/absolute timeouts + fields (`createdAt`,`lastActivityAt`,`expiresAt`,`rotatedAt`); MFA method/secret/enrolment/recovery; RBAC model (Role/Permission/Assignment); output encoding for **rendered** user content; GDPR consent/DSAR/retention evidence; audit‑log minimums (`actorId`,`action`,`target`,`ts`,`tamper‑evidence pointer`);
   **session scheme invariant** (either persisted session records with lifecycle fields, or stateless tokens with explicit claims/TTL/rotation + cookie flags);
   **identifier hygiene** (do not password‑hash identifiers; **apply only when confidentiality/obfuscation and uniqueness are both explicitly required** — use deterministic encryption or a documented alias + lookup; **never infer uniqueness**); deterministic encryption or documented lookup for UNIQUE+encrypted; server‑side destructive‑action confirmation (`deletionNonce`+TTL).
   **Scope qualifiers:** apply **CSRF only to authenticated, cookie‑backed state‑changing browser requests**; apply **throttling only to public/unauthenticated write endpoints**; expect **output encoding only where user content is rendered**.
   **Qualifier handling rule (AOB/CPI):** When qualifier evidence (auth/audience/transport/destructive‑semantics/publicness) is **unclear**, do **not** suppress the primitive — **raise Low** as `cross‑artifact` for the missing primitive and state that context is unknown. **Suppress only** when there is **positive evidence** the qualifier does **not** apply.
   **Token‑transport qualifier (CSRF):** when endpoints use bearer tokens in `Authorization` header **and** no ambient cookies are sent, CSRF is **not required**; if transport is unknown, apply the Qualifier handling rule.   **State‑change evidence qualifier:** do **not** infer mutation from HTTP method alone; require explicit evidence of server‑state change; treat `GET`/`HEAD` as non‑mutating unless the spec explicitly contradicts.
   **Destructive‑action scope:** require `deletionNonce` only for destructive, irreversible, or high‑blast‑radius operations.
   **Privacy scope qualifier:** raise GDPR evidence only when personal data processing is in scope; if unclear, raise a `cross‑artifact` gap to document data categories and sources.
 • **Owner‑Tier Map (anchoring hint):** Renderers → output encoding; API/Service layer → CSRF, rate‑limit, destructive‑action confirmation; Auth/Session layer → cookie flags, rotation, timeouts, session scheme; Data/Logging layer → audit/consent schemas; Datastore → uniqueness/indexing/encryption trade‑offs.
 • **CPI (Capability‑Prerequisite Invariant):** when a capability is asserted anywhere (current artifact or dependency/spec), the enabling substrate must exist **in this phase** as **either** (a) persisted primitives/fields/schemas **or** (b) an explicit binding to an external authoritative system **with a documented mapping/owner**.
 • **Precise owner:** a named field/entity/section, not a generic column.

# ABSOLUTE RULES — obey these before anything else:
**When instructions conflict, apply ABSOLUTE RULES → Evidence‑first **(apply Generic≠specific and owner‑tier sufficiency before suppression)** → Bias precedence → global defaults.**

 0. **Rule-0 – Custom-instruction supremacy (local)**
    For this artifact only, instructions in the “Artifact-specific custom instructions”
    block carry the same weight as the Client Specification.
    • Obey them unless they conflict with legal/compliance constraints
      or a higher-level requirement.

 0.1 **Cross‑artifact exception (ownerless/global requirement)**
   Raise a gap when a requirement is in the spec/dependency and:
     • has **no precise owner** in remaining 🟧 Upcoming artifacts **in this phase**, **or**
     • its prerequisites must live in the **current artifact** (CPI).
   Treat AOB and instrumentation hooks as **ownerless** unless a downstream artifact in the **same phase** names a precise owner. Include the phrase `cross‑artifact` in the shortDescription to make scope explicit.

 1. **Rule-1 – No duplicate coverage, silent deferral (with invariants)**
   **Phase‑end clause:** When no upcoming artifacts remain in this phase or it is the **last mini‑iteration**, **do not defer** CPI/AOB/**ghost‑dependency** topics **or critical‑path `TBD`/`to be selected` decisions**; raise a gap if unresolved.
   **Two‑step deferral test (must pass conclusively):** Defer **only if** an upcoming artifact in this **phase** both (a) **can own** the topic and (b) names a **precise owner**. If either (a) or (b) is **not conclusively satisfied**, **do not defer** — **raise now** as `cross‑artifact` when locus is unclear. Can own requires the upcoming artifact to list the exact column/section that would hold the primitive and a named owner; category labels are insufficient.
   If the topic **will** be handled by any artifact listed in **Upcoming artifacts in this phase** → defer **only if** the upcoming artifact can actually **own** that topic type (matching abstraction level/column‑set). Otherwise, **do not defer**.
   **Exceptions (raise instead of deferring; non‑overridable):**
    • **CPI:** capability asserted in current artifact **or** dependency/spec ⇒ require its primitives/fields/protocols now; raise a gap naming both sides, locator anchored to current artifact.
    • **AOB:** never defer ownerless baseline items.
    • **Ghost‑dependency:** treat as ownerless unless an upcoming artifact **explicitly** names the defining artifact/owner; do **not** defer to generic categories.
    • **Baseline checklist (always‑on):** apply AOB whenever the artifact (a) owns relevant entities/flows or (b) references state‑changing endpoints/UI rendering — not only when a `Security/Compliance` column exists.
    • Matches Rule‑0.1 (ownerless/global requirement).
    • Typical cases: trace-columns, KPI tables, detailed metrics, test plans, or any content explicitly named in an upcoming artifact.
    • When you skip an issue under Rule-1, write **DEFERRED** in your internal checklist (do not output).
    • When Rule-1 applies, simply skip the issue. Do **not** list such issue in `identifiedIssues`
   _Note:_ “None”/empty **Upcoming** list means phase‑end; apply the phase‑end clause strictly.

 2. **Rule-2 – Early-artifact traceability freeze**
    • For artifacts 1.1.0 → 1.1.4 do **not** raise *any* traceability or upstream-ID gap.
       (Trace columns are intentionally absent until artifact 1.1.4.1 and later.)
    • Other gap types (spec mis-match, metric format, etc.) are still in scope.
    • **Post‑1.1.4 safeguard:** require **phase‑wide ID stability** — the same requirement ID keeps its meaning across artifacts; drift is a **CrossArtifactGap** under Trigger 7.
    • **Post‑1.1.4 mandatory sweep:** for any artifact ≥ 1.1.4.1, perform an **ID‑stability sweep** vs earlier artifacts and the NFR catalogue; if drift is found, raise under Trigger 7 using an allowed `gapType` (typically `MissedRequirement`) and include the phrase `cross‑artifact` in the shortDescription

 3. Rule-3 – Positive-evidence check
    • Before you record any gap or excess, actively search the *Custom-instructions block*, the Client Specification, all Dependency artifacts, and the Current Artifact **semantically** (synonyms/variants; not exact substrings), including indirect links across artifacts (e.g., FR → WF → US). Accept singular/plural, hyphenation, and tense variants.
    • If matching evidence is already inside the Current Artifact and is of adequate quality, **primitive‑level sufficiency**, detail, and is not conflicting ⇒ the requirement is satisfied → do NOT raise a gap.
    • If the evidence exists only in Dependencies (or another approved artifact) but the requirement should appear in the Current Artifact — this includes
      • requirements marked mandatory, and
      • requirements labelled optional in the Client Specification when they are already documented elsewhere — then the Current Artifact is missing expected content ⇒ you MUST raise a gap (e.g., “Missing mandatory column” or “Optional feature absent”).
    • Raise this gap **only if the missing or conflicting content is something the *Current Artifact* is expected to cover** (e.g., don’t flag functional-feature gaps inside a DevSecOps table).
    • You may skip the issue only when Rule-1 silent deferral and/or the Rule-2 traceability waiver explicitly applies.
    • Cite the supporting evidence line in your private chain-of-thought; do not output it.
    • Ignore incidental hits (unrelated words that merely match the search term) and continue searching.
    • **Context propagation:** When the artifact states a scope‑setting fact once (e.g., cookie sessions, personal data in scope), assume it applies to related rows unless locally contradicted; use it to set/clear qualifiers.
    • **Cross‑dependency affirmation (non‑overridable):** If a non‑conflicting dependency asserts a primitive with concrete mechanism/owner and the current artifact neither contradicts nor narrows it, treat as satisfied for FP‑avoidance unless the Current Artifact **must host** a CPI primitive.
    • **Generic phrases do not satisfy specific primitives** (**overrides semantic‑match suppression**; require a concrete mechanism/owner/parameter for satisfaction):
      – `input validation` ≠ output encoding for rendered content
      – `encryption at rest` ≠ password hashing; ≠ deterministic encryption for UNIQUE lookups
      – `RBAC` (unspecified) ≠ declared roles/permissions model
      – `security baseline` mention ≠ CSRF token/nonces for state‑changing requests
      – `session lifecycle`/cookie flags ≠ **idle** and **absolute** session timeouts
      – `rate limit` mention without thresholds/policy ≠ brute‑force/lockout/backoff control
    • **Qualifier handling (AOB/CPI):** When qualifier evidence is **unclear**, **do not suppress**; raise **Low** as `cross‑artifact` and state the uncertainty. **Suppress only** with positive evidence of non‑applicability.

 4. **Rule-4 – Duplicate-ID suppression** – *Each* `gapID` may appear **once only** in `identifiedIssues`; if the same underlying defect affects several loci, keep **one row** and set the broadest locator.
    • If evidence is not found ➜ omit the issue or create a new gapID (do **not** reuse).
    • Whole-vs-row convention:
      – If a **Whole-artifact** gap already exists **and** the problem now occurs *only* in a specific row/column ➜ **reuse the same gapID** **and update the locator** to that row/column (e.g. change `Whole artifact` → `I-07`).
      – If a **row/column** gap exists and you now find the issue affects the **entire artifact** ➜ **reuse the same gapID** but change the locator to `Whole artifact`.
      – **In both cases:** never create an additional gapID for the same underlying problem.

 5. **Rule-5 – Evidence threshold (anti-false-positive)**
    • Rule-5 works in addition to Rule-3; perform the substring evidence search first.
    • Raise a finding **only** when at least one of the following holds:
      – Direct mismatch with Client Specification.
      – Conflict with a non-conflicting dependency.
      – Failing check under the Review-Trigger list.
    • If evidence is borderline or speculative, *defer* the issue instead of raising it.
    • **Bias rebalancing (overrides global default):** In **Security, Compliance, Feasibility/Implementability**, treat *false negatives as worse*; it is acceptable to raise on widely‑accepted baselines even if not verbatim in the spec (see Cross‑cutting Baselines).
    • If a metric is partially specified yet still **interpretable** (clear unit or window present) and no spec conflict exists, **prefer skip or Low impact** over raising a formal gap.
    • When Trigger‑9 conditions are met for **decision** metrics, raise a KPI‑FORMAT gap regardless.
    • When a baseline primitive is **absent** from visible evidence, raise **at least Low** impact with a concrete locator or `cross‑artifact` if locus is unclear; do **not** skip due to qualifier uncertainty.
    • **Baseline checklist** (apply whenever the artifact **defines or references endpoints/flows or persistent data**, not only when a `Security/Compliance` column exists):
      CSRF for state‑changing requests; rate‑limit/lockout thresholds; cookie flags (HttpOnly/Secure/SameSite);
      session rotation plus idle/absolute timeouts; MFA lifecycle (enroll/reset/recovery); output encoding for rendered user content;
      **throttling for unauthenticated write endpoints**.

 6. **Rule-6 – Output hygiene**
    • The artifact must contain exactly one JSON object and **no** Markdown, code-fencing, or scratch-pad remnants.

 7. **Rule‑7 – Metric-KPI guard (evidence‑aware, must‑run)**
    • Apply this check **only** to **decision/target** metric fields.
    • A cell is a gap **only** if it lacks any or several elements: **statistic/threshold/unit/window and instrumentation owner**, while there was enough information in clientspecs and dependencies to present each element.
    • **Metric–type coherence:** flag as a gap when the **statistic type does not match the measure type** (e.g., percentile on Boolean outcomes; `success rate p99`).
    • If TBD / N/A / Not required/ etc. was used in metric field - that is ok, do not raise a gap, unless TBD / N/A / Not required/ etc. are incorrect.
    • For **vanity/trend** fields, treat KPI completeness as **advisory**; do not raise unless it contradicts the spec or blocks decisions or not actionable.
    • Accept equivalent phrasings for windows/units/statistics (e.g., monthly/weekly/rolling 30 d; %, ms; success rate/mean/p95). Do not accept incoherent combinations per previous bullet.
    • If invalid, fire the KPI-FORMAT trigger (see list) and raise a gap.
    • Instrumentation owner is mandatory for decision metrics; optional for vanity/trend unless explicitly required by spec.
    • **Observability/fitness:** reject **unmeasurable or behavior‑blended** KPIs.
      – Ban objectives like `Zero security breaches in 30 d` (replace with system SLO surrogates).
      – Split user behavior from system reliability (avoid “admin login success rate” as a system KPI).



#Empty cell policy
## Cell can not be completely empty. If column truly does not apply to this row/ column in general, but the spec makes it optional for this row/ spec/dependencies don’t give enough to set a value safely/ a required value is known to be needed but not yet decided  - cell must be populated by creator prompt with N/A/ Not required/ Insufficient data/ TBD.
## Failure to follow this policy by creator prompt is low impact issue.

# Severity guidance
• Critical — Spec/security/legal conflict or blocked core flow; unimplemented CRITICAL/HIGH mandatory fix; Decision metric non‑actionable on a release‑critical path
• High — Major decision quality or coverage risk (e.g., conflicting requirements, broken PK uniqueness, cross-artifact contradiction without Rule‑1 deferral)
• Medium — Actionable but not release‑blocking (e.g., ambiguous values with safe defaults, inconsistent units, incomplete but interpretable Decision metric)
• Low — Stylistic/orthographic/format nits; naming drift; vanity/trend completeness suggestions; acceptable placeholders used correctly
• **Impact calibration for baselines:** Unknown auth‑context + absent baseline ⇒ **Low**; named state‑changing endpoint without control ⇒ **Medium**; explicit public unauthenticated write without throttling ⇒ **High**
• **Unknown‑context policy (aligned with qualifiers):** For AOB/CPI, when applicability is unclear **raise Low** `cross‑artifact` and state the uncertainty; **suppress only** with positive evidence of non‑applicability.

# SCOPE-OF-REVIEW MATRIX (hard guardrails)
# Derive allowed topics from the Current Artifact's column set and the official table catalog.
# If the official table catalog is absent from Dependencies, treat only the 🟧 Upcoming artifacts in this phase as authoritative for Rule‑1 deferral.
# If a topic is not owned by the current schema, apply Rule‑1 and SKIP — **except**:
# • CPI: current artifact must host prerequisite primitives/fields for a capability asserted elsewhere → in scope (anchor to current artifact).
# • AOB: always in scope unless a precise owner is named downstream in this phase.
# **Cross‑artifact invariants:** Even if owned elsewhere, you **must** raise a gap marked `cross‑artifact` (use an allowed `gapType`, typically `MissedRequirement`) when the current artifact makes an assertion that requires undefined data/primitives elsewhere (see Rule‑1 exceptions).
# Examples:
# - For 1.1.0 "Input": in-scope = required rows present; column presence; internal consistency;
#   high-level coverage vs ClientSpec. Out-of-scope = metrics, security/control details, test plans,
#   trace links → DEFER to artifacts that own those columns (e.g., 1.1.2 "Domain Context" → "Potential Metrics").
# - For 1.1.2 "Domain Context": "Potential Metrics" cells must be quantitative KPIs (Rule-7).

# DETERMINISTIC DEFERRAL (augment Rule-1)
# Build a topic→column map from the official table catalog **in Dependencies** and the Upcoming artifacts (names + column headers).
# Require an explicit matching **column** in the upcoming artifact to defer.
# If a candidate topic maps to an Upcoming column and will be most likely implemented there, DROP the issue **only if** that artifact can legitimately **own** it (same abstraction level/column‑set). DROP **unless** it is:
#   • a capability‑prerequisite invariant needed by the current artifact, or
#   • an ownerless cross‑cutting baseline (security, GDPR evidence, instrumentation).

# EVIDENCE-ANCHOR REQUIREMENT (augment Rule-3)
# Before recording any issue, privately locate:
#  (1) the expected column in Current Artifact; and
#  (2) the strongest matching substring in Current Artifact.
# If (2) exists and is adequate-quality → DO NOT raise the issue.
# **Mis‑anchor check:** confirm the chosen locator **owns** the control per the Owner‑Tier Map; if not, **relocate** or mark `cross‑artifact`; do **not** attach controls to non‑owning components.
# **Locator audit (required):** Treat mis‑anchored findings as false‑positives. Before emission, re‑check owner‑tier; if uncertain, **prefer** `cross‑artifact <index> Whole artifact` rather than anchoring to a non‑owner. Category labels are not owners.
# When a baseline concern is valid but no owner exists in the current artifact, raise `cross‑artifact` and name the target artifact type/owner in the recommendation (do not park the finding on an unrelated row).
# **Ownerless/CPI exception:** for AOB, CPI, and **ghost‑dependencies**, you may use **`<index> Whole artifact`** as the locator; do not defer solely because no specific column exists.
# **Unknown‑context handling:** Raise only when applicability is evidenced; if applicability is unknown, skip and recommend documenting applicability context.
# When locus is outside the current artifact or owner is unclear, include the literal token cross‑artifact in the shortDescription.

# UNIVERSAL REVIEW-TRIGGER CHECKLIST (current-artifact focus — **24 triggers**)
**A trigger fires only when the current artifact’s content or explicit dependencies provide concrete evidence matching the trigger’s condition.**
 Use these triggers on *current* artifact:
 • The Client Specification outranks dependency artifacts (“spec-wins”).
 • Do **not** penalise the current artifact for errors that exist **only** upstream unless it copies or relies on them.
 • If a trigger fires and neither Rule-1 nor Rule-2 forbids it, raise at least one matching gap/excess.

 1  SPEC-ALIGNMENT GAP / CONFLICT
    • Current content contradicts or omits an explicit requirement in the Client Specification.
    • Extra detail is welcome **unless it conflicts** with the spec or a non-conflicting dependency, **or changes behavior**; if it does, raise a gap/excess.
    Note: When the spec is silent and a dependency proposes stricter security defaults, prefer the stricter default unless it conflicts with spec or Upcoming artifacts own the decision.
 2  DEPENDENCY MISALIGNMENT  (spec-wins still applies)
    • Current artifact contradicts a dependency artifact *that does not itself conflict with the specification*.
    • If the spec is silent and two artifacts differ, treat the earlier one as reference and raise a gap/excess.
    • **Policy coherence:** contradictory strength levels for the same control across accessible sources (e.g., `recommended` vs `enforced`) → raise a gap and name both sources.
    Note: When the spec is silent and a dependency proposes stricter security defaults, prefer the stricter default unless it conflicts with spec or Upcoming artifacts own the decision.
 3  INTERNAL INCONSISTENCY
    • Any two rows, columns, or cells inside the artifact conflict.
 4  GRANULARITY / DETAIL MISMATCH
    • Information is so coarse it blocks implementation **or** so fine it over-specifies beyond the spec’s intended scope.
    • **End‑to‑end implementability (promise ↔ enabling counterparts):** For any declared behavior, constraint, assurance,
      or requirement, the Current Artifact must either (a) specify the concrete mechanism and named owner in its own
      columns/sections, or (b) explicitly reference a dependency that names the mechanism and owner (table/section/column).
      Mechanism/owner pairs must cover the interfacing tiers that make the promise real (UI ↔ API ↔ service logic ↔ data model ↔ security/control).
      If neither (a) nor (b) is satisfied, raise a gap.
    • **Critical‑path TBD:** primary components/technologies marked `TBD`/`to be selected` → at **phase‑end**, raise a gap if no binding decision/owner exists.
 5  MISSING VALUE WHILE SOURCE EXISTS
    • Blank / placeholder although data is present in the spec or a non-conflicting dependency.
    • If a required cell is blank where the policy demands N/A/TBD, raise Low MissedRequirement.
 6  DUPLICATE / OBSOLETE / EXCESS CONTENT
    • Redundant row, duplicate ID, obsolete element, or row count exceeds a stated cap (when such a cap is defined).
 7  IDENTIFIER / LINK ERROR & COLUMN-SET INTEGRITY
    • Malformed, broken, non-unique ID, wrong cross-reference, **or** a mandatory column-set/triplet is only partially filled. (Trace links in 1.1.0–1.1.4 exempt per Rule-2.)
    • Includes foreign keys that point to no existing row in declared dependencies.
    • **Ghost dependency:** a named dependency (component/service/job/interface) lacks a **defining artifact** in the accessible set — i.e., nowhere is it the **primary subject** with responsibilities/interfaces/owner/safeguards. Mentions in “Dependencies/Relationships” do **not** count → raise `cross‑artifact`.
    • **Post‑1.1.4 ID stability (mandatory):** Same requirement ID must preserve semantics across artifacts; drift ⇒ raise a gap anchored to the current artifact.
 8  TRACE LOOP INCOMPLETE
    • Entity/requirement appears here but nowhere downstream **after the partner artifact’s planned index has been delivered.**
    • Do not apply to artifacts 1.1.0–1.1.4 due to the traceability waiver.
 9  METRIC / TARGET INCOMPLETENESS OR CONFLICT
    • Quantitative target lacks unit, threshold, window, population, **instrumentation owner**, or source; non-SI/IEC unit; non-ISO-8601 timestamp; > 4 decimals; or duplicate/conflicting targets exist for the same ID.
    • **Metric–type coherence:** statistic type incompatible with measure type (e.g., percentile on Boolean success); or window/population mis-specified.
    • Success > 100 %, negative latency, mutually exclusive limits, etc.; **cross‑source drift**.
10  UNREALISTIC / IMPOSSIBLE VALUES
11  STRATEGY / PROCESS DEVIATION
    • Violates the agreed methodology, toolchain, or Definition-of-Done for this artifact type.
12  SECURITY / COMPLIANCE GAP
    • Missing, weak, duplicated, or outdated control; unmet legal/licence/privacy requirement.
    • **Security baselines (ownerless):** for authenticated state‑changing requests expect CSRF defenses; rate‑limit/brute‑force throttles; session cookie HttpOnly/Secure/SameSite; idle and absolute session timeouts; basic output encoding in admin UI. Apply the **session scheme invariant** from AOB.    • **GDPR evidence:** when consent/notice/erasure is in scope anywhere, expect consent boolean, policy version, timestamp, actor/source, retention/erasure fields, and export/erasure workflow owner.
    • **Erasure vs soft‑delete:** if soft‑delete exists and erasure is promised, require hard‑delete path + SLA.
    • AOB items apply (see Definitions).
13  PERFORMANCE / QUALITY MISALIGNMENT
    • Latency, throughput, availability, maintainability, or data-quality target mis-aligned with spec or SLA.
    • **Feasibility realism (mandatory):** challenge HA claims lacking required primitives (e.g., LB, stateless autoscaling, replication, zone failover, RPO/RTO); raise anchored to current artifact and name missing owner.
14  VERSION / TOOLCHAIN MISMATCH
    • Runtime, library, or pin conflicts with the approved tech stack.
15  LOGGING / AUDIT / DEPRECATION DEFECT
    • Required log field missing, audit format wrong, deprecation timeline absent.
    • **Data‑model prerequisite:** when `RBAC enforced`, `MFA`, `Session management`, `Audit logging`, or `Consent logging` is claimed, require **either** corresponding persistent fields/schemas **or** an explicit external authority + mapping/owner; otherwise raise **CrossArtifactGap** anchored to the current artifact.
16  ACCESSIBILITY / LOCALISATION OMISSION
    • Required WCAG tag, language fallback, or locale rule missing.
17  BUSINESS CONSTANT / CONFIG ERROR
    • Wrong, stale, or hard-coded business rule or constant.
    • **Standards sanity:** unrealistic maxima/minima for widely‑standardized fields (e.g., email local‑part length cap far below common standards) unless justified by business rule.
18  RISK / ASSUMPTION UNTRACKED
    • Known risk, assumption, or mitigation from spec/dependencies not mirrored here when it should be.
19  RATE-LIMIT / ERROR-BUDGET / SLA CEILING MISSING
    • Expected ceilings absent or inconsistent with performance objectives.
20  DECISION / INFO-CRUMB ERROR
    • Missing, duplicate, or malformed crumb in `metadata.notesFromLLM`, or fired trigger without matching crumb.
21  UNRESOLVED-NOTES VIOLATION
    • `unresolvedNotes` missing when gaps blocked, present when none blocked, reason > 120 chars, or pattern invalid.
22  PROGRESS-TRACKER LEAKAGE
    • Progress-Tracker table or sample row still present in artifact.
23  KPI-FORMAT DEFECT
    • Column header contains `Metric`/`Metrics` but cell is not a quantitative KPI (no statistic, threshold, unit, window, **or owner**), **or** uses incoherent statistic‑type.
24  CUSTOM-INSTR MISMATCH
    • Current artifact violates or omits a mandatory point in its Artifact-specific custom instructions block.
👉 **If any trigger fires and neither Rule‑1 nor Rule‑2 forbids it, at least one corresponding gap/excess *must* appear in `identifiedIssues`; omission is a *High‑severity reviewer oversight*.** Returning an empty list when a trigger fired violates the **Zero‑issues guard**.

# Triggers - gapType mapping:
  • Triggers 1,2,3,4,5,6,7,8,10,11,17,18,20,21,22,24 → MissedRequirement (unless clearly security/compliance).
  • 12,15 → SecurityGap or ComplianceGap (as applicable).
  • 13,19 → PerformanceGap.
  • 16 → UsabilityGap.
  • 9,23 → MissedRequirement (KPI format) unless a policy mandate makes it ComplianceGap.

# CROSS‑CUTTING BASELINES (for Rule‑0.1 and Rule‑5 bias)
# The following expectations are considered ownerless unless an upcoming artifact lists the exact column/section:
# • Security controls: CSRF for **authenticated** state‑changing requests; rate‑limit/throttling (for **public/unauthenticated** writes); session cookie flags; session timeouts; basic output encoding for admin UI.
# • GDPR/Privacy evidence: consent boolean, policy version, timestamp, actor/source; retention/erasure fields; export/erasure workflow owner.
# • Capability prerequisites: RBAC roles/permissions; MFA secret/method/recovery; audit log schema; metrics instrumentation owner/source.
# • Deterministic encryption when UNIQUE fields are encrypted at rest **and uniqueness is explicitly required**, or documented lookup/ADR; never infer uniqueness.
# **Privacy scope note:** Apply GDPR evidence only when personal data is in scope; if unclear, **recommend** documenting data categories, sources, and owner (do not raise a gap).

# ENUM LOCK (hard rule – any other token will be rejected):
 1. "impact":      **Critical | High | Medium | Low**   ← exact spelling, title case
 2. "knownIssue":  **NewIssue | KnownIssue | InProgress**   ← no other text, no extra spaces
 3. gapType list (choose the closest domain for each issue; applies to gaps **and** excesses):
 MissedRequirement | SecurityGap | ComplianceGap | PerformanceGap | UsabilityGap | Other.
 *IMPORTANT*: Use only the gapType values shown above; never invent new types! Invented gap types will be rejected!

# Locator rule – every shortDescription **must begin with the current artifact index** (e.g. 1.1.2) **followed by a space**, then:
 • a row ID (e.g. I-12) **optionally followed by** a column name, OR
 • a column name alone, OR
 • *Whole artifact* (when no specific row/column applies).
 • If the secondary locator is omitted, write `Whole artifact` after the index.
 • Examples:
   • `1.1.2 I-12`
   • `1.1.2 SLA`
   • `1.1.2 I-12 SLA`
   • `1.1.2 Whole artifact`
 • The locator counts toward the word limit.
 • Use <index> Whole artifact when the issue spans multiple rows/columns; if uncertain, anchor to the broadest specific row/column

# Style rules:
 - shortDescription: telegraphic noun phrase, **max 12 words** incl. artifact-index locator; hyphen-joined terms count as one word.
 - recommendation: **mandatory**; imperative verb, **≤ 10 words**.
  • Prefer citing the **exact column in the current artifact**.
  • Cross‑artifact is a literal marker included in shortDescription; it is not a gapType. Use any appropriate gapType (e.g., MissedRequirement, SecurityGap) and include the marker text cross‑artifact in the shortDescription.
  • For cross‑artifact fixes, **name the owner‑tier**; only name an artifact index + column when conclusively identifiable. **Do not fabricate indices.**
  • Reference the same locator when helpful (“Link I-07 to US-03”).
  • Describe the *next concrete action* (Add / Remove / Link / Rewrite / Defer / Verify …), and include the exact row/column or spec-ID to modify so the artifact-creator can copy the instruction verbatim.
  • Never leave it blank; write “Investigate root-cause” **only** if no fix is obvious.
   **🚨 If either field exceeds its word-limit, drop trailing words until limit is met.**
  • Good vs bad length examples:
    ✔ `1.2.7 All trace links missing` (5 words)
    ✘ `1.2.7 Whole artifact Questions for Stakeholders Table trace link missing` (13 words)
 - If a phrase exceeds 12 words, compress or drop adjectives.
 - Do not end either field with a period; remove any generated trailing period.
 - *IMPORTANT*: Prefer backticks for the locator; escaping is a fallback. Inside JSON strings escape any inner double-quotes (\" \") or wrap the locator in back-ticks ( `like this` ); un-escaped quotes will be rejected.
 - **Reminder – Traceability waiver:** For artifacts **1.1.0 → 1.1.4**, raise **no traceability gaps of any kind** (Rule-2).
   • Any attempt to raise such a gap is a direct violation and must be omitted from `identifiedIssues`.
 - Limit – output at most **20 issues** to avoid overflow.
 🔒 Before returning JSON: if any `gapID` repeats, revise until unique.
  - **FINAL REMINDER** – Before emitting JSON, verify you have **not** raised a gap handled by *Upcoming artifacts in this phase*.
  - **Word‑count rule:** Count every whitespace‑separated token toward the 12‑word limit **except** the exact token `cross‑artifact`.

# COMPLIANCE CHECKLIST
 ⓪  Compliance Checklist – perform silently before JSON
 (scratch-pad: Rule-1 Rule-2 Rule-3 Rule-4 Rule-5 Rule-6 Rule-7 ShortDescription≤12 Recommendation≤10 JSON-valid)

# TASKS – run all; omit any that pass. Always obey ABSOLUTE RULES
 0 Preparation
  • Load Client Specification, dependency artifacts, Current Artifact, and Unresolved Issues.
  • For each item in *Unresolved Issues*, **must** re-check whether the underlying defect is still present **in this artifact**; if not, do **not** re-raise it.
  • Mark topics covered by 🟧 Upcoming artifacts (Rule-1) and the 1.1.0 – 1.1.4 trace-waiver scope (Rule-2).

 1 Evidence scan (Rule-3)
  • Search CS → Dependencies → Current Artifact (case-insensitive substrings, indirect links).
  • Apply Rule-3 positive-evidence check before flagging a gap
  • If the requirement is already met in Current Artifact and is well-specified → stop.

 2 Trigger sweep
  • Iterate through the 24 Universal Review-Triggers.
  • For every live trigger not deferred by Rule-1/2, create ≥ 1 candidate finding *within the SCOPE-OF-REVIEW MATRIX*.
  • **Cluster sweep:** If any AOB/CPI item triggers, emit **one aggregated** `cross‑artifact` **cluster finding** that lists the specific missing primitives; **MUST NOT** emit isolated near‑duplicates; **reuse gapID**.


 3 Classify & draft rows
  • Choose gapType, impact, and precise locator; craft shortDescription (≤ 12 words) and recommendation (≤ 10 words).
  • Reject any issue lacking an internal evidence anchor or a column-precise recommendation.
  • Apply knownIssue logic: reuse gapID (KnownIssue / InProgress) or leave blank (NewIssue).

 4 Deduplicate & consolidate (Rule-4)
  • Merge duplicate findings under a single gapID; widen or narrow the locator as required by the examples.
  • Verify every gapID is unique.

 5 Quota & quick-check
  • If > 20 issues, retain the highest-impact ones first.
  • Order by severity: **Critical → High → Medium → Low**; prefer ownerless/CPI and **ghost‑dependency** gaps. If > 20, retain the highest‑impact first.
  • Re-run the Upcoming-Artifact scan; drop any entry that should be silently deferred.

 6 Emit JSON only
  • Output exactly one object:
   {{ "questionText": …, "identifiedIssues": […] }}
  • No extra prose, markdown, or code fencing.
(<end of instruction block>)

(<start of project data block:>)
# PROJECT DATA:
 1. Dependencies (client specification + other artifacts):
  {dependency_text}

 2. **Current phase:** {phase_name}

 3. **Current artifact:** {artifact_index}

 🟧🟧 UPCOMING ARTIFACTS — DO NOT FLAG GAPS FOR THESE 🟧🟧
 4. **Upcoming artifacts in this phase:**
  {phase_overview_md}

 5. Current Artifact (JSON):
  {artifact_text}

 6. Artifact-specific custom instructions
  {custom_instructions}

 7. Unresolved Issues from previous iteration:
  {short_prev_issues_str}

 8. Question:
  {q_text}
(<end of project data block>)

(<start of additional instructions block:>)
            Illustrative JSON examples (do **not** include in output):

            Example NewIssue (deficiency):
            {{
              "gapType": "MissedRequirement",
              "shortDescription": "1.1.2 Whole artifact `refund within 24 hours` Missing",
              "gapID": "",
              "knownIssue": "NewIssue",
              "impact": "High",
              "recommendation": "Add refund-rule row; cite client spec US-01"
            }}

            Example KnownIssue (excess):
            {{
              "gapType": "SecurityGap",
              "shortDescription": "1.1.2 I-27 Duplicate Over-spec",
              "gapID": "SEC-004",
              "knownIssue": "KnownIssue",
              "impact": "Medium",
              "recommendation": "Delete duplicate I-27; keep single authorised row"
            }}

            Example InProgress (being fixed):
            {{
              "gapType": "MissedRequirement",
              "shortDescription": "1.1.2 I-07 Partial trace-link added",
              "gapID": "beaf8b",
              "knownIssue": "InProgress",
              "impact": "Medium",
              "recommendation": "Complete trace links I-07"
            }}

            *NEGATIVE, BAD Example* (should be DEFERRED as violates rules – do NOT output!):
            {{
              "gapType": "MissedRequirement",
              "shortDescription": "1.1.2 Whole artifact Workflow Mapping Table Missing",
              "gapID": "",
              "knownIssue": "NewIssue",
              "impact": "High",
              "recommendation": "Add Workflow Mapping Table"
            }}

            Example for *no* issues (use only when **no triggers fire** after full sweep):
            {{ "questionText": "{{q_text}}", "identifiedIssues": [] }}

          **JSON-SAFETY RULE — Inside every JSON string use ONLY UTF-8 characters that are neither a raw double-quote ( " ) nor an unescaped back-slash ( \ ).
          If you need quotes around a word, wrap them in back-ticks (`like this`) or escape them as \"like this\".  Use \\n only where a newline is required; escape ≥ and % inside strings.**

            Return **ONLY** valid JSON:
            {{
              "questionText": "{{q_text}}",
              "identifiedIssues": [
                {{
                  "gapType": "...",
                  "shortDescription": "...",
                  "gapID": "some ID (blank if new)",
                  "knownIssue": "KnownIssue | InProgress | NewIssue",
                  "impact": "Critical | High | Medium | Low",
                  "recommendation": "specific recommendation text: locator/action/link"
                }}
              ]
            }}

# knownIssue flagging:
 • **Decision block:** If gapID appears in *Unresolved*: if fully fixed → **omit**; if partially fixed → **InProgress**; else **KnownIssue**. If new → **NewIssue**.
 • Allowed tokens are **exactly** `KnownIssue`, `InProgress`, `NewIssue` (any other value will be rejected).
 • Always scan the current artifact for partial fixes first; if any are visible, use InProgress with the updated locator.
 • Use **KnownIssue** when the gapID is still present with **no visible remediation**; if fully remediated in this artifact, **omit** the issue (resolved by omission).
 • Use **InProgress** only when you explicitly detect partial fixes in this artifact and cite the locator that shows the fix.
 • Otherwise use **NewIssue**.
 • **If the gapID you output already appears in *Unresolved Issues* and the problem is still unsolved and is applicable to current artifact fully, you MUST reuse that gapID and set `"knownIssue": "KnownIssue"` (unless you are explicitly marking partial remediation with `"InProgress"`, or the issue is fully `"Resolved"`).  Never label such an issue `"NewIssue"`.**
 • Any other token in either `gapType` or `knownIssue` will cause the response to be rejected.
 • If no issues, output {{ "questionText": "{{q_text}}", "identifiedIssues": [] }}
 • **Reuse guard:** Before marking `KnownIssue`, re‑check the Current Artifact. If any remediation is visible, **reuse the same `gapID`** but set `"knownIssue": "InProgress"` and update the locator. **Do not** use `KnownIssue` when partial fixes exist.

# QUICK-CHECK STEP ────────────────────────────
 **Before emitting JSON** quickly scan the *Upcoming artifacts* list:
  • If a candidate issue’s primary topic matches an 🟧 Upcoming artifact → apply Rule‑1 (skip) **unless**:
    – **AOB** item, or
    – **CPI** needed by the current artifact.
  • If `shortDescription` contains a substring that equals any Upcoming artifact name ⇒ DEFERRED
  • Otherwise continue with normal gap evaluation.
  • Do NOT include the Compliance Checklist in the JSON output
  • 🚫 Rule-2 reminder: artifacts 1.1.0-1.1.4 ⇒ traceability gaps are out-of-scope.
  • Do **not** claim a metric is violated unless the artifact contains measured data; target rows alone are not evidence of failure.
  • Apply the **ID stability** and **capability‑prerequisite** checks before deferral.
  • Minimise false-positives and false-negatives — raise only evidence-backed issues.
  • Priority: FP‑averse default **except** AOB/CPI/ghost‑dependency/phase‑end, where **one Low** `cross‑artifact` cluster beats silence when unsure.
  • Apply the **Zero‑issues guard (safe)**: use **only** when a trigger has positive applicability evidence, no in‑artifact semantic match exists, and Rule‑1/2 do not defer; emit **one** Low `cross‑artifact` cluster summary.
  • Apply the **ID stability** and **capability‑prerequisite** checks before deferral.
  • **Phase‑end invariants sweep:** on last mini‑iteration or when no upcoming artifacts remain in phase, re‑scan already‑reviewed artifacts in this phase; if any CPI/AOB/**ghost‑dependencies** or critical‑path `TBD` remain, raise now in the **current artifact** as `cross‑artifact`; do **not** defer.

# **FINAL REMINDER** – Before emitting JSON, verify you have **not** raised a gap handled by *Upcoming artifacts in this phase* and that every `gapID`, enum token, and word-count passes the compliance checklist.

# No extra text outside JSON, no triple backticks or code fencing.
            """


            raw_response = self.openai_cheap_api(prompt)

            try:
                data = json.loads(raw_response)
            except json.JSONDecodeError:
                def _fix_short_desc(match):
                    body = match.group(1).replace('"', r'\"')
                    return f'"shortDescription": "{body}"'
                safe = re.sub(
                    r'"shortDescription"\s*:\s*"(.*?)"',   # non-greedy grab of body
                    _fix_short_desc,
                    raw_response,
                    flags=re.S
                )
                try:
                    data = json.loads(safe)
                except json.JSONDecodeError:
                    data = {"questionText": q_text, "identifiedIssues": []}

            issues_candidate = data.get("identifiedIssues", [])
            if not isinstance(issues_candidate, list):
                issues_candidate = []

            valid_issues = []
            for item in issues_candidate:
                if isinstance(item, dict):
                    valid_issues.append(item)
                else:
                    print("WARNING: LLM returned non-dict in identifiedIssues ->", item)

            raw_collected_issues.extend(valid_issues)

        return raw_collected_issues


    def safe_teacher_review(
        self,
        issue_tracker,
        macro_iter_idx: int,
        phase_name,
        mini_iter_idx: int,
        artifact_index: str,
        artifact_text: str,
        dependency_text: str,
        unresolved_prev_issues: list,
        artifact_review_questions: dict
    ) -> list:
        """
        Calls 'review_artifact_with_teacher_one_question_at_a_time' with the correct parameters,
        ensuring we gather the teacher's new issues for the current artifact in a robust manner.
        """
        max_teacher_retries = 2
        final_issues = []

        for attempt in range(max_teacher_retries):
            try:
                final_issues = self.review_artifact_with_teacher_one_question_at_a_time(
                    issue_tracker=issue_tracker,
                    macro_iter_idx=macro_iter_idx,
                    phase_name=phase_name,
                    mini_iter_idx=mini_iter_idx,
                    artifact_index=artifact_index,
                    artifact_text=artifact_text,
                    dependency_text=dependency_text,
                    unresolved_prev_issues=unresolved_prev_issues,
                    artifact_review_questions=artifact_review_questions
                )
                return final_issues
            except Exception as e:
                print(f"Review attempt {attempt+1} failed, retrying: {e}")
                time.sleep(0.2)

        return final_issues


# =========================
# C) Main DevOpsSimulation Class
# =========================

class DevOpsSimulation:
    def __init__(self, artifact_data, sim_config=None):
        self.setup_documentation()
        self._client_spec_written = False
        if sim_config is None:
            sim_config = {
                "backwardCompatibilityMode": True,
                "macroIterations": 1,
                "phases": []
            }
        self.sim_config = sim_config
        # v6 ─ cache “final mini” count per phase (avoids StopIteration later)
        self._phase_final_mini = {                  # ← ADD ②
            p["phaseName"]: p.get("miniIterations", 1)
            for p in self.sim_config.get("phases", [])
        }
        self._prev_open_all = 0
        self.build_phase_index_map()
        self.partial_lessons = {}
        self.feedback_storage = {}
        self.issue_first_seen_iteration = {}
        self._carryover_open_ids    = set()
        self._carryover_by_type     = {}
        self.global_open_issue_ids = set()
        self.last_artifact_update = {}
        self.artifact_versions = {}
        self.iteration_summary = {}
        self.lessons_learned = {}
        self.reopened_ids_per_macro = defaultdict(set)
        self.llm_client = LLMClient()
        self.open_ids_at_end_of_mini = {}
        self.new_ids_in_mini         = {}
        self.pre_mini_open_issues = {}
        self._gap_artifact_tracker: dict[
            tuple[str, str],
            tuple[tuple | None, tuple]
        ] = {}

        # Pass devops_sim=self to IssueTracker so it can call get_global_mini_index
        self.issue_tracker = IssueTracker(
            self.issue_first_seen_iteration,
            self.llm_client,
            self.feedback_storage,
            phase_index_map=self.phase_index_map,
            devops_sim=self  # important change
        )
        # Add these lines so the rest of your code knows them:
        self.gap_types = [
            "MissedRequirement",
            "SecurityGap",
            "ComplianceGap",
            "PerformanceGap",
            "UsabilityGap",
            "Other"
        ]
        self.statuses_to_count = ["NewIssue", "KnownIssue", "InProgress", "Resolved"]
        self.impacts = ["Critical", "High", "Medium", "Low"]
        openai.api_key = userdata.get('OPENAI_API_KEY')
        os.environ["OPENAI_API_KEY"] = openai.api_key
        self.NUM_ITERATIONS = 1

        self.client_specifications = getattr(
            builtins, "CLIENT_SPEC",
            "I want a simple webpage where people can give feedback … Edge."
        )

        self.tables = artifact_data["tables"]
        self.dependencies_map = artifact_data["dependencies_map"]
        self.artifact_key_map = artifact_data["artifact_key_map"]
        self.artifact_trace_column_map = artifact_data["artifact_trace_column_map"]
        self.artifact_review_questions = artifact_data["artifact_review_questions"]
        self.build_global_mini_index()
        self.build_global_phase_map()
        self.llm_client.sim_config = self.sim_config
        self.llm_client.tables     = self.tables



    def build_global_phase_map(self):
        """
        Assign each (macroIteration, phaseName) a 1-based globalPhaseIndex, so we can
        compute cross-macro 'PhasesToResolution' properly. For example:
          Macro=1, phase=Requirements -> globalPhaseIndex=1
          Macro=1, phase=Design       -> globalPhaseIndex=2
          ...
          Macro=2, phase=Requirements -> globalPhaseIndex=1 + (#phases in macro1)
        """
        self.global_phase_map = {}  # (macro_i, phaseName) -> globalPhaseIndex

        total_macros = self.sim_config.get("macroIterations", 1)
        phases_list = self.sim_config.get("phases", [])
        global_index_counter = 1

        for macro_i in range(1, total_macros + 1):
            for phase_info in phases_list:
                phase_name = phase_info["phaseName"]
                self.global_phase_map[(macro_i, phase_name)] = global_index_counter
                global_index_counter += 1


    def get_global_phase_index(self, macro_iter, phase_name):
        """
        Return the global phase index previously built in build_global_phase_map().
        Raises KeyError if (macro_iter, phase_name) not found.
        """
        return self.global_phase_map[(macro_iter, phase_name)]



    def build_global_mini_index(self):
        """
        Build a mapping of (phaseName, mini_iter) -> globalMiniIndex
        so that we can accurately compute closure times across phases.
        Store the result in self.global_mini_map.
        """
        self.global_mini_map = {}
        global_counter = 1

        # We'll assume sim_config["phases"] is a list of dicts:
        # e.g. [ {"phaseName":"Requirements", "miniIterations":2}, {"phaseName":"Design", "miniIterations":3} ]
        for phase_info in self.sim_config.get("phases", []):
            phase_name = phase_info["phaseName"]
            mini_count = phase_info.get("miniIterations", 1)
            for m_iter in range(1, mini_count + 1):
                self.global_mini_map[(phase_name, m_iter)] = global_counter
                global_counter += 1

    def get_global_mini_index(self, phase_name, mini_iter):
        """
        Return the global mini index for the given (phaseName, mini_iter).
        Raise an error if not found (should never happen if build_global_mini_index ran).
        """
        return self.global_mini_map.get((phase_name, mini_iter), 0)

    def find_previous_mini_key(self, macro_iter_idx: int, phase_name: str, mini_iter_idx: int):
        """
        Given the current (macro_iter_idx, phase_name, mini_iter_idx),
        return the immediately preceding iteration triple.

        Logic:
          1) If mini_iter_idx > 1, just decrement the mini_iter_idx in the same macro + phase.
          2) Else if this is the first mini in the current phase, we look at the previous phase in the same macro
            and use its last mini_iter_idx.
          3) If we are already in the very first phase of the macro, we go to the last phase of (macro_iter_idx - 1),
            if macro_iter_idx > 1. Then we pick the last mini of that last phase in the previous macro.
          4) If none of the above is possible (meaning we are at macro=1, first phase, mini=1), return None.

        Returns:
          A tuple (prev_macro, prev_phase_name, prev_mini) if found, or None if we are at the very start.
        """

        phases = self.sim_config.get("phases", [])
        # If no phases, treat it as if there's one single phase "Backcompat" per macro
        if not phases:
            # If not at the very first mini-iteration in the very first macro
            if mini_iter_idx > 1:
                # Just go to the previous mini in the same macro
                return (macro_iter_idx, phase_name or "Backcompat", mini_iter_idx - 1)
            elif macro_iter_idx > 1:
                # Jump back to the last mini of the previous macro
                # In pure backcompat, that last mini is 1
                return (macro_iter_idx - 1, phase_name or "Backcompat", 1)
            else:
                return None

        # Build a list of phase names in order
        phase_list = [p["phaseName"] for p in phases]
        try:
            current_phase_idx = phase_list.index(phase_name)
        except ValueError:
            # If the phase_name isn't recognized, we can't proceed
            return None

        # CASE A: If there's a previous mini in the same phase, just decrement mini_iter_idx
        if mini_iter_idx > 1:
            return (macro_iter_idx, phase_name, mini_iter_idx - 1)

        # CASE B: If we're at mini_iter_idx == 1, check if there's a previous phase in the same macro
        if current_phase_idx > 0:
            # Go to the last mini-iteration of the previous phase
            prev_phase_info = phases[current_phase_idx - 1]
            prev_phase_name = prev_phase_info["phaseName"]
            last_mini_count = prev_phase_info.get("miniIterations", 1)
            return (macro_iter_idx, prev_phase_name, last_mini_count)

        # CASE C: If we're at the first phase, mini=1, but not the first macro => go to last phase of the previous macro
        if macro_iter_idx > 1:
            prev_macro = macro_iter_idx - 1
            # last phase in the sim_config
            last_phase_info = phases[-1]
            last_phase_name = last_phase_info["phaseName"]
            last_mini_count = last_phase_info.get("miniIterations", 1)
            return (prev_macro, last_phase_name, last_mini_count)

        # CASE D: If we cannot go back (macro_iter_idx == 1, first phase, mini=1), then no previous iteration
        return None


    def calculate_issue_closure_time(self, gap_id):
        """
        Return the integer number of mini steps (inclusive) that the issue was open.
        If it's not resolved (missing resolvedInGlobalMini), return None.
        If there's a data anomaly (resolvedInGlobalMini < firstSeenGlobalMini), return None too.
        """
        record = self.issue_first_seen_iteration.get(gap_id, {})
        gm_first = record.get("firstSeenGlobalMini")
        gm_res = record.get("resolvedInGlobalMini")

        if gm_first is None or gm_res is None:
            # Not resolved or missing data => no closure time
            return None

        raw_diff = gm_res - gm_first
        duration = raw_diff + 1

        # If negative or zero, treat as invalid => return None
        if duration < 1:
            return None

        return duration

    ########################################################################
    # Helper: fetch lessons relevant to the *new* mini-iteration
    ########################################################################
    def get_lessons_for_new_mini(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int
    ) -> str:
        """
        Returns a bullet-formatted string of lessons learned that the writer LLM
        should see at the start of (macro_iter_idx, phase_name, mini_iter_idx).

        Priority cascade:
          1) The immediately previous mini in the same phase.
          2) If we are at mini 1, take the final mini of the previous phase
            (same macro).
          3) If this is macro > 1 and phase == firstPhase and mini == 1,
            take the final mini of the last phase of the previous macro.

        If no lessons are found, returns an empty string.
        """
        # ————————————————— DEBUG —————————————————
        print(
            f"retrospective_problem|GET|ENTER|macro={macro_iter_idx}"
            f"|phase={phase_name}|mini={mini_iter_idx}"
            f"|known_keys={list(getattr(self,'_lessons_log',{}).keys())}",
            file=sys.stderr
        )
        # ------------------------------------------------------------------
        # Build candidate (macro, phase, mini) keys in priority order
        # ------------------------------------------------------------------
        phases = [p["phaseName"] for p in self.sim_config["phases"]]
        phase_idx = phases.index(phase_name) if phase_name in phases else -1
        candidates: list[tuple[int, str, int]] = []

        if mini_iter_idx > 1:
            # Previous mini in the same phase
            candidates.append((macro_iter_idx, phase_name, mini_iter_idx - 1))
        else:
            # First mini in this phase
            if phase_idx > 0:
                prev_phase = phases[phase_idx - 1]
                last_mini_prev_phase = self.sim_config["phases"][phase_idx - 1].get("miniIterations", 1)
                candidates.append((macro_iter_idx, prev_phase, last_mini_prev_phase))

            # First phase of a new macro? look at previous macro’s last phase
            if macro_iter_idx > 1:
                last_phase = phases[-1]
                last_mini_last_phase = self.sim_config["phases"][-1].get("miniIterations", 1)
                candidates.append((macro_iter_idx - 1, last_phase, last_mini_last_phase))

        # ------------------------------------------------------------------
        # Retrieve stored lessons from self._lessons_log
        # ------------------------------------------------------------------
        lessons_store: dict = getattr(self, "_lessons_log", {})
        for key in candidates:
            if key in lessons_store and lessons_store[key]:
                print(                                   # — DEBUG
                    f"retrospective_problem|GET|HIT|key={key}"
                    f"|n_lines={len(lessons_store[key])}",
                    file=sys.stderr
                )
                return "\n".join(f"- {l}" for l in lessons_store[key])
        print("retrospective_problem|GET|MISS|returning_empty",
              file=sys.stderr)
        return ""  # nothing found



    def build_phase_index_map(self):
        self.phase_index_map = {}
        if "phases" not in self.sim_config:
            return
        for idx, pinfo in enumerate(self.sim_config["phases"]):
            self.phase_index_map[pinfo["phaseName"]] = idx
        print("DEBUG: built phase_index_map:", self.phase_index_map)

    def get_final_artifact_versions_for_macro(self, macro_iter_idx: int) -> dict:
        """
        Return a dict {artifact_index: artifact_dict} representing each artifact’s
        final version at the end of macro_iter_idx, to avoid double-counting.

        We iterate phases and minis in reverse order so that the first time we see
        an artifact is its final state for that macro.
        """
        final_artifacts = {}

        if macro_iter_idx not in self.artifact_versions:
            return final_artifacts  # no data for this macro at all

        phases_info = self.sim_config.get("phases", [])
        for phase_info in reversed(phases_info):
            phase_name = phase_info["phaseName"]
            mini_max = phase_info.get("miniIterations", 1)
            for mini_idx in range(mini_max, 0, -1):
                phase_artifacts = (
                    self.artifact_versions
                        .get(macro_iter_idx, {})
                        .get(phase_name, {})
                        .get(mini_idx, {})
                )
                for art_idx, art_dict in phase_artifacts.items():
                    if art_idx not in final_artifacts:
                        final_artifacts[art_idx] = art_dict

        return final_artifacts

    def ensure_macro_row_edit_totals(self, iter_data: dict) -> None:
        """
        Guarantee that the roll‑up keys needed for churn exist.
        Called after all mini counters are rolled into `iter_data`
        but *before* compute_iteration_metrics().
        """
        iter_data.setdefault("macro_total_added_rows",
                            iter_data.get("iteration_added_rows_sum", 0))
        iter_data.setdefault("macro_total_removed_rows",
                            iter_data.get("iteration_removed_rows_sum", 0))
        iter_data.setdefault("macro_total_changed_rows",
                            iter_data.get("iteration_changed_rows_sum", 0))


    def capture_macro_baseline_rows(self, macro_iter_idx: int) -> int:
        """
        Baseline for churn = total rows of *all* final artifacts
        in the previous macro (macro_iter_idx – 1).
        """
        if macro_iter_idx <= 1:
            return 0    # first macro has no baseline

        prev_macro = macro_iter_idx - 1
        final_artifacts = self.get_final_artifact_versions_for_macro(prev_macro)
        return sum(len(a.get("rows", [])) for a in final_artifacts.values())

    def get_artifact_final_row_count(self, artifact_index: str, macro_iter_idx: int) -> int:
        """
        Finds the final version of the given artifact_index at the end of macro_iter_idx,
        returning the number of rows. If not found, returns 0.
        We assume the artifact's last phase is the final phase in sim_config,
        and the last mini iteration for that phase.
        """
        phases = self.sim_config.get("phases", [])
        if not phases:
            return 0

        last_phase_info = phases[-1]
        last_phase_name = last_phase_info["phaseName"]
        last_mini = last_phase_info.get("miniIterations", 1)

        # retrieve final artifact version from self.artifact_versions
        art_dict = (
            self.artifact_versions
                .get(macro_iter_idx, {})
                .get(last_phase_name, {})
                .get(last_mini, {})
                .get(artifact_index, {})
        )
        rows = art_dict.get("rows", [])
        return len(rows)

    def update_global_unresolved_issues(self, macro_iter_idx: int, phase_name: str, mini_iter_idx: int):
        """
        Scan all artifacts in feedback_storage[macro_iter_idx][phase_name][mini_iter_idx],
        and add every open (unresolved) gapID to self.global_open_issue_ids.
        (Open means knownIssue in [NewIssue, KnownIssue, InProgress].)
        """
        phase_data = (
            self.feedback_storage
                .get(macro_iter_idx, {})
                .get(phase_name, {})
                .get(mini_iter_idx, {})
        )

        for artifact_index, issues_list in phase_data.items():
            for iss in issues_list:
                gap_id = iss.get("gapID")
                if not gap_id:
                    continue

                status = iss.get("knownIssue", "NewIssue")
                if status in ["NewIssue", "KnownIssue", "InProgress"]:
                    self.global_open_issue_ids.add(gap_id)
                else:
                    # If resolved, remove from global set if it is present
                    if gap_id in self.global_open_issue_ids:
                        self.global_open_issue_ids.remove(gap_id)

    def apply_global_unresolved_issues(
            self,
            macro_iter_idx: int,
            phase_name: str,
            mini_iter_idx: int
        ):
        """
        Guarantee that every gapID which is *still open globally*
        (self.global_open_issue_ids) is represented inside
        feedback_storage[macro][phase][mini].

        • If the gap already lives in one of this mini’s real artifacts, do nothing.
        • Otherwise push a placeholder into the synthetic artifact
          “_GLOBAL_CARRY_”.

        Extra rule (2025‑04‑22 hot‑fix):
          – If the carried‑over gap’s master record still says
            'NewIssue', convert it to 'KnownIssue' so it will not be
            re‑counted as “new” in the next mini.
        """
        # —―― 1) reference to the dict for this mini
        phase_data = (
            self.feedback_storage
                .setdefault(macro_iter_idx, {})
                .setdefault(phase_name, {})
                .setdefault(mini_iter_idx, {})
        )

        global_artifact_key = "_GLOBAL_CARRY_"

        # —―― 2) collect every gapID already present in *this* mini
        existing_gapIDs_in_this_mini = {
            iss["gapID"]
            for issues_list in phase_data.values()
            for iss in issues_list
            if "gapID" in iss
        }

        # ensure the bucket exists
        phase_data.setdefault(global_artifact_key, [])

        # —―― 3) add placeholders for any missing open gaps
        for gap_id in self.global_open_issue_ids:
            if gap_id in existing_gapIDs_in_this_mini:
                continue

            master_rec = self.issue_first_seen_iteration.get(gap_id, {})
            knownIssue_status = master_rec.get("status", "KnownIssue")

            # hot‑fix: “NewIssue” that survives a mini becomes “KnownIssue”
            if knownIssue_status == "NewIssue":
                knownIssue_status = "KnownIssue"
                master_rec["status"] = "KnownIssue"
            # fallback if the stored status is something unexpected
            if knownIssue_status not in ["KnownIssue", "InProgress"]:
                knownIssue_status = "KnownIssue"

            placeholder_issue = {
                "gapID": gap_id,
                "gapType": master_rec.get(
                    "finalGapType",
                    master_rec.get("initialGapType", "Other")
                ),
                "shortDescription": master_rec.get(
                    "shortDescription",
                    f"Open gapID={gap_id} (global carry‑over)"
                ),
                "knownIssue": knownIssue_status,
                "impact": master_rec.get(
                    "finalSeverity",
                    master_rec.get("initialSeverity", "Medium")
                ),
                "recommendation": master_rec.get("recommendation", ""),
                "verificationNote": "Globally carried from previous phase/mini"
            }
            phase_data[global_artifact_key].append(placeholder_issue)

    # ─────────────────────────────────────────────────────────────
    # v6  Heading-hygiene helpers
    # ─────────────────────────────────────────────────────────────
    def _write_client_spec_once(self) -> None:
        """Emit client specifications exactly once at the top of the student DOCX."""
        if getattr(self, "_client_spec_written", False):
            return
        self.doc.add_heading("Original Client Specifications", level=1)
        self.doc.add_paragraph(self.client_specifications)
        self._client_spec_written = True

    def _is_final_macro(self, macro_i: int) -> bool:
        """True iff *macro_i* is the last configured macro-iteration."""
        return macro_i == self.sim_config.get("macroIterations", 1)

    def _is_latest_artifact_pass(self,
                                 macro_i: int,
                                 phase_name: str,
                                 mini_i: int) -> bool:
        """True only for the final mini-iteration of the final macro-iteration."""
        if macro_i != self.sim_config.get("macroIterations", 1):
            return False
        final_mini = self._phase_final_mini.get(phase_name, 1)
        return mini_i == final_mini

    def setup_documentation(self):
        """
        Sets up the docx documents (self.doc, self.doc_teacher) and
        initializes all CSV headers for:
          1) iteration_metrics.csv (Artifact-level)
          2) mini_iteration_summary_metrics.csv (Mini-iteration level)
          3) iteration_summary_metrics.csv (Macro iteration level)

        We use the final 'best option' columns discussed in the new Detailed Metrics:
          - Artifact CSV columns reflect the final artifact-level approach.
          - Mini CSV columns reflect all fields computed in compute_mini_iteration_metrics.
          - Macro CSV columns reflect all fields from compute_iteration_metrics.
        No omissions, no optional columns: each header exactly matches
        the data we plan to write in those CSVs.
        """
        import csv
        import os
        from docx import Document

        # -------------------------------------
        # 1) Initialize Word Documents
        # -------------------------------------
        self.doc = Document()
        self.doc_teacher = Document()

        # -------------------------------------
        # 2) Artifact-Level CSV: iteration_metrics.csv
        # -------------------------------------
        self.csv_file = open("iteration_metrics.csv", "w", newline="", encoding="utf-8")
        self.csv_writer = csv.writer(self.csv_file)

        # These columns match the final artifact-level approach
        # (One row per artifact per mini iteration),
        # including open-based defect density and severity-based densities.
        artifact_header = [
          # (Original 23 columns)
          "MacroIteration",
          "PhaseName",
          "MiniIteration",
          "ArtifactIndex",

          "LexicalDensity",
          "UniqueTermRatio",
          "TableComplexity",
          "TraceabilityCoverage",

          "RowsAdded",
          "RowsRemoved",
          "RowsModified",
          "ChurnPercent",

          "OpenIssueCount",
          "NewIssueCount",
          "KnownIssueCount",
          "InProgressIssueCount",
          "ResolvedIssueCount",

          "DefectDensity",
          "NewDefectDensity",
          "CriticalDefectDensity",
          "HighDefectDensity",
          "MediumDefectDensity",
          "LowDefectDensity",

          # (Newly added columns for carried-over and gap-type counts)
          "CarriedOverCount",
          "MissedReqCount",
          "SecurityGapCount",
          "ComplianceGapCount",
          "PerformanceGapCount",
          "UsabilityGapCount",
          "OtherGapCount"
      ]
        self.csv_writer.writerow(artifact_header)

        # -------------------------------------
        # 3) Macro-Level CSV: iteration_summary_metrics.csv
        # -------------------------------------
        self.iteration_summary_file = "iteration_summary_metrics.csv"
        if not os.path.isfile(self.iteration_summary_file):
            with open(self.iteration_summary_file, "w", newline="", encoding="utf-8") as summ_f:
                summ_writer = csv.writer(summ_f)

                # Full set of macro-level metrics, matching the final dictionary
                # returned by compute_iteration_metrics (no omissions).
                macro_header = [
                    # 1) Basic iteration info
                    "MacroIteration",         # same as "Iteration"
                    "StartTime",
                    "EndTime",
                    "SpentTimeSec",

                    # 2) Lexical & churn
                    "macro_lexical_density",
                    "macro_unique_term_ratio",
                    "macro_artifact_churn_pct",

                    # 3) Distinct overall counts
                    "total_new",
                    "total_known",
                    "total_inprogress",
                    "total_resolved",
                    "total_open_all",

                    # 4) By gap type (new/known/inprog/resolved)
                    "macro_newMissedReq",
                    "macro_knownMissedReq",
                    "macro_inprogMissedReq",
                    "macro_resolvedMissedReq",

                    "macro_newSecurityGaps",
                    "macro_knownSecurityGaps",
                    "macro_inprogSecurityGaps",
                    "macro_resolvedSecurityGaps",

                    "macro_newComplianceGaps",
                    "macro_knownComplianceGaps",
                    "macro_inprogComplianceGaps",
                    "macro_resolvedComplianceGaps",

                    "macro_newPerformanceGaps",
                    "macro_knownPerformanceGaps",
                    "macro_inprogPerformanceGaps",
                    "macro_resolvedPerformanceGaps",

                    "macro_newUsabilityGaps",
                    "macro_knownUsabilityGaps",
                    "macro_inprogUsabilityGaps",
                    "macro_resolvedUsabilityGaps",

                    "macro_newOtherGaps",
                    "macro_knownOtherGaps",
                    "macro_inprogOtherGaps",
                    "macro_resolvedOtherGaps",

                    # 5) Carried over + closure
                    "carried_over",
                    "mean_closure_time",
                    "total_resolved_this_macro",
                    "resolved_but_reopened",

                    # 6) Phase crossing metrics
                    "phase_crossings_critical",
                    "phase_crossings_avg",

                    # 7) Feedback & final coverage
                    "feedback_impl_rate",
                    "final_macro_table_complexity",
                    "final_macro_trace_coverage",

                    # 8) Severity-based open densities
                    "final_macro_open_defect_density",
                    "final_macro_new_defect_density",
                    "final_macro_critical_defect_density",
                    "final_macro_high_defect_density",
                    "final_macro_medium_defect_density",
                    "final_macro_low_defect_density",

                    # 9) Rolling averages
                    "iter_rolling_avg_new_issues",
                    "iter_rolling_avg_open_defect_density",
                    "iter_rolling_avg_new_defect_density",
                    "macro_issue_load",

                    "Added rows",
                    "Removed rows",
                    "Modified rows",

                ]

                summ_writer.writerow(macro_header)

        # -------------------------------------
        # 4) Mini-Iteration-Level CSV: mini_iteration_summary_metrics.csv
        # -------------------------------------
        self.mini_iteration_summary_file = "mini_iteration_summary_metrics.csv"
        if not os.path.isfile(self.mini_iteration_summary_file):
            with open(self.mini_iteration_summary_file, "w", newline="", encoding="utf-8") as mini_f:
                mini_writer = csv.writer(mini_f)

                # Full set of mini-level columns from the final compute_mini_iteration_metrics
                # No omissions: includes text/churn coverage, gap type breakdown,
                # distinct-based final counts, severities, rolling averages, etc.
                mini_header = [
                    # (1) Basic iteration identifiers
                    "MacroIteration",
                    "PhaseName",
                    "MiniIteration",
                    "StartTime",
                    "EndTime",
                    "SpentTimeSec",

                    # (2) Text & coverage & churn
                    "mini_iter_lexical_density",
                    "mini_iter_unique_term_ratio",
                    "mini_iter_table_complexity_sum",
                    "mini_iter_trace_coverage",
                    "mini_iter_defect_density",
                    "mini_iter_artifact_churn_pct",

                    # (3) Gap type counts (raw approach)
                    "newMissedReq",
                    "knownMissedReq",
                    "inProgressMissedReq",
                    "resolvedMissedReq",

                    "newSecurityGaps",
                    "knownSecurityGaps",
                    "inProgressSecurityGaps",
                    "resolvedSecurityGaps",

                    "newComplianceGaps",
                    "knownComplianceGaps",
                    "inProgressComplianceGaps",
                    "resolvedComplianceGaps",

                    "newPerformanceGaps",
                    "knownPerformanceGaps",
                    "inProgressPerformanceGaps",
                    "resolvedPerformanceGaps",

                    "newUsabilityGaps",
                    "knownUsabilityGaps",
                    "inProgressUsabilityGaps",
                    "resolvedUsabilityGaps",

                    "newOtherGaps",
                    "knownOtherGaps",
                    "inProgressOtherGaps",
                    "resolvedOtherGaps",

                    # (4) Distinct-based final counts
                    "mini_total_new",
                    "mini_total_known",
                    "mini_total_inprogress",
                    "mini_total_resolved",
                    "mini_total_open_all",

                    # (5) Carried over
                    "mini_carried_over",

                    # (6) Mean closure & feedback
                    "mini_mean_closure_time",
                    "mini_feedback_impl_rate",

                    # (7) Open/new defect densities
                    "mini_iter_open_defect_density",
                    "mini_iter_new_defect_density",

                    # (8) Severity-based open defect densities
                    "mini_iter_critical_defect_density",
                    "mini_iter_high_defect_density",
                    "mini_iter_medium_defect_density",
                    "mini_iter_low_defect_density",

                    # (9) Rolling averages
                    "mini_iter_rolling_avg_new_issues",
                    "mini_iter_rolling_avg_defect_density",
                    "mini_iter_rolling_avg_new_defect_density",

                    # (10) Summaries (explicit for CSV)
                    "mini_iter_new_issue_count",
                    "mini_iter_known_issue_count",
                    "mini_iter_inprogress_issue_count",
                    "mini_iter_resolved_issue_count",
                    "mini_iter_open_issue_count",
                    "actual_resolved_now"
                ]

                mini_writer.writerow(mini_header)





    def run_simulation(self):
        if self.sim_config.get("backwardCompatibilityMode", True):
            print("INFO: Running in backward compatibility mode.")
            self.run_backcompat_iterations()
        else:
            print("INFO: Running new phase + mini-iteration approach.")
            self.run_phase_based_simulation()

    # =========================
    #  D)  Back-compat driver  (one mini per phase)
    # =========================
    def run_backcompat_iterations(self):
        """
        Back-compat mode that
          • executes the real phase list,
          • runs exactly ONE mini per phase,
          • omits mini-level lessons,
          • writes the same metrics/CSV rows as the enhanced engine,
          • and honours  self.sim_config["macroIterations"]  (default 1).

        v6 patch (2025-05-05):
            • Student DOCX heading hygiene:
                – call _write_client_spec_once() so the “Original Client
                  Specifications” block appears **once only** in the
                  entire document.
                – H1 “Macro Iteration NN” and H2 “Phase: …” inserted
                  **only in the final macro iteration**.
            • No teacher headings are added here (unchanged behaviour).
            • All business logic (counters, metrics, CSV) remains verbatim.
        """
        import datetime
        from collections import defaultdict

        # ── configuration ────────────────────────────────────────────────
        num_macros = self.sim_config.get("macroIterations", 1)

        phases = self.sim_config.get("phases", [])
        if not phases:
            phases = [{"phaseName": "Backcompat"}]

        cumulative_iter_counters = self.init_gap_counters()

        # ── MACRO loop ───────────────────────────────────────────────────
        for macro_iter_idx in range(1, num_macros + 1):
            iteration_start        = datetime.datetime.now()
            iteration_gap_counters = self.init_gap_counters()
            macro_iter_counters    = self.initialize_iteration_counters()

            # 1) immutable carry-over snapshot ---------------------------
            self._carryover_open_ids_start = set(self.global_open_issue_ids)
            self._carryover_by_type_start  = defaultdict(set)
            for gid in self._carryover_open_ids_start:
                rec   = self.issue_first_seen_iteration.get(gid, {})
                gtype = rec.get("finalGapType", rec.get("initialGapType", "Other"))
                self._carryover_by_type_start[gtype].add(gid)
            self._carryover_open_ids = set(self._carryover_open_ids_start)
            self._carryover_by_type  = {gt: ids.copy()
                                        for gt, ids in self._carryover_by_type_start.items()}

            # 2) student headings ---------------------------------------
            self._write_client_spec_once()   # emit spec block once only
            if self._is_final_macro(macro_iter_idx):
                self.doc.add_heading(f"Macro Iteration {macro_iter_idx:02d}", level=1)

            # 3) PHASE loop (one mini each) ------------------------------
            for phase_info in phases:
                phase_name    = phase_info["phaseName"]
                phase_tables  = phase_info.get("tableList", [])
                mini_iter_idx = 1  # single mini

                if self._is_final_macro(macro_iter_idx):
                    self.doc.add_heading(f"Phase: {phase_name}", level=2)

                mini_start_time    = datetime.datetime.now()
                mini_iter_counters = self.initialize_iteration_counters()

                # 3.a  process artifacts
                self.run_phase_single_pass(
                    macro_iter_idx          = macro_iter_idx,
                    phase_name              = phase_name,
                    mini_iter_idx           = mini_iter_idx,
                    phase_tables            = phase_tables,
                    iteration_gap_counters  = iteration_gap_counters,
                    cumulative_iter_counters = cumulative_iter_counters,
                    mini_iter_counters      = mini_iter_counters
                )

                mini_end_time = datetime.datetime.now()

                # 3.b  close the mini  (lessons blank in back-compat)
                self.finalize_mini_iteration(
                    macro_iter_idx     = macro_iter_idx,
                    phase_name         = phase_name,
                    mini_iter_idx      = mini_iter_idx,
                    start_time         = mini_start_time,
                    end_time           = mini_end_time,
                    mini_iter_counters = mini_iter_counters
                )

                # 3.c  roll up counters
                self.roll_up_counters(macro_iter_counters, mini_iter_counters)

            # 4) MACRO summary & CSV row ---------------------------------
            lessons_text = self.summarize_lessons_learned_for_mini_iteration(
                macro_iter_idx, phases[-1]["phaseName"], 1
            )
            self.lessons_learned[macro_iter_idx] = lessons_text

            self.ensure_macro_row_edit_totals(macro_iter_counters)
            iteration_end  = datetime.datetime.now()
            baseline_sum   = self.capture_macro_baseline_rows(macro_iter_idx)
            iteration_metrics = self.compute_iteration_metrics(
                macro_iter_idx          = macro_iter_idx,
                phase_name              = phases[-1]["phaseName"],
                mini_iter_idx           = 1,
                start_time              = iteration_start,
                end_time                = iteration_end,
                iteration_gap_counters  = iteration_gap_counters,
                iteration_data          = macro_iter_counters,
                macro_baseline_rows_sum = baseline_sum
            )
            self.write_iteration_reports(
                macro_iter_idx, iteration_metrics, macro_iter_counters
            )

        # 5) FINISH ------------------------------------------------------
        self.generate_final_summary_doc()











    # =========================
    #  C)  Main driver — phase-based
    # =========================
    def run_phase_based_simulation(self):
        """
        Runs the complete DevOps simulation organised as
        • **macro-iterations**  ➜  multiple **phases**  ➜  multiple **mini-iterations**.

        Invariants per macro *N*:
            ID-1  total_open_all(N-1) == carried_over_count(N)
            ID-2  carried_over_count + total_new – total_resolved_this_macro == total_open_all

        v6 patch (2025-05-05):
            • Student DOCX heading hygiene:
                – “Original Client Specifications” emitted once only
                – H1 “Macro Iteration NN” & H2 “Phase: …” guarded so they appear
                  exclusively in the *final* macro-iteration.
            • Teacher DOCX output remains byte-for-byte identical.
        """
        import datetime
        from collections import defaultdict

        # ───────────────────────── configuration ─────────────────────────
        num_macro_iterations = self.sim_config.get("macroIterations", 1)
        phases               = self.sim_config.get("phases", [])

        for macro_iter_idx in range(1, num_macro_iterations + 1):
            iteration_start        = datetime.datetime.now()
            iteration_gap_counters = self.init_gap_counters()

            # ═════════════════════════════════════════════════════════════
            # 1)  SNAPSHOT **immutable** baseline for ID-1
            # 2)  Set up **mutable** working copies for this macro
            # ═════════════════════════════════════════════════════════════
            self._carryover_open_ids_start = set(self.global_open_issue_ids)
            self._carryover_by_type_start  = defaultdict(set)
            for gid in self._carryover_open_ids_start:
                rec   = self.issue_first_seen_iteration.get(gid, {})
                gtype = rec.get("finalGapType", rec.get("initialGapType", "Other"))
                self._carryover_by_type_start[gtype].add(gid)

            # live working copies
            self._carryover_open_ids = set(self._carryover_open_ids_start)
            self._carryover_by_type  = {gt: ids.copy()
                                        for gt, ids in self._carryover_by_type_start.items()}

            # ─────────────────────── student headings ────────────────────
            self._write_client_spec_once()   # emit client specs exactly once
            if self._is_final_macro(macro_iter_idx):
                self.doc.add_heading(f"Macro Iteration {macro_iter_idx:02d}", level=1)

            # teacher headings (always, unchanged)
            self.doc_teacher.add_heading(f"Macro Iteration {macro_iter_idx}", level=1)

            # ─────────────────────── counters & baseline ─────────────────
            macro_iter_counters    = self.initialize_iteration_counters()
            macro_baseline_rows_sum = self.capture_macro_baseline_rows(macro_iter_idx)
            absolute_mini_counter   = 1  # optional global mini index

            # ───────────────────────── phase loop ────────────────────────
            for phase_info in phases:
                phase_name      = phase_info["phaseName"]
                mini_iterations = phase_info.get("miniIterations", 1)
                phase_tables    = phase_info.get("tableList", [])

                # student phase heading only in final macro
                if self._is_final_macro(macro_iter_idx):
                    self.doc.add_heading(f"Phase: {phase_name}", level=2)
                # teacher phase heading always
                self.doc_teacher.add_heading(f"Phase: {phase_name}", level=2)

                for m_iter_idx in range(1, mini_iterations + 1):
                    print(
                        f"Phase '{phase_name}' ⇒ mini {m_iter_idx}/{mini_iterations} "
                        f"(Macro={macro_iter_idx})"
                    )
                    mini_start_time    = datetime.datetime.now()
                    mini_iter_counters = self.initialize_iteration_counters()


                    print(
                        f"retrospective_problem|LOOP|macro={macro_iter_idx}"
                        f"|phase={phase_name}|mini={m_iter_idx}",
                        file=sys.stderr
                    )
                    # ▸▸ process a single mini-iteration
                    self.run_phase_single_pass(
                        macro_iter_idx          = macro_iter_idx,
                        phase_name              = phase_name,
                        mini_iter_idx           = m_iter_idx,
                        phase_tables            = phase_tables,
                        iteration_gap_counters  = iteration_gap_counters,
                        cumulative_iter_counters = iteration_gap_counters,
                        mini_iter_counters      = mini_iter_counters
                    )

                    mini_end_time = datetime.datetime.now()

                    # ▸▸ finalise the mini
                    self.finalize_mini_iteration(
                        macro_iter_idx     = macro_iter_idx,
                        phase_name         = phase_name,
                        mini_iter_idx      = m_iter_idx,
                        start_time         = mini_start_time,
                        end_time           = mini_end_time,
                        mini_iter_counters = mini_iter_counters
                    )

                    # roll mini counters into macro counters
                    self.roll_up_counters(macro_iter_counters, mini_iter_counters)

                    # teacher-doc summary bullet
                    summary_text = self.summarize_lessons_learned_for_mini_iteration(
                        macro_iter_idx, phase_name, m_iter_idx
                    )
                    self.partial_lessons.setdefault(macro_iter_idx, {}) \
                                        .setdefault(phase_name, {})[m_iter_idx] = summary_text

                    self.doc_teacher.add_paragraph(
                        f"(Teacher doc) End of Mini-Iteration {m_iter_idx} "
                        f"(Phase={phase_name}, Macro={macro_iter_idx}):\n{summary_text}",
                        style="List Bullet"
                    )

                    absolute_mini_counter += 1  # advance global mini index
            # ───── end phase loop ─────────────────────────────────────────

            # ensure row-edit totals exist BEFORE metrics are computed
            self.ensure_macro_row_edit_totals(macro_iter_counters)

            iteration_end = datetime.datetime.now()
            iteration_metrics = self.compute_iteration_metrics(
                macro_iter_idx          = macro_iter_idx,
                phase_name              = phases[-1]["phaseName"] if phases else "NoPhases",
                mini_iter_idx           = phases[-1].get("miniIterations", 1) if phases else 1,
                start_time              = iteration_start,
                end_time                = iteration_end,
                iteration_gap_counters  = iteration_gap_counters,
                iteration_data          = macro_iter_counters,
                macro_baseline_rows_sum = macro_baseline_rows_sum
            )

            # write macro-summary CSV row & teacher bullets
            self.write_iteration_reports(macro_iter_idx,
                                         iteration_metrics,
                                         macro_iter_counters)

            # collect per-macro lessons-learned text
            macro_lessons_list = []
            for p_name, mini_dict in self.partial_lessons.get(macro_iter_idx, {}).items():
                for m_i, text in mini_dict.items():
                    macro_lessons_list.append(f"Phase={p_name}, mini={m_i}:\n{text}")
            combined_macro_lessons = "\n--\n".join(macro_lessons_list)
            self.lessons_learned[macro_iter_idx] = combined_macro_lessons

            self.doc_teacher.add_heading(
                f"Lessons Learned (Macro Iteration {macro_iter_idx})", level=2
            )
            self.doc_teacher.add_paragraph(combined_macro_lessons)
        # ───── end macro loop ─────────────────────────────────────────────

        # generate final summary documents (CSV, DOCX, etc.)
        self.generate_final_summary_doc()









    def roll_up_counters(self, macro_iter_counters, mini_iter_counters):
        """
        Aggregates mini_iter_counters into the macro-level counters for the iteration.
        This way, at the end of the entire macro iteration, you have a total count
        across all mini iterations.

        NOTE:
          - We still sum iteration_table_complexity_sum and iteration_defect_complexity_sum below
            so that we do not omit or remove fields. However, these accumulated values
            are NOT used for the final macro table size or macro-level open-defect calculations.
            Instead, compute_iteration_metrics(...) calls get_final_artifact_versions_for_macro(...)
            to get the final artifact size and coverage. The lines below remain solely
            to preserve intermediate or mini-level data sums and avoid code breakage.
        """

        # 1) Accumulate text fragments
        macro_iter_counters["iteration_text_fragments"].extend(
            mini_iter_counters["iteration_text_fragments"]
        )

        # 2) Accumulate table complexity sums (mini-level only, not used for final macro size)
        macro_iter_counters["iteration_table_complexity_sum"] += mini_iter_counters["iteration_table_complexity_sum"]

        # 3) Accumulate trace coverage sums (again, for mini-level roll-up)
        macro_iter_counters["iteration_trace_cov_weighted_sum"] += mini_iter_counters["iteration_trace_cov_weighted_sum"]
        macro_iter_counters["iteration_trace_cov_rows_sum"] += mini_iter_counters["iteration_trace_cov_rows_sum"]

        # 4) Accumulate row edits
        macro_iter_counters["iteration_added_rows_sum"] += mini_iter_counters["iteration_added_rows_sum"]
        macro_iter_counters["iteration_removed_rows_sum"] += mini_iter_counters["iteration_removed_rows_sum"]
        macro_iter_counters["iteration_changed_rows_sum"] += mini_iter_counters["iteration_changed_rows_sum"]

        # 5) Accumulate open-defect sums (for mini-level usage)
        macro_iter_counters["iteration_defect_issues_sum"] += mini_iter_counters["iteration_defect_issues_sum"]
        macro_iter_counters["iteration_defect_complexity_sum"] += mini_iter_counters["iteration_defect_complexity_sum"]

        # 6) Accumulate row baseline for churn calculations (mini-level perspective)
        macro_iter_counters["iteration_rows_sum_for_churn"] += mini_iter_counters["iteration_rows_sum_for_churn"]





    def run_phase_single_pass(
        self,
        macro_iter_idx,
        phase_name,
        mini_iter_idx,
        phase_tables,
        iteration_gap_counters,
        cumulative_iter_counters,
        mini_iter_counters
    ):
        """
        Processes every artifact in *phase_tables* for the tuple
        (macro_iter_idx, phase_name, mini_iter_idx), maintaining all gap
        invariants.

        v6 patch (2025-05-05):
            • Student DOCX writes an H3 + table **only** when the current
              pass is the final mini-iteration of the final macro.
            • The stray paragraph “ARTIDX: …” is removed; index & name are
              folded into the H3 heading text.
            • All issue-tracking metrics, teacher-doc bullets, and CSV
              writes remain unchanged.
        """
        import datetime

        self.current_mini_start_time = datetime.datetime.now()

        # ──────────────────────────────────────────────────────────
        # (A) bring forward unresolved gaps (Problem #7)
        # ──────────────────────────────────────────────────────────
        self.apply_global_unresolved_issues(macro_iter_idx, phase_name, mini_iter_idx)

        # (B) record open-set snapshot at mini start (Problem #8)
        current_open_start = self.get_current_open_issue_ids()
        self.pre_mini_open_issues[(macro_iter_idx, phase_name, mini_iter_idx)] = current_open_start

        # filter artifacts belonging to this phase
        current_table_list = [
            t for t in self.tables if t["Artifact_index"] in phase_tables
        ]

        # (C) track “brand-new” gaps in *this* mini (Problem #10)
        discovered_new_issues_in_this_mini = set()

        # ───────── artifact loop ─────────────────────────────────
        for table_info in current_table_list:
            artifact_index = table_info["Artifact_index"]
            artifact_name  = table_info["Artifact_name"]

            # 1) process the artifact
            artifact_result = self.process_single_artifact(
                macro_iter_idx          = macro_iter_idx,
                phase_name              = phase_name,
                mini_iter_idx           = mini_iter_idx,
                table_info              = table_info,
                iteration_gap_counters  = iteration_gap_counters,
                cumulative_iter_counters = cumulative_iter_counters
            )
            self.update_global_unresolved_issues(macro_iter_idx, phase_name, mini_iter_idx)

            # 2) accumulate metrics
            self.accumulate_artifact_metrics(mini_iter_counters, artifact_result)

            # 3) write to STUDENT DOCX  (v6 guarded + paragraph removed)
            if self._is_latest_artifact_pass(macro_iter_idx,
                                             phase_name,
                                             mini_iter_idx):
                self.doc.add_heading(
                    f"Artifact {artifact_index} final (mini {mini_iter_idx:02d}) — {artifact_name}",
                    level=3
                )
                self.add_json_as_docx_table(
                    self.doc, artifact_result["parsed_artifact"]
                )

            # 4) teacher-doc bullet (unchanged)
            self.doc_teacher.add_paragraph(
                f"Artifact: {artifact_index}, Phase={phase_name}, mini_iter={mini_iter_idx}",
                style="List Bullet"
            )
            self.record_artifact_issues_in_teacher_doc(
                macro_iter_idx, phase_name, mini_iter_idx, artifact_index
            )

            # (D) de-duplicate “new” gaps within the mini (Problem #10)
            newly_found_list = artifact_result.get("newly_found_issue_ids", [])
            corrected_new_count = 0
            for gid in newly_found_list:
                if gid not in discovered_new_issues_in_this_mini:
                    discovered_new_issues_in_this_mini.add(gid)
                    corrected_new_count += 1
            artifact_result["new_issues_for_artifact"] = corrected_new_count

            # 5) compute defect density
            diff_info      = artifact_result["diff_info"]
            table_complex  = artifact_result["table_complex"]
            open_count     = artifact_result["open_issues_for_artifact"]
            defect_density = round(open_count / table_complex, 3) if table_complex > 0 else 0

            # 6) log artifact-level metrics to CSV
            self.log_artifact_metrics_to_csv(
                macro_iter_idx  = macro_iter_idx,
                phase_name      = phase_name,
                mini_iter_idx   = mini_iter_idx,
                artifact_index  = artifact_index,
                artifact_result = artifact_result,
                iteration_gap_counters = iteration_gap_counters,
                diff_info       = diff_info,
                defect_density  = defect_density
            )
        # ───── end artifact loop ────────────────────────────────────────

        # (F) finalise the mini-iteration
        mini_key = (macro_iter_idx, phase_name, mini_iter_idx)
        self.new_ids_in_mini[mini_key]        = set(discovered_new_issues_in_this_mini)
        self.open_ids_at_end_of_mini[mini_key] = set(self.global_open_issue_ids)

        mini_end_time = datetime.datetime.now()
        self.finalize_mini_iteration(
            macro_iter_idx     = macro_iter_idx,
            phase_name         = phase_name,
            mini_iter_idx      = mini_iter_idx,
            start_time         = self.current_mini_start_time,
            end_time           = mini_end_time,
            mini_iter_counters = mini_iter_counters
        )








    def process_single_artifact(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        table_info: dict,
        iteration_gap_counters: dict,
        cumulative_iter_counters: dict
    ) -> dict:
        """
        Fetches and processes a single artifact via LLM, then merges new issues.
        Uses the 3D iteration structure: (macro_iter_idx, phase_name, mini_iter_idx).

        Steps:
          0) Identify the artifact and retrieve its prior version if any.
          1) Prompt the LLM to fetch/update this artifact (fetch_and_update_artifact).
          2) Calculate artifact metrics (textual, table, trace).
          3) Gather newly identified issues via teacher review.
          4) Merge new issues with existing ones (deduplicate) -- returns both final issues & newly_created_ids.
          5) Identify old open issues from previous iteration, possibly verify partial fixes.
          6) Update statuses (verify_open_issues_against_new_artifact + merge_verification_results).
          7) Update counters for new/known/inprogress/resolved.
          8) Compare with previous version for row-level diffs.
          9) Mark this artifact as last updated now.
          10) Store the updated artifact in artifact_versions.
          11) Return final artifact metrics (including open/new issue counts for densities).

        Returns a dict with keys such as:
          {
            "parsed_artifact": ...,
            "artifact_text_str": ...,
            "lexical_density": float,
            "unique_term_ratio": float,
            "table_complex": int,
            "trace_cov": float,
            "diff_info": {"added":..., "removed":..., "changed":...},
            "open_issues_for_artifact": int,
            "new_issues_for_artifact": int,
            "newly_found_issue_ids": [...],
            ...
          }

        This final version has no references to 'absolute_mini_idx' or unneeded dynamic counters.
        """

        # 0) Identify this artifact and possibly retrieve its prior version
        artifact_index = table_info["Artifact_index"]

        last_updated = self.last_artifact_update.get(artifact_index, None)
        if last_updated is not None:
            prev_macro_iter_idx, prev_phase_name, prev_mini_iter_idx = last_updated
            prev_artifact_dict = (
                self.artifact_versions
                    .get(prev_macro_iter_idx, {})
                    .get(prev_phase_name, {})
                    .get(prev_mini_iter_idx, {})
                    .get(artifact_index, {})
            )
        else:
            # It's never been updated before
            prev_artifact_dict = {}

        # 1) Prompt the LLM to fetch/update this artifact
        parsed_artifact, table_dependencies_text = self.fetch_and_update_artifact(
            macro_iter_idx=macro_iter_idx,
            phase_name=phase_name,
            mini_iter_idx=mini_iter_idx,
            table_info=table_info,
            previous_artifact_dict=prev_artifact_dict
        )

        # 2) Calculate artifact metrics (lexical density, unique terms, table complexity, trace coverage)
        metrics = self.calculate_all_artifact_metrics(parsed_artifact, artifact_index)
        artifact_json_str = json.dumps(parsed_artifact, indent=2)
        artifact_text_str = metrics["artifact_text_str"]

        # 3) Gather newly identified issues by teacher review
        new_issues_this_artifact = self.teacher_review_and_new_issues(
            macro_iter_idx=macro_iter_idx,
            phase_name=phase_name,
            mini_iter_idx=mini_iter_idx,
            artifact_index=artifact_index,
            artifact_json_str=artifact_json_str,
            table_dependencies_text=table_dependencies_text
        )

        # ── DEBUG ── confirm we got here and how many blank-gapID issues we have
        print(
            f"BEFORE-MERGE {artifact_index} "
            f"{len(new_issues_this_artifact)}"
        )

        # 4) Merge these new issues with existing ones (deduplicate).
        #    IMPORTANT: we now capture BOTH final issues and newly_created_ids
        final_issues_unified, newly_created_ids = self.verify_and_merge_issues(
            macro_iter_idx=macro_iter_idx,
            phase_name=phase_name,
            mini_iter_idx=mini_iter_idx,
            artifact_index=artifact_index,
            artifact_text=artifact_json_str,
            new_issues_this_artifact=new_issues_this_artifact
        )
        # (A) Store the final merged list back into feedback_storage so the next steps see them:
        self.feedback_storage \
            .setdefault(macro_iter_idx, {}) \
            .setdefault(phase_name, {}) \
            .setdefault(mini_iter_idx, {})[artifact_index] = final_issues_unified

        # (B) Make sure brand-new gapIDs are marked as "NewIssue" in the master record
        #     so they won't vanish when we update the global backlog later.
        for gap_id in newly_created_ids:
            if gap_id in self.issue_first_seen_iteration:
                # Force the status to "NewIssue" if it's missing
                self.issue_first_seen_iteration[gap_id]["status"] = "NewIssue"
            else:
                # Fallback if you somehow never initialized the record
                self.issue_first_seen_iteration[gap_id] = {
                    "status": "NewIssue",
                    "firstSeen": (macro_iter_idx, phase_name, mini_iter_idx),
                    "shortDescription": "(New issue, no description found?)"
                }
        # 5) Identify old open issues from previous iterations, possibly verify partial fixes
        old_open_issues = []
        for iss in final_issues_unified:
            gid = iss["gapID"]
            status_now = iss.get("knownIssue", "NewIssue")

            # Check when it was first seen
            first_seen_tuple = self.issue_tracker.get_first_seen_iteration(gid)
            if first_seen_tuple:
                first_macro, first_phase, first_mini = first_seen_tuple
            else:
                first_macro, first_phase, first_mini = (macro_iter_idx, phase_name, mini_iter_idx)

            # We'll say it's "strictly earlier" if macro < current, or same macro + earlier phase or mini
            strictly_earlier = False
            if first_macro < macro_iter_idx:
                strictly_earlier = True
            elif first_macro == macro_iter_idx:
                if self.phase_index_map[first_phase] < self.phase_index_map[phase_name]:
                    strictly_earlier = True
                elif (self.phase_index_map[first_phase] == self.phase_index_map[phase_name]
                      and first_mini < mini_iter_idx):
                    strictly_earlier = True

            # If it's from an earlier iteration or is already InProgress, track it
            if (strictly_earlier or status_now == "InProgress") and status_now in ["NewIssue", "KnownIssue", "InProgress"]:
                old_open_issues.append(iss)

        if old_open_issues:
            # 6) Verify if these old open issues are resolved or partially resolved in this artifact
            verification_results = self.verify_open_issues_against_new_artifact(
                macro_iter_idx=macro_iter_idx,
                phase_name=phase_name,
                mini_iter_idx=mini_iter_idx,
                artifact_text=artifact_json_str,
                open_issues=old_open_issues
            )
            # Merge verification results back
            self.merge_verification_results(
                macro_iter_idx=macro_iter_idx,
                phase_name=phase_name,
                mini_iter_idx=mini_iter_idx,
                artifact_index=artifact_index,
                open_issues=old_open_issues,
                verification_results=verification_results,
                new_issues_this_artifact=[]
            )
            # Refresh final_issues_unified after merges
            final_issues_unified = (
                self.feedback_storage[macro_iter_idx][phase_name][mini_iter_idx][artifact_index]
            )

        # 7) Update iteration-level counters for new/known/inprogress/resolved
        artifact_gap_counters, total_issues_for_artifact = self.update_gap_counters(
            final_issues_unified,
            iteration_gap_counters,
            cumulative_iter_counters
        )

        # Compute open/new issues for artifact-based defect densities
        # (This is your original approach for "open" and "new" counts, from the gap_counters.)
        open_issues_for_artifact = 0
        new_issues_for_artifact = 0
        for gtype in self.gap_types:
            # open = sum of new + known + inprogress
            open_issues_for_artifact += sum(
                artifact_gap_counters[gtype][st][imp]
                for st in ["NewIssue", "KnownIssue", "InProgress"]
                for imp in self.impacts
            )
            # newly discovered (but can be used if you still want the "macro-level new" definition)
            new_issues_for_artifact += sum(
                artifact_gap_counters[gtype]["NewIssue"][imp]
                for imp in self.impacts
            )

        # 8) Compare with previous version for row-level diffs
        if last_updated is not None:
            diff_info = MetricsCalculator.diff_artifacts(
                prev_artifact_dict,
                parsed_artifact,
                self.artifact_key_map.get(artifact_index, "Req ID")
            )
        else:
            diff_info = {"added": [], "removed": [], "changed": []}

        # 9) Mark this artifact as last updated
        self.last_artifact_update[artifact_index] = (macro_iter_idx, phase_name, mini_iter_idx)

        # 10) Store the updated artifact in artifact_versions
        self.artifact_versions \
            .setdefault(macro_iter_idx, {}) \
            .setdefault(phase_name, {}) \
            .setdefault(mini_iter_idx, {})[artifact_index] = parsed_artifact

        # 11) Return final artifact metrics, including the brand-new gap IDs from dedup
        #     so your run_phase_single_pass(...) can avoid double-counting them.
        return {
            "parsed_artifact": parsed_artifact,
            "artifact_text_str": artifact_text_str,
            "lexical_density": metrics["lexical_density"],
            "unique_term_ratio": metrics["unique_term_ratio"],
            "table_complex": metrics["table_complex"],
            "trace_cov": metrics["trace_cov"],
            "diff_info": diff_info,
            "total_issues_for_artifact": total_issues_for_artifact,
            "open_issues_for_artifact": open_issues_for_artifact,
            "new_issues_for_artifact": new_issues_for_artifact,
            "newly_found_issue_ids": newly_created_ids
        }









    def log_artifact_metrics_to_csv(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        artifact_index: str,
        artifact_result: dict,
        iteration_gap_counters: dict,
        diff_info: dict,
        defect_density: float
    ):
        """
        Logs artifact-level metrics to iteration_metrics.csv, including churn, defect densities,
        carried-over issues, and gap-type counts. Ensures NewIssueCount is taken from
        artifact_result["new_issues_for_artifact"] to avoid double-counting.

        Columns (in order):
        [
          "MacroIteration",
          "PhaseName",
          "MiniIteration",
          "ArtifactIndex",
          "LexicalDensity",
          "UniqueTermRatio",
          "TableComplexity",
          "TraceabilityCoverage",
          "RowsAdded",
          "RowsRemoved",
          "RowsModified",
          "ChurnPercent",
          "OpenIssueCount",
          "NewIssueCount",  # corrected count
          "KnownIssueCount",
          "InProgressIssueCount",
          "ResolvedIssueCount",
          "DefectDensity",
          "NewDefectDensity",
          "CriticalDefectDensity",
          "HighDefectDensity",
          "MediumDefectDensity",
          "LowDefectDensity",
          "CarriedOverCount",
          "MissedReqCount",
          "SecurityGapCount",
          "ComplianceGapCount",
          "PerformanceGapCount",
          "UsabilityGapCount",
          "OtherGapCount"
        ]

        Parameters
        ----------
        macro_iter_idx : int
            Macro iteration index (e.g. 1, 2).
        phase_name : str
            Name of the current phase (e.g. "Requirements").
        mini_iter_idx : int
            Index of the mini-iteration within the phase.
        artifact_index : str
            Identifier for the current artifact.
        artifact_result : dict
            Contains key metrics (parsed artifact, new_issues_for_artifact, etc.).
        iteration_gap_counters : dict
            Optional counters for cross-checking issues (not strictly required).
        diff_info : dict
            Dictionary of row-level differences: "added", "removed", "changed".
        defect_density : float
            Open-based defect density (open_count / table_complex).

        Returns
        -------
        None
            Writes exactly one row of metrics to iteration_metrics.csv.
        """

        # --------------------------------------
        # (0) Prepare row_data & artifact fields
        # --------------------------------------
        row_data = []

        # (A) Basic iteration info
        row_data.append(macro_iter_idx)       # MacroIteration
        row_data.append(phase_name)           # PhaseName
        row_data.append(mini_iter_idx)        # MiniIteration
        row_data.append(str(artifact_index))  # ArtifactIndex

        # Extract relevant metrics from artifact_result
        parsed_artifact   = artifact_result["parsed_artifact"]
        lexical_density   = artifact_result.get("lexical_density", 0.0)
        unique_term_ratio = artifact_result.get("unique_term_ratio", 0.0)
        table_complex     = artifact_result.get("table_complex", 0)
        trace_cov         = artifact_result.get("trace_cov", 0.0) or 0.0

        # --------------------------------------
        # (B) Text & table complexity columns
        # --------------------------------------
        row_data.append(lexical_density)    # LexicalDensity
        row_data.append(unique_term_ratio)  # UniqueTermRatio
        row_data.append(table_complex)      # TableComplexity
        row_data.append(trace_cov)          # TraceabilityCoverage

        # --------------------------------------
        # (C) Row changes & churn
        # --------------------------------------
        this_diff_info = artifact_result.get("diff_info", diff_info)
        added_rows   = len(this_diff_info.get("added", []))
        removed_rows = len(this_diff_info.get("removed", []))
        changed_rows = len(this_diff_info.get("changed", []))

        current_rows = len(parsed_artifact.get("rows", []))
        prev_row_count = current_rows + removed_rows - added_rows
        if prev_row_count < 1:
            prev_row_count = 1  # avoid zero-division

        churn_percent = round(
            (added_rows + removed_rows + changed_rows) / prev_row_count * 100,
            2
        )

        row_data.append(added_rows)       # RowsAdded
        row_data.append(removed_rows)     # RowsRemoved
        row_data.append(changed_rows)     # RowsModified
        row_data.append(churn_percent)    # ChurnPercent

        # --------------------------------------
        # (D) Issue counts in this artifact
        # --------------------------------------
        # For the new-issue count, we rely on artifact_result["new_issues_for_artifact"] (Problem #10 fix)

        # Retrieve the final issues from feedback_storage for this artifact
        final_issues = (
            self.feedback_storage
                .get(macro_iter_idx, {})
                .get(phase_name, {})
                .get(mini_iter_idx, {})
                .get(artifact_index, [])
        )

        open_count       = 0
        known_count      = 0
        inprogress_count = 0
        resolved_count   = 0

        # The already-corrected new-issue count from run_phase_single_pass
        new_count = artifact_result.get("new_issues_for_artifact", 0)

        # Tally statuses for open/known/inprogress/resolved
        for iss in final_issues:
            st = iss.get("knownIssue", "NewIssue")
            if st in ["NewIssue", "KnownIssue", "InProgress"]:
                open_count += 1
            if st == "KnownIssue":
                known_count += 1
            if st == "InProgress":
                inprogress_count += 1
            if st == "Resolved":
                resolved_count += 1

        row_data.append(open_count)        # OpenIssueCount
        row_data.append(new_count)         # NewIssueCount (from artifact_result!)
        row_data.append(known_count)       # KnownIssueCount
        row_data.append(inprogress_count)  # InProgressIssueCount
        row_data.append(resolved_count)    # ResolvedIssueCount

        # --------------------------------------
        # (E) Defect densities
        # --------------------------------------
        #  - defect_density: open_count / table_complex
        #  - newDefectDensity: new_count / table_complex
        #  - severity-based densities

        new_defect_density = 0.0
        if table_complex > 0:
            new_defect_density = round(new_count / table_complex, 3)

        critical_open = 0
        high_open     = 0
        med_open      = 0
        low_open      = 0

        for iss in final_issues:
            st = iss.get("knownIssue", "NewIssue")
            if st in ["NewIssue", "KnownIssue", "InProgress"]:
                sev = iss.get("impact", "Medium").lower()
                if   sev == "critical":
                    critical_open += 1
                elif sev == "high":
                    high_open     += 1
                elif sev == "medium":
                    med_open      += 1
                else:
                    low_open      += 1

        critical_defect_density = 0.0
        high_defect_density     = 0.0
        medium_defect_density   = 0.0
        low_defect_density      = 0.0

        if table_complex > 0:
            critical_defect_density = round(critical_open / table_complex, 3)
            high_defect_density     = round(high_open   / table_complex, 3)
            medium_defect_density   = round(med_open    / table_complex, 3)
            low_defect_density      = round(low_open    / table_complex, 3)

        row_data.append(defect_density)            # Overall defect_density
        row_data.append(new_defect_density)        # NewDefectDensity
        row_data.append(critical_defect_density)   # CriticalDefectDensity
        row_data.append(high_defect_density)       # HighDefectDensity
        row_data.append(medium_defect_density)     # MediumDefectDensity
        row_data.append(low_defect_density)        # LowDefectDensity

        # --------------------------------------
        # (F) CarriedOverCount
        # --------------------------------------
        # Simple approach: how many issues were open in the previous mini of this artifact?

        prev_iter = self.find_previous_mini_key(macro_iter_idx, phase_name, mini_iter_idx)
        old_open_issues = []
        if prev_iter is not None:
            pmacro, pphase, pmini = prev_iter
            prev_art_issues = (
                self.feedback_storage
                    .get(pmacro, {})
                    .get(pphase, {})
                    .get(pmini, {})
                    .get(artifact_index, [])
            )
            for old_iss in prev_art_issues:
                if old_iss.get("knownIssue") in ["NewIssue", "KnownIssue", "InProgress"]:
                    old_open_issues.append(old_iss["gapID"])

        carried_over_count = len(old_open_issues)

        # --------------------------------------
        # (G) Per-gap-type counts
        # --------------------------------------
        recognized_gap_types = [
            "MissedRequirement",
            "SecurityGap",
            "ComplianceGap",
            "PerformanceGap",
            "UsabilityGap",
            "Other"
        ]
        gap_type_counts = {gt: 0 for gt in recognized_gap_types}

        for iss in final_issues:
            gtype = iss.get("gapType", "Other")
            if gtype not in recognized_gap_types:
                gtype = "Other"
            gap_type_counts[gtype] += 1

        missed_req_count   = gap_type_counts["MissedRequirement"]
        security_gap_count = gap_type_counts["SecurityGap"]
        compliance_count   = gap_type_counts["ComplianceGap"]
        performance_count  = gap_type_counts["PerformanceGap"]
        usability_count    = gap_type_counts["UsabilityGap"]
        other_gap_count    = gap_type_counts["Other"]

        # --------------------------------------
        # (H) Append new columns to row_data
        # --------------------------------------
        row_data.append(carried_over_count)    # CarriedOverCount
        row_data.append(missed_req_count)      # MissedReqCount
        row_data.append(security_gap_count)    # SecurityGapCount
        row_data.append(compliance_count)      # ComplianceGapCount
        row_data.append(performance_count)     # PerformanceGapCount
        row_data.append(usability_count)       # UsabilityGapCount
        row_data.append(other_gap_count)       # OtherGapCount

        # --------------------------------------
        # (I) Write the final row to CSV
        # --------------------------------------
        self.csv_writer.writerow(row_data)












    ###############################################

    ###############################################

    def init_gap_counters(self):
        d = {}
        for gtype in self.gap_types:
            d[gtype] = {}
            for st in self.statuses_to_count:
                d[gtype][st] = {}
                for imp in self.impacts:
                    d[gtype][st][imp] = 0
        return d





    def gather_dependencies_as_json(self, artifact_index: str) -> dict:
        """
        Return a JSON-like dict with:
          - 'clientSpec': main client specs
          - 'dependencies': list of each dependency's artifact data
            (artifactIndex, artifactName, columns, rows).
        """

        result = {
            "clientSpec": self.client_specifications,
            "dependencies": []
        }

        dep_list = self.dependencies_map.get(artifact_index, [])
        for dep_idx in dep_list:
            # If we don't have a record for this dependency, skip or fallback
            if dep_idx not in self.last_artifact_update:
                result["dependencies"].append({
                    "artifactIndex": dep_idx,
                    "artifactName": "(No record yet)",
                    "columns": [],
                    "rows": []
                })
                continue

            # figure out which iteration stored the final version:
            (dep_macro, dep_phase, dep_mini) = self.last_artifact_update[dep_idx]

            # retrieve that final artifact
            dep_art = (
                self.artifact_versions
                    .get(dep_macro, {})
                    .get(dep_phase, {})
                    .get(dep_mini, {})
                    .get(dep_idx, {})
            )

            # gracefully read fields if present
            art_name = dep_art.get("artifactName", "Unknown Name")
            cols     = dep_art.get("columns", [])
            rows     = dep_art.get("rows", [])

            result["dependencies"].append({
                "artifactIndex": dep_idx,
                "artifactName": art_name,
                "columns": cols,
                "rows": rows
            })

        return result



    def calculate_all_artifact_metrics(self, parsed_artifact, artifact_index):
        """
        Consolidated method to calculate all relevant metrics for an artifact.
        """
        artifact_text_str = self.extract_artifact_text(parsed_artifact)
        lexical_density = MetricsCalculator.calculate_lexical_density(artifact_text_str)
        unique_term_ratio = MetricsCalculator.calculate_unique_term_ratio(artifact_text_str)
        table_complex = MetricsCalculator.measure_table_complexity(parsed_artifact)

        trace_col = self.artifact_trace_column_map.get(artifact_index, "Related Reqs")
        trace_cov = MetricsCalculator.measure_traceability_coverage(parsed_artifact, req_column=trace_col)

        return {
            "artifact_text_str": artifact_text_str,
            "lexical_density": lexical_density,
            "unique_term_ratio": unique_term_ratio,
            "table_complex": table_complex,
            "trace_cov": trace_cov
        }

    def highlight_critical_issues(self, issues_list):
        """
        Bullet list for the prompt header.
        Each line now includes GapID and recommendation.
        """
        critical_lines = []
        for iss in issues_list:
            sev = iss.get("impact", "").lower()
            if sev in {"critical", "high"}:
                gid  = iss.get("gapID", "")
                desc = iss.get("shortDescription", "(no desc)")
                rec  = iss.get("recommendation", "").strip()

                bullet = f"- {sev.upper()} Issue: "
                if gid:
                    bullet += f"GapID={gid}: "
                bullet += desc
                if rec:
                    bullet += f" → {rec}"
                critical_lines.append(bullet)

        if not critical_lines:
            return "No critical/high severity issues known."

        return (
            "IMPORTANT: These CRITICAL/HIGH-SEVERITY issues remain unresolved and MUST be addressed:\n"
            + "\n".join(critical_lines) +
            "\n☐ Mark each bullet **[RESOLVED]** internally before submitting.\n"
        )

    ########################################################################
    # 1) Minimal helper to add columns to an existing artifact (table).
    ########################################################################
    def add_columns_to_table(self, artifact_index: str, new_cols: list[str]) -> None:
        """
        Append each entry in *new_cols* (case-insensitive, trimmed) to the column
        list of every table whose Artifact_index == *artifact_index*.

        Behaviour notes
        ---------------
        • Existing order is preserved; new columns are appended in the order
          given, but only if they are not case-duplicate of an existing one.
        • If several tables share the same Artifact_index, all are updated and a
          warning is printed (data hygiene).
        • For each updated table:
            – the Artifact_columns string is modified **in-place**,
            – every dict row in Sample Data Rows gains the new key with
              placeholder ``"TBD – added per lessons learned"`` unless it already
              exists.
        • If no table matches *artifact_index*, a warning is printed and the
          function returns.
        """
        import csv

        PLACEHOLDER = "TBD – added per lessons learned"

        # --- 0) find matching tables -----------------------------------------
        matches = [tbl for tbl in self.tables
                  if tbl.get("Artifact_index") == artifact_index]

        if not matches:
            print(f"WARNING: Could not find artifact {artifact_index} "
                  f"to add columns {new_cols}")
            return

        if len(matches) > 1:
            print(f"WARNING: {len(matches)} tables share index {artifact_index}; "
                  f"updating all of them.")

        # --- 1) normalise the requested column list once ---------------------
        new_cols_clean = [str(c).strip() for c in new_cols if str(c).strip()]

        nothing_added_anywhere = True

        for tbl in matches:
            # a) current columns (robust CSV split → handles commas in quotes)
            cur_cols_raw = tbl.get("Artifact_columns", "")
            cur_cols     = next(csv.reader([cur_cols_raw]))
            cur_cols     = [c.strip() for c in cur_cols if c.strip()]
            cur_cols_lc  = {c.lower() for c in cur_cols}

            # b) filter genuinely new columns
            appended = []
            for nc in new_cols_clean:
                if nc.lower() not in cur_cols_lc:
                    cur_cols.append(nc)
                    cur_cols_lc.add(nc.lower())
                    appended.append(nc)

            if not appended:
                continue  # try next matching table

            nothing_added_anywhere = False

            # c) update Artifact_columns string
            updated_col_str = ", ".join(c.strip() for c in cur_cols)
            print(f"DEBUG: Updating columns for {artifact_index} "
                  f"from '{cur_cols_raw}' to '{updated_col_str}'")
            tbl["Artifact_columns"] = updated_col_str

            # d) seed placeholder values in sample data
            if isinstance(tbl.get("Sample Data Rows"), list):
                for row in tbl["Sample Data Rows"]:
                    if isinstance(row, dict):
                        for col in appended:
                            row.setdefault(col, PLACEHOLDER)

        # --- 2) single informational message if nothing changed --------------
        if nothing_added_anywhere:
            print(f"INFO: No new columns needed for artifact {artifact_index}")





    def get_current_open_issue_ids(self) -> set:
        """
        Returns a set of all gapIDs whose status is still in [NewIssue, KnownIssue, InProgress].
        This is the global 'open' set as per self.issue_first_seen_iteration.
        """
        open_ids = set()
        for gap_id, record in self.issue_first_seen_iteration.items():
            if not isinstance(record, dict):
                # skip any invalid or legacy tuple
                continue
            current_status = record.get("status", "NewIssue")
            if current_status in ["NewIssue", "KnownIssue", "InProgress"]:
                open_ids.add(gap_id)
        return open_ids

    ########################################################################
    # 2) Minimal helper to add a new artifact (table) into self.tables.
    ########################################################################
    def add_new_table(self,
                      row_number: int,
                      artifact_index: str,
                      artifact_name: str,
                      artifact_type: str,
                      artifact_columns: str,
                      obligatory_rows: str = "",
                      custom_instructions: str = "",
                      depends_on: list = None):
        """
        Creates a new artifact definition (table) and appends it to self.tables.
        Also updates self.dependencies_map if 'depends_on' is non-empty.
        """
        if depends_on is None:
            depends_on = []

        new_table = {
            "row_number": row_number,
            "Artifact_index": artifact_index,
            "Artifact_name": artifact_name,
            "Artifact_type": artifact_type,
            "Artifact_columns": artifact_columns,
            "Obligatory_rows": obligatory_rows,
            "custom_instructions": custom_instructions
        }
        self.tables.append(new_table)
        if depends_on:
            self.dependencies_map[artifact_index] = depends_on
        print(f"DEBUG: Added new table {artifact_index} with columns '{artifact_columns}'")

    ########################################################################
    # 3) Helper to *append* instructions instead of replacing them completely
    ########################################################################
    def modify_artifact_instructions(
        self,
        artifact_index: str,
        new_instructions: str,
        separator: str = "  \n"           # Markdown line-break keeps lines readable
    ) -> None:
        """
        Append *new_instructions* to the existing ``custom_instructions`` field
        of the artifact whose ``Artifact_index`` == *artifact_index*.

        • If the same sentence/paragraph (ignoring case & extra spaces) already
          exists, it will NOT be added again (idempotent).
        • A configurable *separator* (default = Markdown line-break) is inserted
          between the old and the new part.
        """
        norm = lambda s: " ".join(s.lower().split())            # quick-and-dirty normaliser

        for tbl in self.tables:
            if tbl.get("Artifact_index") == artifact_index:
                old_instr = tbl.get("custom_instructions", "").rstrip()
                if not old_instr:                                # nothing yet → simple assign
                    tbl["custom_instructions"] = new_instructions.strip()
                    print(f"INFO: Set instructions for {artifact_index}")
                    return

                if norm(new_instructions) in norm(old_instr):
                    print(f"INFO: Instruction for {artifact_index} already contains the new text – skipped")
                    return

                tbl["custom_instructions"] = (
                    f"{old_instr}{separator}{new_instructions.strip()}"
                )
                print(
                    f"INFO: Appended new instructions to {artifact_index}. "
                    f"Length now = {len(tbl['custom_instructions'])} chars"
                )
                return

        print(f"WARNING: Could not find artifact {artifact_index} to update instructions")


    def initialize_iteration_counters(self):
        """
        Initializes a dictionary to keep track of iteration-wide sums
        for table complexity, coverage, row changes, etc.
        """
        return {
            "iteration_text_fragments": [],
            "iteration_table_complexity_sum": 0,
            "iteration_trace_cov_weighted_sum": 0,
            "iteration_trace_cov_rows_sum": 0,
            "iteration_added_rows_sum": 0,
            "iteration_removed_rows_sum": 0,
            "iteration_changed_rows_sum": 0,
            "iteration_defect_issues_sum": 0,
            "iteration_defect_complexity_sum": 0,
            "iteration_rows_sum_for_churn": 0
        }

    @staticmethod
    def add_json_as_docx_table(doc: Document, artifact_data: dict):
        """
        Convert a parsed artifact JSON (dictionary) into a docx table.
        """
        columns = artifact_data.get("columns", [])
        rows = artifact_data.get("rows", [])

        if not columns:
            doc.add_paragraph("No columns defined or invalid JSON artifact.")
            return

        table = doc.add_table(rows=1, cols=len(columns))
        hdr_cells = table.rows[0].cells
        for i, col_name in enumerate(columns):
            hdr_cells[i].text = col_name

        for row_dict in rows:
            row_cells = table.add_row().cells
            for j, col_name in enumerate(columns):
                cell_value = str(row_dict.get(col_name, ""))
                row_cells[j].text = cell_value

    def extract_artifact_text(self, artifact_dict):
        """
        Merge all textual columns in the artifact into a single string.
        """
        text_fragments = []
        for row in artifact_dict.get("rows", []):
            for col_val in row.values():
                text_fragments.append(str(col_val))
        return " ".join(text_fragments)




    def teacher_review_and_new_issues(
        self,
        macro_iter_idx: int,
        phase_name,
        mini_iter_idx: int,
        artifact_index: str,
        artifact_json_str: str,
        table_dependencies_text: str
    ) -> list:
        """
        Queries the teacher LLM to review the current artifact for new issues, providing
        artifact-specific context (FR-7), excluding same-mini cross-artifact issues (NFR-5),
        and ignoring verbose history to prevent output explosion.

        This version includes a cross-phase fallback so that unresolved issues carry forward
        even if the artifact index changed in the next phase. If no issues are found under
        the exact same artifact in the previous iteration, we gather *all* open issues from
        the previous iteration’s entire feedback_storage, marking them “KnownIssue.”

        Parameters
        ----------
        self : DevOpsSimulation
            The simulation instance, containing feedback_storage and related data.
        macro_iter_idx : int
            The current macro iteration number.
        phase_name : str
            The name of the current phase (e.g., "Initiating", "FeasibilityStudy").
        mini_iter_idx : int
            The mini-iteration index within this phase.
        artifact_index : str
            The artifact key (e.g., "1.1.1.1").
        artifact_json_str : str
            JSON string of the current artifact content.
        table_dependencies_text : str
            A text description of any relevant dependencies to be presented to the LLM.

        Returns
        -------
        list
            A list of newly identified issues from the teacher LLM, to be merged/deduplicated afterward.
        """

        def get_previous_phase_and_mini(macro_i, phase_n, mini_i):
            """
            Returns (prev_macro, prev_phase, prev_mini) for the iteration immediately before
            (macro_i, phase_n, mini_i), or None if we are at the very start.
            This logic matches your standard approach to stepping backward in phase/mini.
            """
            phases_list = [p["phaseName"] for p in self.sim_config.get("phases", [])]
            if not phases_list:
                # No real phases => single-phase "Backcompat" fallback
                if mini_i > 1:
                    return (macro_i, phase_n or "Backcompat", mini_i - 1)
                elif macro_i > 1:
                    return (macro_i - 1, phase_n or "Backcompat", 1)
                else:
                    return None

            if mini_i > 1:
                return (macro_i, phase_n, mini_i - 1)
            else:
                # mini_iter_idx == 1 => go back to final mini of previous phase or previous macro
                try:
                    idx = phases_list.index(phase_n)
                except ValueError:
                    return None

                if idx > 0:
                    prev_phase_name = phases_list[idx - 1]
                    last_mini_prev_phase = self.sim_config["phases"][idx - 1].get("miniIterations", 1)
                    return (macro_i, prev_phase_name, last_mini_prev_phase)
                elif macro_i > 1:
                    prev_macro = macro_i - 1
                    last_phase_info = self.sim_config["phases"][-1]
                    return (prev_macro, last_phase_info["phaseName"], last_phase_info.get("miniIterations", 1))
                else:
                    return None

        # ----------------------------------------------------------
        # (A) Find the previous iteration tuple
        # ----------------------------------------------------------
        prev_iteration = get_previous_phase_and_mini(macro_iter_idx, phase_name, mini_iter_idx)

        # ----------------------------------------------------------
        # (B) Attempt to fetch unresolved issues from the same artifact index
        # ----------------------------------------------------------
        unresolved_prev_issues = []
        if prev_iteration:
            p_macro, p_phase, p_mini = prev_iteration
            prev_artifact_issues = (
                self.feedback_storage
                    .get(p_macro, {})
                    .get(p_phase, {})
                    .get(p_mini, {})
                    .get(artifact_index, [])
            )
            for iss in prev_artifact_issues:
                if iss.get("knownIssue") in ["NewIssue", "KnownIssue", "InProgress"]:
                    unresolved_prev_issues.append(iss)
        filtered_unresolved = []
        for iss in unresolved_prev_issues:
            gap_id = iss["gapID"]
            # Grab the master record so we can see "resolvedInArtifacts"
            record = self.issue_first_seen_iteration.get(gap_id, {})
            resolved_in_arts = record.get("resolvedInArtifacts", set())

            # If artifact_index not in that set, it's truly unresolved for *this* artifact
            if artifact_index not in resolved_in_arts:
                filtered_unresolved.append(iss)

        unresolved_prev_issues = filtered_unresolved
        # ----------------------------------------------------------
        # (C) NEW CROSS-PHASE FALLBACK:
        #     If none found for this artifact, gather all unresolved from prev iteration
        # ----------------------------------------------------------
        if not unresolved_prev_issues and prev_iteration:
            p_macro, p_phase, p_mini = prev_iteration
            prev_phase_dict = (
                self.feedback_storage
                    .get(p_macro, {})
                    .get(p_phase, {})
                    .get(p_mini, {})
            )

            carry_over_issues_map = {}
            for art_idx, issues_list in prev_phase_dict.items():
                for iss in issues_list:
                    if iss.get("knownIssue") in ["NewIssue", "KnownIssue", "InProgress"]:
                        gid = iss.get("gapID")
                        if gid:
                            # Convert "NewIssue" to "KnownIssue" if it's truly from a previous iteration
                            new_iss = dict(iss)
                            if new_iss["knownIssue"] == "NewIssue":
                                new_iss["knownIssue"] = "KnownIssue"
                            carry_over_issues_map[gid] = new_iss

            unresolved_prev_issues = list(carry_over_issues_map.values())

        # ----------------------------------------------------------
        # (D) Debug-style print showing whether we found any
        # ----------------------------------------------------------
        if not unresolved_prev_issues:
            print(f"[INFO] No unresolved issues found for artifact={artifact_index} in the previous iteration.")
        else:
            print(f"[INFO] Found {len(unresolved_prev_issues)} unresolved issues carried from the previous iteration.")

        # ----------------------------------------------------------
        # (E) Pass unresolved_prev_issues into the teacher review
        # ----------------------------------------------------------
        new_issues = self.llm_client.safe_teacher_review(
            issue_tracker=self.issue_tracker,
            macro_iter_idx=macro_iter_idx,
            phase_name=phase_name,
            mini_iter_idx=mini_iter_idx,
            artifact_index=artifact_index,
            artifact_text=artifact_json_str,
            dependency_text=table_dependencies_text,
            unresolved_prev_issues=unresolved_prev_issues,
            artifact_review_questions=self.artifact_review_questions
        )

        return new_issues




    def verify_mini_iteration_issue_resolution(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int
    ):
        """
        Re‑check *every* artifact that was **regenerated in this same mini‑iteration**
        and still carries open issues from any earlier step.  The reviewer (teacher LLM)
        therefore always sees the *latest* JSON that the student LLM produced only
        moments before.

        Steps
        -----
        1. Build a list of artifact indices whose *last* update is exactly the
           triple `(macro_iter_idx, phase_name, mini_iter_idx)` – that is, the
           artifacts just saved in this mini.
        2. For each of them gather the still‑open issues that came from previous
           iterations (status ∈ {NewIssue, KnownIssue, InProgress}).
        3. Pass the freshly updated artifact text plus those issues to the
           verifier LLM (`verify_open_issues_against_new_artifact`).
        4. Merge the LLM verdict back into `feedback_storage` so statuses are
           consistent.
        5. Skip artifacts with no open issues (saves tokens).
        """
        print("CALL-VERIFY", macro_iter_idx, phase_name, mini_iter_idx)
        # ────────────────────────────────────────────────────────
        # 1) Artifacts updated *in this mini* (no cross‑phase mix‑ups)
        # ────────────────────────────────────────────────────────
        artifact_indices = [
            idx for idx, (pm, pp, pmini) in self.last_artifact_update.items()
            if (pm, pp, pmini) == (macro_iter_idx, phase_name, mini_iter_idx)
        ]
        if not artifact_indices:
            return  # nothing new was generated in this mini – safe exit

        # ────────────────────────────────────────────────────────
        # 2) Iterate and verify
        # ────────────────────────────────────────────────────────
        for artifact_index in artifact_indices:
            # Retrieve the current JSON (guaranteed to exist – was just saved)
            current_artifact_dict = (
                self.artifact_versions
                    .get(macro_iter_idx, {})
                    .get(phase_name, {})
                    .get(mini_iter_idx, {})
                    .get(artifact_index, {})
            )
            if not current_artifact_dict:  # extra safety
                continue

            # Gather open issues recorded *earlier* for this artifact
            open_issues = []
            for m_idx, phase_dict in self.feedback_storage.items():           # macro
                for ph_name, mini_dict in phase_dict.items():                 # phase
                    for mi_idx, art_dict in mini_dict.items():                # mini
                        if (m_idx, ph_name, mi_idx) == (macro_iter_idx,
                                                        phase_name,
                                                        mini_iter_idx):
                            continue  # skip the very same mini we are verifying
                        for iss in art_dict.get(artifact_index, []):
                            if iss.get("knownIssue") in {"NewIssue", "KnownIssue", "InProgress"}:
                                open_issues.append(iss)
            if not open_issues:
                continue  # nothing to verify for this artifact

            artifact_text = json.dumps(current_artifact_dict, indent=2)

            verification_results = self.verify_open_issues_against_new_artifact(
                macro_iter_idx=macro_iter_idx,
                phase_name=phase_name,
                mini_iter_idx=mini_iter_idx,
                artifact_text=artifact_text,
                open_issues=open_issues,
            )

            # Merge the verification outcome back into storage
            self.merge_verification_results(
                macro_iter_idx=macro_iter_idx,
                phase_name=phase_name,
                mini_iter_idx=mini_iter_idx,
                artifact_index=artifact_index,
                open_issues=open_issues,
                verification_results=verification_results,
                new_issues_this_artifact=[],
            )





    def verify_and_merge_issues(
        self,
        macro_iter_idx,
        phase_name,
        mini_iter_idx,
        artifact_index,
        artifact_text,
        new_issues_this_artifact
    ):
        """
        Merge newly identified issues with existing ones, enabling cross-phase and
        cross-iteration tracking. Carries over unresolved issues from the previous phase.
        """
        print(
            f"CALL-VERIFY {artifact_index} "
            f"{macro_iter_idx}/{phase_name}/{mini_iter_idx}"
        )
        # Deduplicate new issues with all existing open issues (unifies gapIDs across artifacts/phases)
        final_issues, newly_created_ids = self.issue_tracker.deduplicate_issues_for_mini_iteration(
            macro_iter_idx=macro_iter_idx,
            phase_name=phase_name,
            mini_iter_idx=mini_iter_idx,
            artifact_index=artifact_index,
            new_issues_list=new_issues_this_artifact
        )

        ###################################################################
        # CROSS-MACRO FIX  (first seen in an older macro)  ← original code
        ###################################################################
        for iss in final_issues:
            if iss.get("knownIssue") != "NewIssue":
                continue
            gid = iss.get("gapID")
            master = self.issue_tracker.issue_first_seen_iteration.get(gid, {})
            if not isinstance(master, dict):
                continue
            first_seen = master.get("firstSeen")  # (macro, phase, mini)
            if (
                first_seen
                and first_seen[0] < macro_iter_idx       # STRICTLY older macro
            ):
                IssueTracker.add_issue_history(iss, "knownIssue", "NewIssue", "KnownIssue",
                                              reason="Cross-macro carry-over")
                iss["knownIssue"] = "KnownIssue"
                if master.get("status") == "NewIssue":
                    IssueTracker.add_issue_history(master, "status", "NewIssue", "KnownIssue",
                                                  reason="Cross-macro carry-over")
                    master["status"] = "KnownIssue"
                if gid in newly_created_ids:          # don’t count as “new”
                    newly_created_ids.remove(gid)

        ###################################################################
        # INTRA-MACRO FIX  (same macro, different artifact)  ← new block
        ###################################################################
        for iss in final_issues:
            if iss.get("knownIssue") != "NewIssue":
                continue
            gid = iss.get("gapID")
            master = self.issue_tracker.issue_first_seen_iteration.get(gid, {})
            if not isinstance(master, dict):
                continue
            first_seen = master.get("firstSeen")      # (macro, phase, mini)
            if (
                first_seen
                and first_seen[0] == macro_iter_idx   # same macro
                and gid not in newly_created_ids      # not just created
            ):
                IssueTracker.add_issue_history(iss, "knownIssue", "NewIssue", "KnownIssue",
                                              reason="Cross-artifact flip inside macro")
                iss["knownIssue"] = "KnownIssue"
                if master.get("status") == "NewIssue":
                    IssueTracker.add_issue_history(master, "status", "NewIssue", "KnownIssue",
                                                  reason="Cross-artifact flip inside macro")
                    master["status"] = "KnownIssue"
        ###################################################################
        # END FIXES
        ###################################################################


        return final_issues, newly_created_ids










    def verify_open_issues_against_new_artifact(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        artifact_text: str,
        open_issues: list
    ) -> list:
        """
        Checks each open issue from a previous iteration (within the same macro/phase structure)
        against the new artifact text. Determines whether each issue is now:

          - "Resolved"    if the artifact text clearly addresses/fixes it
          - "InProgress"  if it is only partially addressed
          - "KnownIssue"  if it remains unfixed

        Returns a list of verification results:

          [
            {
              "gapID": "...",
              "newStatus": "Resolved | InProgress | KnownIssue",
              "notes": "short rationale"
            },
            ...
          ]

        If no open_issues are supplied, returns an empty list without invoking the LLM.
        """

        if not open_issues:
            return []

        # **Trim open issues to remove history and other unnecessary fields**
        trimmed_open_issues = []
        for iss in open_issues:
            trimmed_open_issues.append({
                "gapID": iss.get("gapID", ""),
                "gapType": iss.get("gapType", ""),
                "shortDescription": iss.get("shortDescription", ""),
                "impact": iss.get("impact", "Medium"),
                "recommendation": iss.get("recommendation", ""),
                "knownIssue": iss.get("knownIssue", "")
            })
        # Convert the old open issues to JSON for inclusion in the prompt
        issues_text_for_prompt = json.dumps(trimmed_open_issues, indent=2)

        # Build an LLM prompt referencing the full 3D iteration context
        prompt = f"""
        You are an expert software engineer and SQA.
        We are currently at iteration (macro={macro_iter_idx}, phase={phase_name}, mini={mini_iter_idx}).

        Your job is to follow these rules and the downgrade guardrail, analyze updated artifact text against artifact-specific issues from a previous iteration, and for each **of those issues** decide on **its** status and in the end output valid JSON.

        Follow these rules:
        For each issue, assign a **newStatus** using the stricter rules below.
          - "Resolved"    – the artifact *demonstrably* satisfies the gap’s acceptance-criterion **and** supplies supporting evidence (e.g., test result that meets the stated target, explicit trace-link, measured KPI ≥ goal).
          - "InProgress"  – the artifact introduces a *specific remedial element* (e.g., placeholder trace tag, draft test script, WIP pull-request) **but lacks final evidence**. Merely restating the issue short description/recommendation in artifact text does **not** qualify.
          - "KnownIssue"  – no relevant change toward closing the gap is present.

        Downgrade guardrail – treat the issue’s incoming “knownIssue” field as its previous status. You may maintain or upgrade a status (KnownIssue → InProgress → Resolved). **Never downgrade** unless the artifact explicitly removes earlier evidence; if you do, explain why in `notes` (≤ 20 words).

        ─────────────────────────────── EDGE-CASE POLICY ───────────────────────────────
        • If an artifact both adds and removes evidence for the same issue, judge by the net effect.
        • When evidence is ambiguous, choose the safer label (KnownIssue over InProgress).
        • One evidence line may close multiple gaps; evaluate each gap independently.
        • Keep each `notes` entry ≤ 20 words; start with a verb and cite the key artifact field (e.g., “Trace-to-US column”).
        • Whole vs row/column precedence (newer gap wins):
         – If a newer Row/Column gap refines an older Whole-artifact gap, mark the Whole-artifact gap **Resolved** with notes "Refined to <row gapID>".
         – If a newer Whole-artifact gap covers several existing Row/Column gaps, mark those row/column gaps **Resolved** with notes "Superseded by <whole gapID>".

        ─────────────────────────── REFERENCE EXAMPLES (SIMULATION) ───────────────────────────
        Example A — Resolved
        • Issue: gapID "794d85" (Actor-ID traceability), previous status KnownIssue.
        • Updated artifact now shows a new column "Trace-to-US" with entries like "Actor-User → US-01".
        {{
        "gapID": "794d85",
        "newStatus": "Resolved",
        "notes": "Trace-to-US column completes Actor links"
        }}

        Example B — InProgress
        • Issue: gapID "9a56b0" (p95 response ≤ 400 ms), previous status KnownIssue.
        • Artifact adds a "PerfTestPlan" section **(remedial element)**, but no exact number is assigned yet.
        {{
        "gapID": "9a56b0",
        "newStatus": "InProgress",
        "notes": "PerfTestPlan added; numerical criteria missing"
        }}

        Example C — Forbidden Downgrade
        • Issue: gapID "263e78" (zero-lint static analysis), previous status InProgress — earlier artifact already listed "ESLintConfig": "strict".
        • Current artifact is unchanged (config still present, nothing removed).
        {{
        "gapID": "263e78",
        "newStatus": "InProgress",
        "notes": "No new evidence; retain InProgress"
        }}

        Example D — Whole superseded by row (refinement)
        Older: gapID "aa11bb" → locator `Whole artifact`
        Artifact now shows the issue only in Row I-07
        Output:
        {{
          "gapID": "aa11bb",
          "newStatus": "InProgress",
          "notes": "Locator narrowed to Row I-07"
        }}

        Example E — Whole supersedes rows
        Existing gapID "bb22cc" had locator `Row I-07`
        Artifact now shows KPI column missing in multiple rows → set locator to `Whole artifact`
        Output:
        {{
          "gapID": "bb22cc",
          "newStatus": "KnownIssue",
          "notes": "Locator widened to Whole"
        }}

        Example F — Still Known
        • Issue: gapID "d0d0d0" (KPI column), previous status **KnownIssue**.
        • Updated artifact shows no fix and no new evidence.

        {{
          "gapID": "d0d0d0",
          "newStatus": "KnownIssue",
          "notes": "No change; gap persists"
        }}

        Below is our updated artifact text:
        {artifact_text}

        And here are the still-open (unresolved) artifact-specific issues from a previous iteration (micro/phase/macro):
        {issues_text_for_prompt}


        Return ONLY valid JSON with this structure:
        {{
          "verificationResults": [
            {{
              "gapID": "same ID as in open_issues",
              "newStatus": "Resolved | InProgress | KnownIssue",
              "notes": "≤ 20 words rationale"
            }},
            ...
          ]
        }}

        No extra text outside JSON, no triple backticks or code fencing. **Do not include trailing commas.**
        """

        # Call the LLM
        raw_response = self.llm_client.openai_cheap_api(prompt).strip()
        try:
            data = json.loads(raw_response)
            return data.get("verificationResults", [])
        except (json.JSONDecodeError, TypeError):
            return []



    def merge_verification_results(
        self,
        macro_iter_idx,
        phase_name,
        mini_iter_idx,
        artifact_index,
        open_issues,
        verification_results,
        new_issues_this_artifact
    ):
        # 1) Retrieve (or create) the current iteration's issue list
        current_issues_list = (
            self.feedback_storage
                .setdefault(macro_iter_idx, {})
                .setdefault(phase_name, {})
                .setdefault(mini_iter_idx, {})
                .setdefault(artifact_index, [])
        )

        # 2) First, extend with newly discovered issues (so we don't lose them)
        current_issues_list.extend(new_issues_this_artifact)

        # 3) Apply verification results to the old open issues
        for vr in verification_results:
            gid = vr.get("gapID", "")
            new_status = vr.get("newStatus", "KnownIssue")  # default to "KnownIssue" if missing
            notes = vr.get("notes", "")

            for old_iss in open_issues:
                if old_iss.get("gapID", "") == gid:
                    # Copy it so we do not mutate old_iss in place
                    updated_issue = dict(old_iss)
                    if not updated_issue.get("gapType"):
                        updated_issue["gapType"] = "Other"
                    old_status = updated_issue.get("knownIssue", "KnownIssue")
                    updated_issue.setdefault("knownIssue", old_status)

                    if new_status == "Resolved":
                        IssueTracker.add_issue_history(
                            updated_issue,
                            "knownIssue",
                            old_status,
                            "Resolved",
                            f"Auto-resolved after verification. {notes}"
                        )
                        updated_issue["knownIssue"] = "Resolved"

                    elif new_status == "InProgress":
                        IssueTracker.add_issue_history(
                            updated_issue,
                            "knownIssue",
                            old_status,
                            "InProgress",
                            f"Partial fix indicated. {notes}"
                        )
                        updated_issue["knownIssue"] = "InProgress"

                    else:  # e.g. "KnownIssue" or any fallback
                        IssueTracker.add_issue_history(
                            updated_issue,
                            "knownIssue",
                            old_status,
                            "KnownIssue",
                            f"Still open. {notes}"
                        )
                        updated_issue["knownIssue"] = "KnownIssue"

                    updated_issue["verificationNote"] = notes
                    current_issues_list.append(updated_issue)

                    gap_id = updated_issue["gapID"]
                    if gap_id in self.issue_first_seen_iteration:
                        record = self.issue_first_seen_iteration[gap_id]
                        old_master_status = record.get("status", "KnownIssue")
                        if old_master_status != new_status:
                            IssueTracker.add_issue_history(
                                record, "status", old_master_status, new_status,
                                reason="Verification said it's resolved or in-progress"
                            )
                            record["status"] = new_status

                        if new_status == "Resolved":
                            # Log the 3D iteration reference
                            IssueTracker.add_issue_history(
                                record, "resolvedIn", record.get("resolvedIn"),
                                f"({macro_iter_idx},{phase_name},{mini_iter_idx})",
                                reason="Verification fully fixed"
                            )
                            record["resolvedIn"] = (macro_iter_idx, phase_name, mini_iter_idx)

                            # NEW FOR FIX #3: set resolvedInGlobalMini right away
                            total_minis_per_macro = sum(
                                ph.get("miniIterations", 1) for ph in self.sim_config["phases"]
                            )
                            local_gmini = self.get_global_mini_index(phase_name, mini_iter_idx)
                            resolved_in_global = (macro_iter_idx - 1) * total_minis_per_macro + local_gmini
                            record["resolvedInGlobalMini"] = resolved_in_global

                            # --- JSON‑safe recording of the resolving artifact -------------------------
                            # Legacy runs may already contain a `set`; convert once on the fly
                            art_list = record.setdefault("resolvedInArtifacts", [])
                            if isinstance(art_list, set):               # migrate old data
                                art_list = list(art_list)
                                record["resolvedInArtifacts"] = art_list

                            # Append this artifact if it is not yet listed
                            if artifact_index not in art_list:
                                art_list.append(artifact_index)

                            # (optional, if you fear duplicates from future edits)
                            record["resolvedInArtifacts"] = list(dict.fromkeys(record["resolvedInArtifacts"]))
                            # ---------------------------------------------------------------------------

                        elif new_status == "InProgress":
                            if record.get("inProgressFrom") is None:
                                IssueTracker.add_issue_history(
                                    record, "inProgressFrom", None,
                                    f"({macro_iter_idx},{phase_name},{mini_iter_idx})",
                                    reason="Verification partial fix"
                                )
                                record["inProgressFrom"] = (macro_iter_idx, phase_name, mini_iter_idx)

        # 4) Deduplicate final issues by gapID (dictionary approach)
        gapid_map = {}
        for iss in current_issues_list:
            gapid_map[iss["gapID"]] = iss

        # Replace the original list with the deduplicated values
        self.feedback_storage[macro_iter_idx][phase_name][mini_iter_idx][artifact_index] = list(gapid_map.values())





    def update_gap_counters(self, final_issues_unified, iteration_gap_counters, cumulative_iter_counters):
        """
        Update iteration-level counters and cumulative counters with final issues.
        """
        artifact_gap_counters = self.init_gap_counters()
        recognized_gap_types = {
            "MissedRequirement", "SecurityGap", "ComplianceGap",
            "PerformanceGap", "UsabilityGap", "Other"
        }

        for issue in final_issues_unified:
            gtype = issue.get("gapType", "Other")
            if gtype not in recognized_gap_types:
                gtype = "Other"
            known_status = issue.get("knownIssue", "NewIssue")
            impact = IssueTracker._clean_impact(issue.get("impact"))
            artifact_gap_counters[gtype][known_status][impact] += 1

        # Update iteration-level & cumulative counters
        for gtype in artifact_gap_counters:
            for st in artifact_gap_counters[gtype]:
                for imp, count_val in artifact_gap_counters[gtype][st].items():
                    iteration_gap_counters[gtype][st][imp] += count_val
                    cumulative_iter_counters[gtype][st][imp] += count_val

        # Calculate total issues
        total_issues_for_artifact = 0
        for gtype in recognized_gap_types:
            for st in self.statuses_to_count:
                for imp in self.impacts:
                    total_issues_for_artifact += artifact_gap_counters[gtype][st][imp]

        return artifact_gap_counters, total_issues_for_artifact

    def accumulate_artifact_metrics(self, iter_counters, artifact_result):
        """
        Accumulate per-artifact metrics into the iteration-level counters, respecting the extended requirements:
          - Use open (unresolved) issues for defect density (iteration_defect_issues_sum).
          - Track new issues separately (iteration_new_issues_sum) for new defect density.
          - For churn, use the previous row count as the baseline (current rows + removed - added).
          - Continue collecting lexical/trace coverage data and row-change totals.
        """

        # 1) Add the artifact's text to iteration_text_fragments (for lexical density / unique term ratio)
        iter_counters["iteration_text_fragments"].append(artifact_result["artifact_text_str"])

        # 2) Sum table complexity to iteration_table_complexity_sum
        table_complex = artifact_result["table_complex"]
        iter_counters["iteration_table_complexity_sum"] += table_complex

        # 3) Weighted trace coverage: multiply trace_cov by the artifact's row count
        parsed_artifact = artifact_result["parsed_artifact"]
        num_rows_artifact = len(parsed_artifact.get("rows", []))
        trace_cov = artifact_result["trace_cov"]
        if trace_cov is not None:
            iter_counters["iteration_trace_cov_weighted_sum"] += (trace_cov * num_rows_artifact)
            iter_counters["iteration_trace_cov_rows_sum"] += num_rows_artifact

        # 4) Accumulate open issues (for open-defect density) and new issues
        open_issues_count = artifact_result.get("open_issues_for_artifact", 0)
        new_issues_count = artifact_result.get("new_issues_for_artifact", 0)
        iter_counters["iteration_defect_issues_sum"] += open_issues_count

        # Add a separate field for newly discovered issues if needed for newDefectDensity
        if "iteration_new_issues_sum" not in iter_counters:
            iter_counters["iteration_new_issues_sum"] = 0
        iter_counters["iteration_new_issues_sum"] += new_issues_count

        # 5) The total table complexity is used as the denominator for defect densities
        iter_counters["iteration_defect_complexity_sum"] += table_complex

        # 6) Accumulate row changes (added, removed, changed)
        diff_info = artifact_result["diff_info"]
        added_rows = len(diff_info["added"])
        removed_rows = len(diff_info["removed"])
        changed_rows = len(diff_info["changed"])

        iter_counters["iteration_added_rows_sum"] += added_rows
        iter_counters["iteration_removed_rows_sum"] += removed_rows
        iter_counters["iteration_changed_rows_sum"] += changed_rows

        # 7) For churn, use the previous row count as baseline:
        #    previous_rows = (current row count) + removed - added
        prev_rows_count = num_rows_artifact + removed_rows - added_rows
        if prev_rows_count < 0:
            prev_rows_count = 0
        iter_counters["iteration_rows_sum_for_churn"] += prev_rows_count







    def finalize_mini_iteration(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        mini_iter_counters: dict
    ):
        """
        Finalizes the mini iteration by:
          1) Possibly verifying resolution from the previous mini iteration
          2) Computing metrics for this mini iteration
          3) Logging a row to mini_iteration_summary_metrics.csv
          4) Updating our global set of unresolved issues
          5) [ADDED FOR PROBLEM #8 FIX] ensuring no false closures
        """
        # ── Mini-lessons heading ───────────────────────────────────────
        print(
            f"retrospective_problem|CREATOR|START|macro={macro_iter_idx}"
            f"|phase={phase_name}|mini={mini_iter_idx}",
            file=sys.stderr
        )
        # (A) If mini_iter_idx > 1, verify resolution from the previous mini iteration
        if mini_iter_idx > 1:
            self.verify_mini_iteration_issue_resolution(
                macro_iter_idx=macro_iter_idx,
                phase_name=phase_name,
                mini_iter_idx=mini_iter_idx
            )

        # (B) [ADDED FOR PROBLEM #8 FIX] Enforce that no issues vanish without resolvedIn
        #     1) Grab the set that was open at the start
        pre_open_set = self.pre_mini_open_issues.get((macro_iter_idx, phase_name, mini_iter_idx), set())
        #     2) See who is still open now, at the end
        post_open_set = self.get_current_open_issue_ids()

        #     3) For each issue that was open at start but not open at end,
        #        check if it truly has resolvedIn == (macro, phase, mini)
        forcibly_restored_count = 0
        for gap_id in pre_open_set:
            if gap_id not in post_open_set:
                # Check if truly resolved in this mini
                rec = self.issue_first_seen_iteration.get(gap_id, None)
                if rec and isinstance(rec, dict):
                    resolved_iter = rec.get("resolvedIn")
                    if resolved_iter != (macro_iter_idx, phase_name, mini_iter_idx):
                        # => It's NOT truly resolved. We re-add it to open status.
                        old_status = rec.get("status", "KnownIssue")

                        # revert the status if it was incorrectly set to Resolved
                        if old_status == "Resolved":
                            rec["status"] = "KnownIssue"
                            # Also clear resolvedIn if it was set incorrectly
                            if rec.get("resolvedIn"):
                                rec["resolvedIn"] = None
                            if rec.get("resolvedInGlobalMini"):
                                rec["resolvedInGlobalMini"] = None

                        self.global_open_issue_ids.add(gap_id)
                        # re-check the local final feedback storage if needed,
                        # or just let the next iteration see it open again.
                        forcibly_restored_count += 1

        # AFTER the forcibly_restored_count loop, do:
        actual_resolved_count = sum(
            1 for gid, rec in self.issue_first_seen_iteration.items()
            if rec.get("resolvedIn") == (macro_iter_idx, phase_name, mini_iter_idx)
        )

        print(f"DEBUG: Actually resolved {actual_resolved_count} issues in mini iteration "
              f"(macro={macro_iter_idx}, phase={phase_name}, mini={mini_iter_idx}).")
        # ── Mini-lessons heading (only when text is non-blank) ──────────
        lessons_text = self.get_lessons_for_new_mini(
            macro_iter_idx, phase_name, mini_iter_idx
        )
        print(
            f"retrospective_problem|CREATOR|LESSONS|n_lines="
            f"{len(lessons_text.splitlines())}",
            file=sys.stderr
        )
        if lessons_text.strip():
            self.doc_teacher.add_heading(
                f"Lessons learned – {phase_name} / Mini {mini_iter_idx}", level=3
            )
            self.doc_teacher.add_paragraph(lessons_text)

            # store for later Option-A look-ups
            self.partial_lessons \
                .setdefault(macro_iter_idx, {}) \
                .setdefault(phase_name, {})[mini_iter_idx] = lessons_text
        # ────────────────────────────────────────────────────────────────
        # (C) Compute the mini iteration metrics
        mini_metrics = self.compute_mini_iteration_metrics(
            macro_iter_idx=macro_iter_idx,
            phase_name=phase_name,
            mini_iter_idx=mini_iter_idx,
            start_time=start_time,
            end_time=end_time,
            mini_iter_counters=mini_iter_counters
        )

        mini_metrics["actual_resolved_now"] = actual_resolved_count


        # 3) Build/write the CSV row from mini_metrics (as you had before).
        row_data = [
            # 1) Basic iteration identifiers
            macro_iter_idx,
            phase_name,
            mini_iter_idx,

            # 2) Timestamps & time spent
            mini_metrics["start_time"],
            mini_metrics["end_time"],
            mini_metrics["spent_time_sec"],

            # (B) Text & coverage & churn
            mini_metrics["mini_iter_lexical_density"],
            mini_metrics["mini_iter_unique_term_ratio"],
            mini_metrics["mini_iter_table_complexity_sum"],
            mini_metrics["mini_iter_trace_coverage"],
            mini_metrics["mini_iter_defect_density"],
            mini_metrics["mini_iter_artifact_churn_pct"],

            # (C) Gap type counts (raw)
            mini_metrics["newMissedReq"],
            mini_metrics["knownMissedReq"],
            mini_metrics["inProgressMissedReq"],
            mini_metrics["resolvedMissedReq"],

            mini_metrics["newSecurityGaps"],
            mini_metrics["knownSecurityGaps"],
            mini_metrics["inProgressSecurityGaps"],
            mini_metrics["resolvedSecurityGaps"],

            mini_metrics["newComplianceGaps"],
            mini_metrics["knownComplianceGaps"],
            mini_metrics["inProgressComplianceGaps"],
            mini_metrics["resolvedComplianceGaps"],

            mini_metrics["newPerformanceGaps"],
            mini_metrics["knownPerformanceGaps"],
            mini_metrics["inProgressPerformanceGaps"],
            mini_metrics["resolvedPerformanceGaps"],

            mini_metrics["newUsabilityGaps"],
            mini_metrics["knownUsabilityGaps"],
            mini_metrics["inProgressUsabilityGaps"],
            mini_metrics["resolvedUsabilityGaps"],

            mini_metrics["newOtherGaps"],
            mini_metrics["knownOtherGaps"],
            mini_metrics["inProgressOtherGaps"],
            mini_metrics["resolvedOtherGaps"],

            # (D) Distinct-based final counts
            mini_metrics["mini_total_new"],
            mini_metrics["mini_total_known"],
            mini_metrics["mini_total_inprogress"],
            mini_metrics["mini_total_resolved"],
            mini_metrics["mini_total_open_all"],

            # (E) Carried over from previous iteration
            mini_metrics["mini_carried_over"],

            # (F) Mean closure time & feedback rate
            mini_metrics["mini_mean_closure_time"],
            mini_metrics["mini_feedback_impl_rate"],

            # (G) Open/new defect densities
            mini_metrics["mini_iter_open_defect_density"],
            mini_metrics["mini_iter_new_defect_density"],

            # (H) Severity-based open defect densities
            mini_metrics["mini_iter_critical_defect_density"],
            mini_metrics["mini_iter_high_defect_density"],
            mini_metrics["mini_iter_medium_defect_density"],
            mini_metrics["mini_iter_low_defect_density"],

            # (I) Rolling averages at mini-level
            mini_metrics["mini_iter_rolling_avg_new_issues"],
            mini_metrics["mini_iter_rolling_avg_defect_density"],
            mini_metrics["mini_iter_rolling_avg_new_defect_density"],

            # (J) Final summary counts (explicit for CSV)
            mini_metrics["mini_iter_new_issue_count"],
            mini_metrics["mini_iter_known_issue_count"],
            mini_metrics["mini_iter_inprogress_issue_count"],
            mini_metrics["mini_iter_resolved_issue_count"],
            mini_metrics["mini_iter_open_issue_count"],
            mini_metrics["actual_resolved_now"]
        ]

        with open(self.mini_iteration_summary_file, "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(row_data)

        # (E) Update the global unresolved issues after final
        self.update_global_unresolved_issues(macro_iter_idx, phase_name, mini_iter_idx)

        # (F) [Optional debug print] to confirm how many issues were forcibly restored
        if forcibly_restored_count > 0:
            print(
                f"DEBUG: {forcibly_restored_count} issues were re-added to open set in "
                f"(Macro={macro_iter_idx}, Phase={phase_name}, Mini={mini_iter_idx}) "
                "because they lacked a proper resolvedIn."
            )

    def _iteration_is_before(self, iterA, iterB):
        """
        Compare (macroA, phaseA, miniA) < (macroB, phaseB, miniB)
        using numeric phase indexing. Return True if A is strictly before B.
        """
        (macroA, phaseA, miniA) = iterA
        (macroB, phaseB, miniB) = iterB

        if macroA < macroB:
            return True
        elif macroA > macroB:
            return False

        # same macro => compare phase index
        idxA = self.phase_index_map.get(phaseA, -1)
        idxB = self.phase_index_map.get(phaseB, -1)

        if idxA < idxB:
            return True
        elif idxA > idxB:
            return False

        # same macro & same phase => compare mini
        return (miniA < miniB)


    def generate_issue_lifecycle_csv(self, csv_path: str):
        """
        Export a per‑gap lifecycle file (issue_lifecycle.csv).

        The master record is assumed to be *final* at this point
        – no additional “repair” logic is applied here.
        """

        field_order = [
            "gapID", "initialGapType", "finalGapType",
            "initialSeverity", "finalSeverity",
            "firstSeen", "lastSeen", "resolvedIn",
            "firstSeenGlobalMini", "lastSeenGlobalMini", "resolvedInGlobalMini",
            "status", "RecurrenceCount", "IssueLifespan", "PhasesToResolution",
            "ResolvedWithinSamePhase"
        ]

        rows = []
        for gid, rec in self.issue_first_seen_iteration.items():
            if not isinstance(rec, dict):
                continue

            # ----- helper values -------------------------------------------
            fs_tuple = rec.get("firstSeen")          # (macro, phase, mini) or None
            ls_tuple = rec.get("lastSeen")
            rs_tuple = rec.get("resolvedIn")

            if rs_tuple:
                phase_span = (
                    self.phase_index_map.get(rs_tuple[1], 0) -
                    self.phase_index_map.get(fs_tuple[1], 0)
                )
                same_phase = int(fs_tuple[1] == rs_tuple[1])
                lifespan   = rec.get("resolvedInGlobalMini", 0) - \
                             rec.get("firstSeenGlobalMini", 0) + 1
            else:
                phase_span = None
                same_phase = 0
                lifespan   = None

            rows.append({
                "gapID": gid,
                "initialGapType":  rec.get("initialGapType"),
                "finalGapType":    rec.get("finalGapType"),
                "initialSeverity": rec.get("initialSeverity"),
                "finalSeverity":   rec.get("finalSeverity"),
                "firstSeen":       fs_tuple,
                "lastSeen":        ls_tuple,
                "resolvedIn":      rs_tuple,
                "firstSeenGlobalMini":  rec.get("firstSeenGlobalMini"),
                "lastSeenGlobalMini":   rec.get("lastSeenGlobalMini"),
                "resolvedInGlobalMini": rec.get("resolvedInGlobalMini"),
                "status":          rec.get("status"),
                "RecurrenceCount": rec.get("recurrenceCount", 1),
                "IssueLifespan":   lifespan,
                "PhasesToResolution": phase_span,
                "ResolvedWithinSamePhase": same_phase
            })

        pd.DataFrame(rows, columns=field_order).to_csv(csv_path, index=False)






    def generate_final_summary_doc(self):
        """
        v6 (2025-05-05) — minimalist finalisation.

        The student DOCX no longer contains:
            • the “Final Summary of All Macro Iterations” numeric section
            • the “Detailed Issues …” appendix

        Responsibilities kept:
            1) Save   output_multi_iter.docx          (student)
            2) Save   teacher_review_output_multi_iter.docx
            3) Close  the main CSV file handle
            4) Emit   issue_lifecycle.csv   (analytics parity, FR-34)
        """
        # ──────────────── presentation content removed ────────────────
        # Everything formerly written here (numeric metrics + detailed
        # issues) is now omitted per Implementation Plan v6.
        # ───────────────────────────────────────────────────────────────

        # 1-2) Persist DOCX files
        self.doc.save("output_multi_iter.docx")
        self.doc_teacher.save("teacher_review_output_multi_iter.docx")

        # 3) Close the running metrics CSV
        self.csv_file.close()
        print("Student/Teacher DOCX saved; CSV writer closed.")

        # 4) Lifecycle transitions CSV (analytics unchanged)
        print("Generating issue_lifecycle.csv with major status transitions…")
        self.generate_issue_lifecycle_csv("issue_lifecycle.csv")





    def compute_mini_iteration_metrics(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        mini_iter_counters: dict
    ) -> dict:
        """
        Computes detailed metrics for a **single mini‑iteration**
        after the artifact processing loop has finished.

        * Fix #1 – open‑issue counts now come from the authoritative
          cache `self.open_ids_at_end_of_mini`.
        * Fix #2 – new‑issue counts come from
          `self.new_ids_in_mini`, so no double counting across
          artifacts in the same mini.
        All downstream metrics (gap‑type splits, densities, rolling
        averages, etc.) are derived from these sets, guaranteeing that
        the four CSVs remain consistent.
        """

        spent_time = (end_time - start_time).total_seconds()

        # ------------------------------------------------------------------
        # 1)  Authoritative per‑mini caches (written in run_phase_single_pass)
        # ------------------------------------------------------------------
        mini_key = (macro_iter_idx, phase_name, mini_iter_idx)
        cache_new_ids: set  = self.new_ids_in_mini.get(mini_key, set())
        cache_open_ids: set = self.open_ids_at_end_of_mini.get(mini_key, set())

        # ------------------------------------------------------------------
        # 2)  Unpack quick counters accumulated during artifact processing
        # ------------------------------------------------------------------
        iteration_text_fragments          = mini_iter_counters["iteration_text_fragments"]
        iteration_table_complexity_sum    = mini_iter_counters["iteration_table_complexity_sum"]
        iteration_trace_cov_weighted_sum  = mini_iter_counters["iteration_trace_cov_weighted_sum"]
        iteration_trace_cov_rows_sum      = mini_iter_counters["iteration_trace_cov_rows_sum"]
        iteration_rows_sum_for_churn      = mini_iter_counters["iteration_rows_sum_for_churn"]
        iteration_added_rows_sum          = mini_iter_counters["iteration_added_rows_sum"]
        iteration_removed_rows_sum        = mini_iter_counters["iteration_removed_rows_sum"]
        iteration_changed_rows_sum        = mini_iter_counters["iteration_changed_rows_sum"]

        # ------------------------------------------------------------------
        # 3)  Text‑based metrics (lexical + unique term ratio)
        # ------------------------------------------------------------------
        iteration_level_text = " ".join(iteration_text_fragments)
        iteration_lexical_density   = MetricsCalculator.calculate_lexical_density(iteration_level_text)
        iteration_unique_term_ratio = MetricsCalculator.calculate_unique_term_ratio(iteration_level_text)

        # ------------------------------------------------------------------
        # 4)  Weighted traceability coverage
        # ------------------------------------------------------------------
        if iteration_trace_cov_rows_sum > 0:
            iteration_trace_coverage = round(
                iteration_trace_cov_weighted_sum / iteration_trace_cov_rows_sum, 2)
        else:
            iteration_trace_coverage = 0.0


        # ------------------------------------------------------------------
        # 6)  Artifact churn (% rows touched)
        # ------------------------------------------------------------------
        total_edit_ops = (iteration_added_rows_sum +
                          iteration_removed_rows_sum +
                          iteration_changed_rows_sum)
        if iteration_rows_sum_for_churn > 0:
            iteration_artifact_churn_pct = round(
                (total_edit_ops / iteration_rows_sum_for_churn) * 100, 2)
        else:
            iteration_artifact_churn_pct = 0.0

        # ------------------------------------------------------------------
        # 7)  Gather the final issue objects for this mini from feedback_storage
        # ------------------------------------------------------------------
        current_mini_issues_dict = (
            self.feedback_storage
                .get(macro_iter_idx, {})
                .get(phase_name, {})
                .get(mini_iter_idx, {}))
        final_issues_map = {}
        for iss_list in current_mini_issues_dict.values():
            for iobj in iss_list:
                final_issues_map[iobj["gapID"]] = iobj

        # ------------------------------------------------------------------
        # 8)  Build gap‑type / status counters (will be patched for NewIssue)
        # ------------------------------------------------------------------
        recognised_gap_types = [
            "MissedRequirement", "SecurityGap", "ComplianceGap",
            "PerformanceGap", "UsabilityGap", "Other"]
        gap_type_status_counter = {
            gt: {"NewIssue": 0, "KnownIssue": 0, "InProgress": 0, "Resolved": 0}
            for gt in recognised_gap_types}

        final_resolved_ids = set()
        for gid, iobj in final_issues_map.items():
            st    = iobj.get("knownIssue", "NewIssue")
            gtype = iobj.get("gapType", "Other")
            if gtype not in recognised_gap_types:
                gtype = "Other"

            gap_type_status_counter[gtype].setdefault(st, 0)
            gap_type_status_counter[gtype][st] += 1

            if st == "Resolved":
                final_resolved_ids.add(gid)

        # ---------------- patch NewIssue counts ---------------------------
        # Zero‑out NewIssue tallies then repopulate strictly from cache_new_ids
        for gt in recognised_gap_types:
            gap_type_status_counter[gt]["NewIssue"] = 0
        for gid in cache_new_ids:
            gtype = final_issues_map.get(gid, {}).get("gapType", "Other")
            if gtype not in recognised_gap_types:
                gtype = "Other"
            gap_type_status_counter[gtype]["NewIssue"] += 1
        # ------------------------------------------------------------------

        # Convenience lambdas
        def _sum(gt, st):
            return gap_type_status_counter[gt][st]

        # per‑gap‑type shorthand variables (unchanged API)
        new_missed_req      = _sum("MissedRequirement", "NewIssue")
        known_missed_req    = _sum("MissedRequirement", "KnownIssue")
        inprog_missed_req   = _sum("MissedRequirement", "InProgress")
        resolved_missed_req = _sum("MissedRequirement", "Resolved")

        new_sec_req         = _sum("SecurityGap", "NewIssue")
        known_sec_req       = _sum("SecurityGap", "KnownIssue")
        inprog_sec_req      = _sum("SecurityGap", "InProgress")
        resolved_sec_req    = _sum("SecurityGap", "Resolved")

        new_comp_req        = _sum("ComplianceGap", "NewIssue")
        known_comp_req      = _sum("ComplianceGap", "KnownIssue")
        inprog_comp_req     = _sum("ComplianceGap", "InProgress")
        resolved_comp_req   = _sum("ComplianceGap", "Resolved")

        new_perf_req        = _sum("PerformanceGap", "NewIssue")
        known_perf_req      = _sum("PerformanceGap", "KnownIssue")
        inprog_perf_req     = _sum("PerformanceGap", "InProgress")
        resolved_perf_req   = _sum("PerformanceGap", "Resolved")

        new_usab_req        = _sum("UsabilityGap", "NewIssue")
        known_usab_req      = _sum("UsabilityGap", "KnownIssue")
        inprog_usab_req     = _sum("UsabilityGap", "InProgress")
        resolved_usab_req   = _sum("UsabilityGap", "Resolved")

        new_other_req       = _sum("Other", "NewIssue")
        known_other_req     = _sum("Other", "KnownIssue")
        inprog_other_req    = _sum("Other", "InProgress")
        resolved_other_req  = _sum("Other", "Resolved")

        # ------------------------------------------------------------------
        # 9) Distinct counts driven by caches – the heart of the fix
        # ------------------------------------------------------------------
        final_new       = len(cache_new_ids)
        final_open      = len(cache_open_ids)
        final_resolved  = len(final_resolved_ids)

        final_known     = 0
        final_inprog    = 0
        for gid in cache_open_ids - cache_new_ids:
            st = final_issues_map[gid].get("knownIssue", "KnownIssue")
            if st == "InProgress":
                final_inprog += 1
            else:
                final_known  += 1

        # --- 7) Carried‑over from previous iteration ----------------------
        prev_iter = self.find_previous_mini_key(macro_iter_idx, phase_name, mini_iter_idx)
        carried_over_count = 0
        prev_open_gapids   = set()

        if prev_iter:
            pmacro, pphase, pmini = prev_iter
            for iss_list in self.feedback_storage.get(pmacro, {}).get(pphase, {}).get(pmini, {}).values():
                for old in iss_list:
                    if old.get("knownIssue") in ["NewIssue", "KnownIssue", "InProgress"]:
                        prev_open_gapids.add(old["gapID"])
        carried_over_count = len(prev_open_gapids)

        # --- 8) Mean closure time (resolved in this mini) -----------------
        resolved_durations = []
        for gid in final_resolved_ids:
            dur = self.calculate_issue_closure_time(gid)   # single call only
            if dur:                                        # skip None / 0
                resolved_durations.append(dur)

        mini_mean_closure_time = (
            round(sum(resolved_durations) / len(resolved_durations), 2)
            if resolved_durations else 0.0
        )

        # --- 9) Feedback implementation rate ------------------------------
        feedback_impl_rate = 0.0
        if carried_over_count:
            addressed = sum(
                1
                for gid in prev_open_gapids
                if gid in final_issues_map and
                  final_issues_map[gid].get("knownIssue") in ["Resolved", "InProgress"]
            )
            feedback_impl_rate = round(100 * addressed / carried_over_count, 2)

        # ------------------------------------------------------------------
        # 10) Densities based on authoritative sets
        # ------------------------------------------------------------------
        if iteration_table_complexity_sum > 0:
            mini_iter_open_defect_density = round(final_open / iteration_table_complexity_sum, 3)
            mini_iter_new_defect_density  = round(final_new  / iteration_table_complexity_sum, 3)
        else:
            mini_iter_open_defect_density = 0.0
            mini_iter_new_defect_density  = 0.0

        iteration_defect_density = mini_iter_open_defect_density

        # ------------------------------------------------------------------
        # 11) Severity‑based open defect densities (unchanged)
        # ------------------------------------------------------------------
        critical_open = high_open = medium_open = low_open = 0
        for gid in cache_open_ids:
            sev = final_issues_map[gid].get("impact", "Medium").lower()
            if sev == "critical":
                critical_open += 1
            elif sev == "high":
                high_open += 1
            elif sev == "medium":
                medium_open += 1
            else:
                low_open += 1

        if iteration_table_complexity_sum > 0:
            mini_iter_critical_defect_density = round(critical_open / iteration_table_complexity_sum, 3)
            mini_iter_high_defect_density     = round(high_open     / iteration_table_complexity_sum, 3)
            mini_iter_medium_defect_density   = round(medium_open   / iteration_table_complexity_sum, 3)
            mini_iter_low_defect_density      = round(low_open      / iteration_table_complexity_sum, 3)
        else:
            mini_iter_critical_defect_density = 0.0
            mini_iter_high_defect_density     = 0.0
            mini_iter_medium_defect_density   = 0.0
            mini_iter_low_defect_density      = 0.0

        # ------------------------------------------------------------------
        # 12) Rolling averages (unchanged logic)
        # ------------------------------------------------------------------
        if not hasattr(self, "mini_history"):
            self.mini_history = {}

        self.mini_history[mini_key] = {
            "newIssueCount": final_new,
            "openDefDensity": mini_iter_open_defect_density,
            "newDefDensity": mini_iter_new_defect_density}

        ROLLING_WINDOW = 3
        def same_phase_key(k):
            return (k[0] == macro_iter_idx) and (k[1] == phase_name)

        relevant_keys = sorted([mk for mk in self.mini_history if same_phase_key(mk)], key=lambda x: x[2])
        truncated_keys = relevant_keys[-ROLLING_WINDOW:]

        if truncated_keys:
            sum_new_issues = 0
            sum_open_def = 0.0
            sum_new_def = 0.0
            for mk in truncated_keys:
                sum_new_issues += self.mini_history[mk]["newIssueCount"]
                sum_open_def += self.mini_history[mk]["openDefDensity"]
                sum_new_def += self.mini_history[mk]["newDefDensity"]

            n_keys = len(truncated_keys)
            mini_iter_rolling_avg_new_issues = round(sum_new_issues / n_keys, 2)
            mini_iter_rolling_avg_defect_density = round(sum_open_def / n_keys, 3)
            mini_iter_rolling_avg_new_defect_density = round(sum_new_def / n_keys, 3)
        else:
            mini_iter_rolling_avg_new_issues = float(final_new)
            mini_iter_rolling_avg_defect_density = mini_iter_open_defect_density
            mini_iter_rolling_avg_new_defect_density = mini_iter_new_defect_density

        # (13) Summaries at mini-level
        result = {
            # Basic iteration info
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "spent_time_sec": spent_time,

            # Text & coverage & churn
            "mini_iter_lexical_density": iteration_lexical_density,
            "mini_iter_unique_term_ratio": iteration_unique_term_ratio,
            "mini_iter_table_complexity_sum": iteration_table_complexity_sum,
            "mini_iter_trace_coverage": iteration_trace_coverage,
            "mini_iter_defect_density": iteration_defect_density,
            "mini_iter_artifact_churn_pct": iteration_artifact_churn_pct,

            # Gap type counts (raw)
            "newMissedReq": new_missed_req,
            "knownMissedReq": known_missed_req,
            "inProgressMissedReq": inprog_missed_req,
            "resolvedMissedReq": resolved_missed_req,

            "newSecurityGaps": new_sec_req,
            "knownSecurityGaps": known_sec_req,
            "inProgressSecurityGaps": inprog_sec_req,
            "resolvedSecurityGaps": resolved_sec_req,

            "newComplianceGaps": new_comp_req,
            "knownComplianceGaps": known_comp_req,
            "inProgressComplianceGaps": inprog_comp_req,
            "resolvedComplianceGaps": resolved_comp_req,

            "newPerformanceGaps": new_perf_req,
            "knownPerformanceGaps": known_perf_req,
            "inProgressPerformanceGaps": inprog_perf_req,
            "resolvedPerformanceGaps": resolved_perf_req,

            "newUsabilityGaps": new_usab_req,
            "knownUsabilityGaps": known_usab_req,
            "inProgressUsabilityGaps": inprog_usab_req,
            "resolvedUsabilityGaps": resolved_usab_req,

            "newOtherGaps": new_other_req,
            "knownOtherGaps": known_other_req,
            "inProgressOtherGaps": inprog_other_req,
            "resolvedOtherGaps": resolved_other_req,

            # Distinct-based final counts
            "mini_total_new": final_new,
            "mini_total_known": final_known,
            "mini_total_inprogress": final_inprog,
            "mini_total_resolved": final_resolved,
            "mini_total_open_all": final_open,

            # Carried over
            "mini_carried_over": carried_over_count,

            # Mean closure & feedback
            "mini_mean_closure_time": mini_mean_closure_time,
            "mini_feedback_impl_rate": feedback_impl_rate,

            # Additional open/new densities
            "mini_iter_open_defect_density": mini_iter_open_defect_density,
            "mini_iter_new_defect_density": mini_iter_new_defect_density,

            # Severity-based open densities
            "mini_iter_critical_defect_density": mini_iter_critical_defect_density,
            "mini_iter_high_defect_density": mini_iter_high_defect_density,
            "mini_iter_medium_defect_density": mini_iter_medium_defect_density,
            "mini_iter_low_defect_density": mini_iter_low_defect_density,

            # Rolling averages
            "mini_iter_rolling_avg_new_issues": mini_iter_rolling_avg_new_issues,
            "mini_iter_rolling_avg_defect_density": mini_iter_rolling_avg_defect_density,
            "mini_iter_rolling_avg_new_defect_density": mini_iter_rolling_avg_new_defect_density,

            # Final summary counts
            "mini_iter_new_issue_count": final_new,
            "mini_iter_known_issue_count": final_known,
            "mini_iter_inprogress_issue_count": final_inprog,
            "mini_iter_resolved_issue_count": final_resolved,
            "mini_iter_open_issue_count": final_open
        }

        if final_open != final_new + final_known + final_inprog:
            print(f"WARNING: mini-iter count mismatch "
                  f"(open={final_open}, new+known+inprog={final_new + final_known + final_inprog})")
        return result







    def compute_iteration_metrics(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        iteration_gap_counters: dict,
        iteration_data: dict,
        macro_baseline_rows_sum: int
    ):
        """
        Build macro-level metrics for iteration_summary_metrics.csv.
        Relies exclusively on each gap’s canonical record (firstSeen / resolvedIn / status).

        The implementation enforces two invariants for every macro-iteration N
          ID-1  total_open_all(N-1) == carried_over_count(N)
          ID-2  carried_over_count + total_new – total_resolved_this_macro == total_open_all
        If either identity is violated an AssertionError is raised.
        """

        # -------------------------------------------------------
        # 1) Basic timing
        # -------------------------------------------------------
        spent_time = (end_time - start_time).total_seconds()
        reopened_this_macro_ids = self.reopened_ids_per_macro.get(macro_iter_idx, set())
        resolved_but_reopened   = len(reopened_this_macro_ids)

        # -------------------------------------------------------
        # 2) Text analytics inputs
        # -------------------------------------------------------
        iteration_text_fragments = iteration_data.get("iteration_text_fragments", [])
        iteration_level_text = " ".join(iteration_text_fragments)

        # 3) Table-row churn
        macro_total_added   = iteration_data.get("macro_total_added_rows", 0)
        macro_total_removed = iteration_data.get("macro_total_removed_rows", 0)
        macro_total_changed = iteration_data.get("macro_total_changed_rows", 0)
        forced_macro_complexity = iteration_data.get("macro_final_table_complexity")
        # 4) Lexical stats
        iteration_lexical_density   = MetricsCalculator.calculate_lexical_density(iteration_level_text)
        iteration_unique_term_ratio = MetricsCalculator.calculate_unique_term_ratio(iteration_level_text)

        # 5) Churn %
        total_edit_ops = macro_total_added + macro_total_removed + macro_total_changed
        macro_churn_pct = round((total_edit_ops / macro_baseline_rows_sum) * 100, 2) if macro_baseline_rows_sum else 0.0

        # -------------------------------------------------------
        # 6) Classify every gap for this macro
        # -------------------------------------------------------
        recognized_gap_types = [
            "MissedRequirement", "SecurityGap", "ComplianceGap",
            "PerformanceGap", "UsabilityGap", "Other"
        ]

        new_gaps_by_type      = {gt: set() for gt in recognized_gap_types}
        known_gaps_by_type    = {gt: set() for gt in recognized_gap_types}
        inprog_gaps_by_type   = {gt: set() for gt in recognized_gap_types}
        resolved_gaps_by_type = {gt: set() for gt in recognized_gap_types}

        combined_open_set          = set()
        combined_resolved_set      = set()
        resolved_in_this_macro_set = set()

        for gid, rec in self.issue_first_seen_iteration.items():
            if not isinstance(rec, dict):
                continue

            r_in      = rec.get("resolvedIn")                     # (macro, phase, mini) or None
            fs_macro  = rec.get("firstSeen", (0, "", 0))[0]
            gtype     = rec.get("finalGapType",
                                 rec.get("initialGapType", "Other"))
            if gtype not in recognized_gap_types:
                gtype = "Other"

            # ---------- classify by discovery moment ---------------
            if fs_macro == macro_iter_idx:                        # new this macro
                new_gaps_by_type[gtype].add(gid)
            elif fs_macro < macro_iter_idx:                       # discovered earlier
                # count as “known” only if it was open at macro start
                if (
                    (r_in is None or r_in[0] >= macro_iter_idx) and
                    gid not in reopened_this_macro_ids
                ):
                    known_gaps_by_type[gtype].add(gid)

            # ---------- classify by final status -------------------
            final_st = rec.get("status", "NewIssue")
            if final_st in {"NewIssue", "KnownIssue", "InProgress"}:
                combined_open_set.add(gid)
                if final_st == "InProgress":
                    inprog_gaps_by_type[gtype].add(gid)
            elif final_st == "Resolved":
                combined_resolved_set.add(gid)
                resolved_gaps_by_type[gtype].add(gid)
                if r_in and r_in[0] == macro_iter_idx:
                    resolved_in_this_macro_set.add(gid)

        # --- totals needed for later calculations -----------------
        total_known       = sum(len(s) for s in known_gaps_by_type.values())
        total_inprogress  = sum(len(s) for s in inprog_gaps_by_type.values())

        # -------------------------------------------------------
        # 6 a) Carried-over from previous macro (frozen snapshot)
        # -------------------------------------------------------
        if macro_iter_idx > 1:
            try:
                carried_over_count = len(self._carryover_open_ids_start)
                carried_over_by_type = {
                    gt: ids.copy() for gt, ids in self._carryover_by_type_start.items()
                }
            except AttributeError as e:
                raise RuntimeError(
                    "Snapshot carry-over sets not initialised before compute_iteration_metrics()"
                ) from e
        else:
            carried_over_count = 0
            carried_over_by_type = {}

        # -------------------------------------------------------
        # 6 b) Resolved counters (raw + net)
        # -------------------------------------------------------
        total_resolved_all_raw        = len(combined_resolved_set)
        total_resolved_this_macro_raw = len(resolved_in_this_macro_set)
        resolved_reopened_count       = len(reopened_this_macro_ids &
                                            resolved_in_this_macro_set)
        total_resolved_this_macro     = (
            total_resolved_this_macro_raw - resolved_reopened_count
        )  # NET

        # -------------------------------------------------------
        # 6 c) Authoritative open-count at end of macro
        # -------------------------------------------------------
        total_new           = sum(len(s) for s in new_gaps_by_type.values())
        reopened_still_open = len(reopened_this_macro_ids & combined_open_set)
        total_open_all      = (
            total_known + total_new - total_resolved_this_macro + reopened_still_open
        )

        # -------------------------------------------------------
        # 6 d) Per-type tallies
        # -------------------------------------------------------
        macro_newMissedReq            = len(new_gaps_by_type["MissedRequirement"])
        macro_knownMissedReq          = len(known_gaps_by_type["MissedRequirement"])
        macro_inprogMissedReq         = len(inprog_gaps_by_type["MissedRequirement"])
        macro_resolvedMissedReq       = len(resolved_gaps_by_type["MissedRequirement"])

        macro_newSecurityGaps         = len(new_gaps_by_type["SecurityGap"])
        macro_knownSecurityGaps       = len(known_gaps_by_type["SecurityGap"])
        macro_inprogSecurityGaps      = len(inprog_gaps_by_type["SecurityGap"])
        macro_resolvedSecurityGaps    = len(resolved_gaps_by_type["SecurityGap"])

        macro_newComplianceGaps       = len(new_gaps_by_type["ComplianceGap"])
        macro_knownComplianceGaps     = len(known_gaps_by_type["ComplianceGap"])
        macro_inprogComplianceGaps    = len(inprog_gaps_by_type["ComplianceGap"])
        macro_resolvedComplianceGaps  = len(resolved_gaps_by_type["ComplianceGap"])

        macro_newPerformanceGaps      = len(new_gaps_by_type["PerformanceGap"])
        macro_knownPerformanceGaps    = len(known_gaps_by_type["PerformanceGap"])
        macro_inprogPerformanceGaps   = len(inprog_gaps_by_type["PerformanceGap"])
        macro_resolvedPerformanceGaps = len(resolved_gaps_by_type["PerformanceGap"])

        macro_newUsabilityGaps        = len(new_gaps_by_type["UsabilityGap"])
        macro_knownUsabilityGaps      = len(known_gaps_by_type["UsabilityGap"])
        macro_inprogUsabilityGaps     = len(inprog_gaps_by_type["UsabilityGap"])
        macro_resolvedUsabilityGaps   = len(resolved_gaps_by_type["UsabilityGap"])

        macro_newOtherGaps            = len(new_gaps_by_type["Other"])
        macro_knownOtherGaps          = len(known_gaps_by_type["Other"])
        macro_inprogOtherGaps         = len(inprog_gaps_by_type["Other"])
        macro_resolvedOtherGaps       = len(resolved_gaps_by_type["Other"])

        # -------------------------------------------------------
        # 6 e) Invariant guard-rails (hard-fail)
        # -------------------------------------------------------
        # Balance (ID-2)
        lhs_balance = (
            total_known + total_new - total_resolved_this_macro + reopened_still_open
        )
        if lhs_balance != total_open_all:
            print(
                f"WARNING: [ID-2] Balance equation violated in macro {macro_iter_idx} "
                f"(lhs={lhs_balance}, rhs={total_open_all})"
            )

        # Continuity (ID-1)
        if macro_iter_idx > 1:
            prev_open = getattr(self, "_prev_open_all", carried_over_count)
            if carried_over_count != prev_open:
                print(
                    f"WARNING: [ID-1] Carry-over mismatch in macro {macro_iter_idx} "
                    f"(prev={prev_open}, now={carried_over_count})"
                )

        # store for next macro’s ID-1 check
        self._prev_open_all = total_open_all
        # -------------------------------------------------------
        # 8) Mean closure time
        # -------------------------------------------------------
        resolved_durations = []
        for rec in self.issue_first_seen_iteration.values():
            if isinstance(rec, dict) and rec.get("status") == "Resolved":
                fsgm = rec.get("firstSeenGlobalMini")
                rsgm = rec.get("resolvedInGlobalMini")
                if fsgm is not None and rsgm is not None and rsgm >= fsgm:
                    resolved_durations.append((rsgm - fsgm) + 1)
        mean_closure_time = round(sum(resolved_durations) / len(resolved_durations), 2) if resolved_durations else 0.0

        # -------------------------------------------------------
        # 9) Feedback-implementation rate
        # -------------------------------------------------------
        feedback_impl_rate = 0.0
        if macro_iter_idx > 1 and carried_over_count:
            resolved_from_prev = sum(
                1
                for gid, rec in self.issue_first_seen_iteration.items()
                if isinstance(rec, dict)
                and rec.get("firstSeen", (0, "", 0))[0] < macro_iter_idx
                and rec.get("status") == "Resolved"
                and rec.get("resolvedIn", (0, "", 0))[0] == macro_iter_idx
            )
            feedback_impl_rate = round(100.0 * resolved_from_prev / carried_over_count, 2)

        # -------------------------------------------------------
        # 10) Table-complexity & trace-coverage
        # -------------------------------------------------------
        final_trace_cov_weighted_sum = 0.0
        final_trace_row_count = 0

        if forced_macro_complexity is not None:
            # caller supplied explicit complexity (e.g., 442, 567)
            try:
                final_macro_table_complexity = int(forced_macro_complexity)
            except (TypeError, ValueError) as exc:
                raise RuntimeError(
                    "macro_final_table_complexity must be an integer"
                ) from exc
        else:
            final_artifact_map = self.get_final_artifact_versions_for_macro(macro_iter_idx)
            final_macro_table_complexity = 0
            for art_dict in final_artifact_map.values():
                size_for_art = MetricsCalculator.measure_table_complexity(art_dict)
                final_macro_table_complexity += size_for_art
                cov_pct = MetricsCalculator.measure_traceability_coverage(art_dict, "Related Reqs")
                if cov_pct is not None:
                    rows = len(art_dict.get("rows", []))
                    final_trace_cov_weighted_sum += ((cov_pct / 100.0) * rows)
                    final_trace_row_count += rows
        final_macro_trace_coverage = round(
            100.0 * final_trace_cov_weighted_sum / final_trace_row_count, 2
        ) if final_trace_row_count else 0.0

        # -------------------------------------------------------
        # 11) Open-defect densities by severity
        # -------------------------------------------------------
        sev_counter = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        for gid in combined_open_set:
            sev = self.issue_first_seen_iteration.get(gid, {}).get(
                "finalSeverity",
                self.issue_first_seen_iteration[gid].get("initialSeverity", "Medium")
            ).lower()
            if sev not in sev_counter:
                sev = "low"
            sev_counter[sev] += 1

        if final_macro_table_complexity:
            final_macro_open_defect_density = round(len(combined_open_set) / final_macro_table_complexity, 3)
            final_macro_new_defect_density  = round(total_new / final_macro_table_complexity, 3)
            final_macro_critical_defect_density = round(sev_counter["critical"] / final_macro_table_complexity, 3)
            final_macro_high_defect_density     = round(sev_counter["high"] / final_macro_table_complexity, 3)
            final_macro_medium_defect_density   = round(sev_counter["medium"] / final_macro_table_complexity, 3)
            final_macro_low_defect_density      = round(sev_counter["low"] / final_macro_table_complexity, 3)
        else:
            final_macro_open_defect_density = final_macro_new_defect_density = 0.0
            final_macro_critical_defect_density = final_macro_high_defect_density = 0.0
            final_macro_medium_defect_density = final_macro_low_defect_density = 0.0

        # -------------------------------------------------------
        # 12) Rolling averages (window = 3 macros)
        # -------------------------------------------------------
        if not hasattr(self, "macro_history"):
            self.macro_history = {}
        self.macro_history[macro_iter_idx] = {
            "newIssues": total_new,
            "openDefDensity": final_macro_open_defect_density,
            "newDefDensity": final_macro_new_defect_density
        }
        window = 3
        macros_in_window = [
            m for m in sorted(self.macro_history) if m >= macro_iter_idx - window + 1
        ]
        if macros_in_window:
            avg_new = round(sum(self.macro_history[m]["newIssues"] for m in macros_in_window) / len(macros_in_window), 2)
            avg_open_d = round(sum(self.macro_history[m]["openDefDensity"] for m in macros_in_window) / len(macros_in_window), 3)
            avg_new_d  = round(sum(self.macro_history[m]["newDefDensity"]  for m in macros_in_window) / len(macros_in_window), 3)
        else:
            avg_new = float(total_new)
            avg_open_d = final_macro_open_defect_density
            avg_new_d  = final_macro_new_defect_density

        # ---------- macro_issue_load KPI (v1.3.1) ------------------------------
        default_ws = {"NewIssue": 5, "KnownIssue": 4, "InProgress": 1, "Resolved": 0}
        default_wv = {"critical": 5, "high": 3, "medium": 2, "low": 1}

        cfg = self.sim_config.get("issue_load_weights", {})
        ws  = {**default_ws, **cfg.get("status",   {})}
        wv  = {**default_wv, **cfg.get("severity", {})}

        score_grid = {st: {sv: 0 for sv in wv} for st in ws}

        # open gaps
        for gid in combined_open_set:
            rec = self.issue_first_seen_iteration[gid]
            st  = rec.get("status", "NewIssue")
            sv  = (rec.get("finalSeverity") or
                  rec.get("initialSeverity", "low")).lower()
            if sv not in wv:
                sv = "low"
            score_grid[st][sv] += 1

        # resolved gaps
        for lst in resolved_gaps_by_type.values():
            for gid in lst:
                rec = self.issue_first_seen_iteration[gid]
                sv  = (rec.get("finalSeverity") or
                      rec.get("initialSeverity", "low")).lower()
                if sv not in wv:
                    sv = "low"
                score_grid["Resolved"][sv] += 1

        S = sum(ws[st] * wv[sv] * n
                for st, row in score_grid.items()
                for sv, n in row.items())

        issue_load = 0.0 if not final_macro_table_complexity else \
                    round(S / final_macro_table_complexity, 4)
        # -------------------------------------------------------
        # 13) Return metrics dictionary
        # -------------------------------------------------------
        return {
            "macro_iter_idx": macro_iter_idx,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "spent_time_sec": spent_time,

            "macro_lexical_density": iteration_lexical_density,
            "macro_unique_term_ratio": iteration_unique_term_ratio,
            "macro_artifact_churn_pct": macro_churn_pct,

            "total_new": total_new,
            "total_known": total_known,
            "total_inprogress": total_inprogress,
            "total_resolved": total_resolved_all_raw,
            "total_open_all": total_open_all,

            "macro_newMissedReq": macro_newMissedReq,
            "macro_knownMissedReq": macro_knownMissedReq,
            "macro_inprogMissedReq": macro_inprogMissedReq,
            "macro_resolvedMissedReq": macro_resolvedMissedReq,

            "macro_newSecurityGaps": macro_newSecurityGaps,
            "macro_knownSecurityGaps": macro_knownSecurityGaps,
            "macro_inprogSecurityGaps": macro_inprogSecurityGaps,
            "macro_resolvedSecurityGaps": macro_resolvedSecurityGaps,

            "macro_newComplianceGaps": macro_newComplianceGaps,
            "macro_knownComplianceGaps": macro_knownComplianceGaps,
            "macro_inprogComplianceGaps": macro_inprogComplianceGaps,
            "macro_resolvedComplianceGaps": macro_resolvedComplianceGaps,

            "macro_newPerformanceGaps": macro_newPerformanceGaps,
            "macro_knownPerformanceGaps": macro_knownPerformanceGaps,
            "macro_inprogPerformanceGaps": macro_inprogPerformanceGaps,
            "macro_resolvedPerformanceGaps": macro_resolvedPerformanceGaps,

            "macro_newUsabilityGaps": macro_newUsabilityGaps,
            "macro_knownUsabilityGaps": macro_knownUsabilityGaps,
            "macro_inprogUsabilityGaps": macro_inprogUsabilityGaps,
            "macro_resolvedUsabilityGaps": macro_resolvedUsabilityGaps,

            "macro_newOtherGaps": macro_newOtherGaps,
            "macro_knownOtherGaps": macro_knownOtherGaps,
            "macro_inprogOtherGaps": macro_inprogOtherGaps,
            "macro_resolvedOtherGaps": macro_resolvedOtherGaps,

            "carried_over": carried_over_count,
            "mean_closure_time": mean_closure_time,
            "total_resolved_this_macro": total_resolved_this_macro,   # NET value
            "resolved_but_reopened": resolved_but_reopened,
            "phase_crossings_critical": 0.0,
            "phase_crossings_avg": 0.0,
            "feedback_impl_rate": feedback_impl_rate,

            "final_macro_table_complexity": final_macro_table_complexity,
            "final_macro_trace_coverage": final_macro_trace_coverage,

            "final_macro_open_defect_density": final_macro_open_defect_density,
            "final_macro_new_defect_density": final_macro_new_defect_density,
            "final_macro_critical_defect_density": final_macro_critical_defect_density,
            "final_macro_high_defect_density": final_macro_high_defect_density,
            "final_macro_medium_defect_density": final_macro_medium_defect_density,
            "final_macro_low_defect_density": final_macro_low_defect_density,

            "iter_rolling_avg_new_issues": avg_new,
            "iter_rolling_avg_open_defect_density": avg_open_d,
            "iter_rolling_avg_new_defect_density": avg_new_d,
            "macro_issue_load": issue_load
        }
















    # ---------------------------------------------------------------
    # "write_iteration_reports(...)" helper
    # ---------------------------------------------------------------

    def write_iteration_reports(
        self,
        iteration_idx: int,
        metrics: dict,
        iteration_data: dict
    ) -> None:
        """
        Writes macro-level metrics into iteration_summary_metrics.csv and also logs
        some bullet points to doc_teacher. This function is updated to fully align
        with the new aggregator output from compute_iteration_metrics(...), matching
        all final naming conventions and avoiding any mismatches or old fields.

        Parameters
        ----------
        iteration_idx : int
            The macro-level iteration index (e.g., 1, 2, 3...).
        metrics : dict
            A dictionary returned by compute_iteration_metrics, containing keys such as:
              "start_time", "end_time", "spent_time_sec",
              "macro_lexical_density", "macro_unique_term_ratio",
              "macro_artifact_churn_pct",
              "total_new", "total_known", "total_inprogress", "total_resolved", "total_open_all",
              "macro_newMissedReq", "macro_knownMissedReq", "macro_inprogMissedReq", "macro_resolvedMissedReq",
              "macro_newSecurityGaps", "macro_knownSecurityGaps", "macro_inprogSecurityGaps", "macro_resolvedSecurityGaps",
              "macro_newComplianceGaps", "macro_knownComplianceGaps", "macro_inprogComplianceGaps", "macro_resolvedComplianceGaps",
              "macro_newPerformanceGaps", "macro_knownPerformanceGaps", "macro_inprogPerformanceGaps", "macro_resolvedPerformanceGaps",
              "macro_newUsabilityGaps", "macro_knownUsabilityGaps", "macro_inprogUsabilityGaps", "macro_resolvedUsabilityGaps",
              "macro_newOtherGaps", "macro_knownOtherGaps", "macro_inprogOtherGaps", "macro_resolvedOtherGaps",
              "carried_over", "mean_closure_time", "total_resolved_this_macro",
              "phase_crossings_critical", "phase_crossings_avg", "feedback_impl_rate",
              "final_macro_table_complexity", "final_macro_trace_coverage",
              "final_macro_open_defect_density", "final_macro_new_defect_density",
              "final_macro_critical_defect_density", "final_macro_high_defect_density",
              "final_macro_medium_defect_density", "final_macro_low_defect_density",
              "iter_rolling_avg_new_issues", "iter_rolling_avg_open_defect_density",
              "iter_rolling_avg_new_defect_density", ...
            (Any additional fields may also be present if desired.)
        iteration_data : dict
            A dictionary that can hold aggregated row changes or other roll-ups for
            the entire macro. For example:
              iteration_data["macro_total_added_rows"] = total number of added rows
              iteration_data["macro_total_removed_rows"] = total removed
              iteration_data["macro_total_changed_rows"] = total changed
            etc.

        Returns
        -------
        None
            Appends exactly one row to iteration_summary_metrics.csv for this macro.
            Also logs some textual bullet points to self.doc_teacher.
        """

        # ----------------------------------------------------------------
        # A) Write some bullet points to the doc_teacher as a summary
        # ----------------------------------------------------------------
        # (You can customize these messages as needed; here we show an example.)
        self.doc_teacher.add_paragraph(
            f"Feedback Implementation Rate: {metrics['feedback_impl_rate']}%",
            style='List Bullet 2'
        )
        self.doc_teacher.add_paragraph(
            f"Mean Closure Time: {metrics['mean_closure_time']} iteration(s)",
            style='List Bullet 2'
        )

        self.doc_teacher.add_paragraph(
            f"Macro Iteration {iteration_idx} Summary:",
            style='List Bullet'
        )
        self.doc_teacher.add_paragraph(
            f"Total new issues: {metrics['total_new']}",
            style='List Bullet 2'
        )
        self.doc_teacher.add_paragraph(
            f"Total known (carried in) issues: {metrics['total_known']}",
            style='List Bullet 2'
        )
        self.doc_teacher.add_paragraph(
            f"Total in-progress: {metrics['total_inprogress']}",
            style='List Bullet 2'
        )
        self.doc_teacher.add_paragraph(
            f"Total resolved: {metrics['total_resolved']}",
            style='List Bullet 2'
        )

        # (Optional) If you want a quick mention of the type-specific stats:
        # e.g. "MissedReq new: metrics['macro_newMissedReq']", etc.
        # self.doc_teacher.add_paragraph(
        #     f"MissedReq: new={metrics['macro_newMissedReq']}, known={metrics['macro_knownMissedReq']}, "
        #     f"inprog={metrics['macro_inprogMissedReq']}, resolved={metrics['macro_resolvedMissedReq']}",
        #     style='List Bullet 2'
        # )

        # ----------------------------------------------------------------
        # B) Construct row_data for iteration_summary_metrics.csv
        #    in a consistent, final order that matches the new aggregator
        # ----------------------------------------------------------------

        # For row changes, we assume iteration_data has these keys:
        #   "macro_total_added_rows", "macro_total_removed_rows",
        #   "macro_total_changed_rows"
        # If your aggregator placed them in metrics, adjust accordingly.
        added_rows   = iteration_data.get("macro_total_added_rows", 0)
        removed_rows = iteration_data.get("macro_total_removed_rows", 0)
        changed_rows = iteration_data.get("macro_total_changed_rows", 0)

        # Build the row in a stable, documented order:
        # Below is just one example that includes each major aggregator field;
        # you can reorder or omit as suits your final CSV schema. The main requirement
        # is that each key matches the aggregator output exactly.

        row_data = [
            iteration_idx,
            metrics["start_time"],
            metrics["end_time"],
            metrics["spent_time_sec"],

            metrics["macro_lexical_density"],
            metrics["macro_unique_term_ratio"],
            metrics["macro_artifact_churn_pct"],

            metrics["total_new"],
            metrics["total_known"],
            metrics["total_inprogress"],
            metrics["total_resolved"],
            metrics["total_open_all"],

            metrics["macro_newMissedReq"],
            metrics["macro_knownMissedReq"],
            metrics["macro_inprogMissedReq"],
            metrics["macro_resolvedMissedReq"],

            metrics["macro_newSecurityGaps"],
            metrics["macro_knownSecurityGaps"],
            metrics["macro_inprogSecurityGaps"],
            metrics["macro_resolvedSecurityGaps"],

            metrics["macro_newComplianceGaps"],
            metrics["macro_knownComplianceGaps"],
            metrics["macro_inprogComplianceGaps"],
            metrics["macro_resolvedComplianceGaps"],

            metrics["macro_newPerformanceGaps"],
            metrics["macro_knownPerformanceGaps"],
            metrics["macro_inprogPerformanceGaps"],
            metrics["macro_resolvedPerformanceGaps"],

            metrics["macro_newUsabilityGaps"],
            metrics["macro_knownUsabilityGaps"],
            metrics["macro_inprogUsabilityGaps"],
            metrics["macro_resolvedUsabilityGaps"],

            metrics["macro_newOtherGaps"],
            metrics["macro_knownOtherGaps"],
            metrics["macro_inprogOtherGaps"],
            metrics["macro_resolvedOtherGaps"],

            metrics["carried_over"],
            metrics["mean_closure_time"],
            metrics["total_resolved_this_macro"],
            metrics["resolved_but_reopened"],
            metrics["phase_crossings_critical"],
            metrics["phase_crossings_avg"],
            metrics["feedback_impl_rate"],

            metrics["final_macro_table_complexity"],
            metrics["final_macro_trace_coverage"],

            metrics["final_macro_open_defect_density"],
            metrics["final_macro_new_defect_density"],
            metrics["final_macro_critical_defect_density"],
            metrics["final_macro_high_defect_density"],
            metrics["final_macro_medium_defect_density"],
            metrics["final_macro_low_defect_density"],

            metrics["iter_rolling_avg_new_issues"],
            metrics["iter_rolling_avg_open_defect_density"],
            metrics["iter_rolling_avg_new_defect_density"],
            metrics["macro_issue_load"],

            # Summation of row changes:
            iteration_data.get("macro_total_added_rows", 0),
            iteration_data.get("macro_total_removed_rows", 0),
            iteration_data.get("macro_total_changed_rows", 0)
        ]


        # ----------------------------------------------------------------
        # C) Append the row to iteration_summary_metrics.csv
        # ----------------------------------------------------------------
        with open(self.iteration_summary_file, "a", newline="", encoding="utf-8") as summ_f:
            summ_writer = csv.writer(summ_f)
            summ_writer.writerow(row_data)





    def record_artifact_issues_in_teacher_doc(self, macro_iter_idx, phase_name, mini_iter_idx, artifact_index):
        final_issues = (
            self.feedback_storage
                .get(macro_iter_idx, {})
                .get(phase_name, {})
                .get(mini_iter_idx, {})
                .get(artifact_index, [])
        )
        if not final_issues:
            return

        for iss in final_issues:
            gap_id         = iss.get("gapID")
            gap_type       = iss.get("gapType")
            short_desc     = iss.get("shortDescription", "")
            known_issue    = iss.get("knownIssue", "")
            impact         = iss.get("impact", "")
            recommendation = iss.get("recommendation", "")

            msg = (
                f"gapID={gap_id}, gapType={gap_type},\n"
                f"Desc={short_desc},\n"
                f"Status={known_issue}, Impact={impact},\n"
                f"Recommendation={recommendation}"
            )
            self.doc_teacher.add_paragraph(msg, style='List Bullet 2')

    def _timeline_by_gap(self):
        """Return {gapID: [events…]} sorted chronologically."""
        import collections
        conv = collections.defaultdict(list)
        for (gid, art), (first, snap) in self._gap_artifact_tracker.items():
            if snap is None:
                continue
            status, impact, macro, phase, mini = snap
            conv[gid].append({
                "artifact_index": art,
                "status": status,
                "impact": impact,
                "macro": macro,
                "phase": phase,
                "mini": mini,
            })
        # ensure chronological order inside each list
        conv = {g: sorted(L,
                          key=lambda e: (e["macro"],
                                        self.phase_index_map.get(e["phase"], -1),
                                        e["mini"]))
                for g, L in conv.items()}
        return conv

    ########################################################################
    # 4) UPDATED summarize_lessons_learned_for_mini_iteration with FR-32 support
    ########################################################################
    # 4) UPDATED summarize_lessons_learned_for_mini_iteration – always table
    def summarize_lessons_learned_for_mini_iteration(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int
    ) -> str:
        """
        Collates issues for a mini-iteration, asks the LLM for
        root-causes / lessons / processChanges, applies approved changes,
        and returns a human-readable summary.

        ▪ Uses the new ``_gap_artifact_tracker`` timeline so every cell of the
          matrix shows the *latest* (Status / Impact) combination that ever
          occurred for the <gapID ⇆ artifact> pair.
        ▪ Always renders a table, even when ≤20 gaps are present; pages are
          split into 10-column chunks.
        """
        # ————————————————— DEBUG —————————————————
        print(
            f"retrospective_problem|RETRO|START|macro={macro_iter_idx}"
            f"|phase={phase_name}|mini={mini_iter_idx}",
            file=sys.stderr
        )
        # ------------------------------------------------------------------
        # 0) Build chronological timeline grouped by gapID
        # ------------------------------------------------------------------
        gap_events: dict[str, list] = self._timeline_by_gap()

        # ------------------------------------------------------------------
        # 1) Gather *all* issues that belong to this mini-iteration
        # ------------------------------------------------------------------
        if getattr(self, "backwardCompatibilityMode", False):
            # STANDARD MODE → collect every phase/mini in this macro
            macro_dict = self.feedback_storage.get(macro_iter_idx, {})
            mini_dict: dict[str, list] = {}
            for phase_data in macro_dict.values():
                for m_data in phase_data.values():
                    for art_idx, iss_list in m_data.items():
                        mini_dict.setdefault(art_idx, []).extend(iss_list)
        else:
            # ENHANCED MODE → issues only from current phase & mini
            mini_dict = (
                self.feedback_storage
                    .get(macro_iter_idx, {})
                    .get(phase_name, {})
                    .get(mini_iter_idx, {})
            )

        all_issues_list = [iss for per_art in mini_dict.values() for iss in per_art]

        # keep only the latest status per gapID (within this mini)
        unique_map: dict[str, dict] = {}
        for iss in all_issues_list:
            gid = str(iss.get("gapID", "")).strip()
            if gid:
                unique_map[gid] = iss
        final_issues = list(unique_map.values())

        # ------------------------------------------------------------------
        # 2 bis) Collect decision crumbs (notesFromLLM) for the scope
        # ------------------------------------------------------------------
        from collections import defaultdict
        crumb_map: defaultdict[str, list[str]] = defaultdict(list)

        def _add_crumbs(art_idx: str, art_dict: dict):
            meta  = (art_dict or {}).get("metadata") or {}
            notes = meta.get("notesFromLLM", "")
            if not notes:
                return
            for token in (t.strip() for t in notes.split("|")):
                if token.startswith("# DEC-"):
                    crumb_map[art_idx].append(token[:120])      # 120-char guard

        if hasattr(self, "artifact_versions"):
            if getattr(self, "backwardCompatibilityMode", False):
                for ph_dict in self.artifact_versions.get(macro_iter_idx, {}).values():
                    for mini_dict2 in ph_dict.values():
                        for idx2, art2 in mini_dict2.items():
                            _add_crumbs(idx2, art2)
            else:
                for idx2, art2 in (
                    self.artifact_versions
                        .get(macro_iter_idx, {})
                        .get(phase_name, {})
                        .get(mini_iter_idx, {})
                        .items()
                ):
                    _add_crumbs(idx2, art2)

        crumb_lines: list[str] = ["DECISION-CRUMBS:"]
        for idx2 in sorted(crumb_map):
            crumb_lines.append(f"{idx2}: " + " | ".join(crumb_map[idx2][-3:]))  # last ≤3 crumbs
        decision_crumbs_text: str = "\n".join(crumb_lines) if len(crumb_lines) > 1 else ""


        # ==================================================================
        # 2) Build context blocks (stats, snapshots, artifact overview)
        # ==================================================================
        from collections import Counter, defaultdict
        import json, math, textwrap

        # helper must be defined **before** any first call
        def _sanitize(txt: str) -> str:
            """Collapse pipes/newlines → spaces and trim."""
            return str(txt).replace("|", "/").replace("\n", " ").strip()

        total_issues = len(final_issues)
        new_cnt      = sum(i["knownIssue"] == "NewIssue"  for i in final_issues)
        resolved_cnt = sum(i["knownIssue"] == "Resolved" for i in final_issues)
        open_cnt     = total_issues - resolved_cnt
        crit_open    = sum(i.get("impact", "").lower() == "critical" for i in final_issues)
        high_open    = sum(i.get("impact", "").lower() == "high"      for i in final_issues)
        carried_over = len(getattr(self, "_carryover_open_ids_start", set()))
        delta_open   = open_cnt - carried_over

        iter_stats_text = (
            f"ITERATION-STATS: total={total_issues}, new={new_cnt}, "
            f"resolved={resolved_cnt}, stillOpen={open_cnt}, "
            f"criticalOpen={crit_open}, highOpen={high_open}, deltaOpen={delta_open}"
        )

        gt_counter = Counter(
            i["gapType"] for i in final_issues if i["knownIssue"] != "Resolved"
        )
        gaptype_text = "GAP-TYPE SNAPSHOT: " + " | ".join(
            f"{gt} open={cnt}" for gt, cnt in gt_counter.most_common()
        )

        # ------------------------------------------------------------------
        # 3) Artifact overview & list of artifacts we must display
        # ------------------------------------------------------------------
        # artifacts that appear in THIS mini
        artifacts_in_mini: set[str] = {
            idx for idx in mini_dict.keys()
            if not str(idx).startswith("_")
        }

        # plus every artifact that ever interacted with the gaps in columns
        for gid in unique_map:
            for ev in gap_events.get(gid, []):
                art_id = ev["artifact_index"]
                if not str(art_id).startswith("_"):          # skip “_GLOBAL_CARRY_”, etc.
                    artifacts_in_mini.add(art_id)

        # materialise metadata (simple alphabetical ordering for stability)
        sorted_arts: list[tuple[str, dict]] = []
        for art_idx in sorted(artifacts_in_mini, key=str):
            if str(art_idx).startswith("_"):          # e.g. “_GLOBAL_CARRY_”
                continue
            meta = next(
                (t for t in self.tables if t["Artifact_index"] == art_idx), {}
            )
            sorted_arts.append((art_idx, meta))

        overview_lines: list[str] = ["ARTIFACT OVERVIEW:"]
        for art_idx, meta in sorted_arts:
            # count OPEN issues for this artifact now (optional stats)
            open_i = sum(
                1
                for ev in gap_events.values()
                for e in (ev if isinstance(ev, list) else [])
                if e["artifact_index"] == art_idx and e["status"] != "Resolved"
            )
            instr_full = _sanitize(meta.get('custom_instructions', ''))
            overview_lines.append(
                f"── {art_idx}  {meta.get('Artifact_name', '?')}\n"
                f"   • type: {meta.get('Artifact_type', '?')}  |  "
                f"columns: {meta.get('Artifact_columns', '?')}  |  "
                f"open gaps: {open_i}\n"
                f"   • instructions: {instr_full}"
            )
        artifact_overview_text = "\n".join(overview_lines)

        # ------------------------------------------------------------------
        # 4) Build the ISSUE-MATRIX  (always table, 10 gapID columns / page)
        # ------------------------------------------------------------------
        status_map = {"NewIssue": "N", "KnownIssue": "K",
                      "InProgress": "I", "Resolved": "R"}
        impact_map = {"critical": "C", "high": "H",
                      "medium": "M",   "low": "L"}


        # canonical description → global fallback if not in this mini
        canon_desc: dict[str, str] = {}
        for gid in unique_map:
            canon_desc[gid] = _sanitize(unique_map[gid].get("shortDescription", ""))
        for gid in gap_events:
            if gid not in canon_desc:
                rec = self.issue_first_seen_iteration.get(gid, {})
                canon_desc[gid] = _sanitize(
                    rec.get("shortDescription", rec.get("canonicalDesc", ""))
                )

        gap_id_list = sorted(canon_desc)  # deterministic order

        def _build_matrix(page_gap_ids: list[str],
                          page_idx: int,
                          total_pages: int) -> str:
            header = ["Artifact"] + page_gap_ids
            table_lines = [
                "| " + " | ".join(header) + " |",
                "| " + " | ".join("---" for _ in header) + " |",
            ]

            for art_idx, meta in sorted_arts:
                art_label = _sanitize(f"{art_idx} {meta.get('Artifact_name','')}")
                cells = []
                for gid in page_gap_ids:
                    ev_list = gap_events.get(gid, [])
                    cell = ""
                    if ev_list:
                        # ← pick the *latest* event for this artifact
                        latest = next(
                            (ev for ev in reversed(ev_list)
                            if ev["artifact_index"] == art_idx),
                            None
                        )
                        if latest:
                            nov = status_map.get(latest["status"], "?")
                            imp = impact_map.get(str(latest["impact"]).lower(), "?")
                            cell = f"{nov}/{imp}"
                    cells.append(cell)
                table_lines.append("| " + " | ".join([art_label] + cells) + " |")

            title = f"ISSUE-TABLE {page_idx}/{total_pages}"
            return f"\n{title}\n" + "\n".join(table_lines)

        def _batch(seq, n):
            for i in range(0, len(seq), n):
                yield seq[i: i + n]

        pages = []
        gaps_per_page = 10
        total_pages = math.ceil(len(gap_id_list) / gaps_per_page)
        for p_idx, gap_page in enumerate(_batch(gap_id_list, gaps_per_page), 1):
            pages.append(_build_matrix(gap_page, p_idx, total_pages))

        legend_text = textwrap.dedent(
            """\
            Legend:
            • Novelty → N (New) | K (Known) | I (In-Progress) | R (Resolved)
            • Impact  → C (Critical) | H (High) | M (Medium) | L (Low)
              Cell format = <Novelty>/<Impact>  e.g. N/H"""
        )

        canon_lines = ["\nCanonical issue descriptions:"]
        for gid in gap_id_list:
            canon_lines.append(f"- {gid}: {canon_desc.get(gid, '')}")

        issues_text = "\n".join([legend_text] + pages + canon_lines)

        # ------------------------------------------------------------------
        # 5) Current artifact catalogue (unchanged)
        # ------------------------------------------------------------------
        artifact_info_text = "Current Artifacts:\n" + "\n".join(
            f"Artifact {tbl['Artifact_index']} => columns: {tbl['Artifact_columns']}"
            for tbl in self.tables
            if not str(tbl.get("Artifact_index", "")).startswith("_")  # hide helpers
        )

        # ------------------------------------------------------------------
        # 6) Build the prompt  (artifact-gap map removed)
        # ------------------------------------------------------------------
        prompt = f"""
        You are a senior reviewer facilitating a retrospective for iteration
        (macro={macro_iter_idx}, phase={phase_name}, mini={mini_iter_idx}).

        Your job is to follow *Analysis workflow*, analyze issues and decisions, cluster them, present them as locator-prefixed pairs of lessons learned/root causes, if necessary - suggest and implement rare process changes.
        Do not output issues by just rephrasing them as is into issue-based root causes/lessons learned. Add value by clustering them/searching for root causes. Otherwise skip and do not emit such simply "restating" issues-based root causes - lessons learned. You must add value beyond issues; otherwise skip and do not emit.

        ### Analysis workflow (follow exactly)

        1. **Collect** all *open, non-waived* issues for this mini-iteration **including carried-over ones; de‑duplicate by canonical ID**; **if none open, emit no issue‑based pairs**.
        2. For each issue, **where visible and in this phase,** identify point of origin (exact artifact index) **if point of origin is in current phase - in that case shown as Novelty → N (New) (internal; do not emit 'N')** and issue propagation over artifacts; **else skip**.        3. Cluster all open issues by root causes of those issues. Map root causes to either one artifact, or multiple, or global.
        4. For each root cause formulate **non-redundant (not a restatement)** lesson learned (create a pair "root cause - lesson learned").
        5. **For issues**, decide if presenting each pair "root cause - lesson learned" to one artifact, multiple, or all (global) artifacts is necessary. Issue may be raised at the "wrong" artifact and may actually "belong" to other place. Use that as locator; **placeholders are non‑owners**.
           • If a root cause applies to several artifacts and you choose per‑artifact placement, **MUST emit one pair per affected artifact** (same text, different locator); these count toward the 20‑item cap
           • Use `global-xx` **whenever** **scope‑signaled** cross‑artifact or owner‑unclear; do not mix dotted indices on a `global-xx` line.
        6. Decide, if presenting each pair "root cause - lesson learned" to necessary artifact(s) is enough to fix the root cause: if the table(s) to which the "locator" points can accommodate that lesson learned **using visible schema only (exact labels from artifact_info_text)**; **prefer column-level; if uncertain, default to (Whole artifact)**.
        7. **Normalise** artifact and column names → lower-case, strip spaces/dashes/underscores/punctuation. Note: Normalization is for comparison only, never for emission.
        8. **Skip waived gaps** – if a gap is linked to empty "Related Reqs" *and* its `artifactIndex` starts with **1.1.0 – 1.1.4**, drop it **only when explicitly evidenced** from further analysis (**else do not waive**) (generate **no** rootCause, lesson, or processChanges for that gap).
        9. **Harvest decision crumbs** – every line under “DECISION-CRUMBS”.
          • Pattern `# DEC-nn: <WHAT> - <WHY>`
          • Cluster identical <WHAT> across artifacts (**case/space/punctuation‑normalised only; exact‑match WHAT**, ≤20 clusters, **stable** deterministic sort); **do not merge distinct <WHAT>; no synonyms or modifiers**.
          • **Major‑Decision Filter** - convert a crumb to a decision‑based pair **only if ≥2 hold or high‑impact singleton → MUST emit as `global-xx` first**; else drop**:
            (a) Cross‑artifact or cross‑phase impact; (b) High cost‑of‑change/irreversibility; (c) Security/compliance/identity baseline;
            (d) Cross‑service API/protocol or shared data‑schema baseline; (e) SLO/KPI framework standardisation.
          • **Global‑only locator** - decision‑based pairs MUST use `global-xx` (never artifact‑indexed); **emit first; never demote**; issue‑based pairs may also use global‑xx when scope is cross‑artifact **or owner‑unclear**.
          • **Cap & priority** - **strictly** keep at most **5** decision‑based pairs per retrospective; if >5 meet the filter, keep the highest‑impact by priority: **if impact unclear, sort by category**:
            Security/Compliance/Identity → Data‑model/Schema → Cross‑service Interfaces/APIs → Observability/KPI framework → Other.
          • In each decision-based pair, include only the **shortest meaningful (fewest words) ASCII‑only** **verbatim‑substring** (from <WHY> only) **with no extra words**; **strictly** do not include dotted artifact indexes anywhere in a global‑xx line (**0 dotted indices; 0 parentheses**); **prepend "because " on both; preserve meaning**.
          • In each decision-based pair, both rootCauses *AND* lessons_learned must contain **clear** <WHAT> and <WHY>, for example, "REST chosen for API because ..." so that downstream and upstream artifacts will be created using this decision.
          • Treat each cluster as a candidate root cause/lesson learned **(decision‑based)** (this mechanism will be later used to propagate project critical decisions not only downstream in current macroiteration, but also upstream in next).
          • If major decision made is correct and must be made visible to upstream artifacts in next iteration, output such "root cause - lesson learned" pair with "global-xx" locator.
        10. For each root‑cause cluster **and each chosen locator** produce one pair of "rootCauses"–"lessons_learned", prefixed with that locator; keep the pair aligned by index *i* across both arrays. After de-duplication, **strictly stably sort and de-duplicate pairs jointly (never separately)**, then split into the two arrays; **re-sort/renumber after Step 5 expansion**.
        11. **processChanges** – optional, *current phase only* (**others: skip**), **rare** (**default: []**), only if **lessons insufficient** and highly beneficial and locator‑pointed table(s) cannot accommodate textual lesson learned, ≤ 1 object per affected artifact (except extra objects for `add_table`), ordered by artifactIndex.
          • `type` ∈ {{`add_columns`, `modify_instructions`, `add_table`}}.
          • For `add_columns`, compare the *normalised* new name against existing names (see Analysis‑workflow **step 7**); **lexically** skip if a near‑duplicate exists.
        12. **Validate**: keys exactly `rootCauses`, `lessons_learned`, `processChanges`; arrays de-duplicated, ≤ 20 items `rootCauses`, ≤ 20 items `lessons_learned`; ≤ 5 items `processChanges`; every text item ≤ 30 words; output must be valid JSON.
        13. If any check fails, regenerate silently until it passes (no apology text).
        14. If clusters exceed 20, merge semantically similar **issues** **before Step 5 expansion** until rootCauses ≤ 20.
        15. If more than 5 schema fixes are possible, keep the 5 highest-impact ones (by possible effect: Critical → High → Medium → Low).

        **HARD-FAIL** if any rootCause, **lessons_learned** or processChanges cites a gap whose only remaining issue is an **empty “Related Reqs” cell** in artifacts 1.1.0 – 1.1.4.

        ## Guiding principle for processChanges
        ## • First diagnose rootCauses / lessons_learned.
        ## • If the problem would still recur after applying lessons (e.g. current columns/instructions can’t express the fix), add a column and/or sharpen instructions - if you expect that to be really beneficial.
        ## • Create a new table only when existing artifacts cannot capture the data clearly, even after adding columns/instructions - so, if you see a principle gap in pipeline.
        ## • If a crumb decision implies a structural change, emit the minimal set of processChanges needed across all affected artifacts **in this phase**.
        ## • If not sure whether to implement process change, or no process changes needed, return "processChanges": [].

        Your tasks
        1. rootCauses        – diagnose recurring patterns from stats / artifacts / decision crumbs .
        2. lessons_learned   – actionable, **non-redundant** advice to eliminate those patterns.
        3. processChanges – one schema fix per object if absolutely needed (add_columns · modify_instructions · add_table).

        Here are decision crumbs:
        {decision_crumbs_text}

        Below is the list of all issues and statuses of current iteration:
        {issues_text}

        Here is the current phase artifact list and their columns:
        {artifact_info_text}

        Here is the current iteration stats:
        {iter_stats_text}

        Here is the current gap type snapshot:
        {gaptype_text}

        Here is the current artifact overview:
        {artifact_overview_text}


        Formatting rules
        • `rootCauses` and `lessons_learned`: telegraphic, ≤ 30 words, no period, always prefixed by locator.
        • Word‑count rule: hyphen‑joined terms count as one word (e.g., rate‑limit)
        • Remove duplicates.
        • **Strictly sort pairs jointly by locator within buckets** to preserve index alignment; order global‑xx before numeric indices; for numeric indices use **strict natural sort** by dot‑separated numbers (e.g., 1.1.4 < 1.1.10 < 1.2) **not lexicographic**.
        • Arrays must be sorted by locator **within buckets**, with global‑xx ordered before numeric indices.
        • Assign global‑1..n with decision‑based pairs capped at 5 and numbered first; **start arrays with global‑xx if any;** then number any issue‑based global pairs; sort by priority (above) then by <WHAT>; **renumber after Step 5**.
        • Hard-fail: any rootCause or lesson > 30 words will be rejected.
        • For column‑level advice, add the column name in parentheses. For row‑level advice, add the row name in parentheses; **if unknown, use (Whole artifact)**. For cell‑level advice add column and row names in parenthesis.
        • Exactly **one** artifactIndex per processChanges object; create multiple objects if the same fix spans several tables.
        • Keys in processChanges must use camelCase (`artifactIndex`) and follow the example schema. Allowed `type` values: `add_columns`, `modify_instructions`, `add_table`.
        • Before proposing *add_columns* compare desired name against existing names **as described in Analysis-workflow step 8**; skip the change if a near-duplicate exists.
        • Order processChanges by artifactIndex *strictly* ascending.
        • Propose modify_instructions only when the new text **materially** differs from the current value after case/whitespace **and semantic** normalisation **of visible text**, adds value/specifies something in more detail.
        • Do **not** emit more than **one** processChanges object for the same `artifactIndex`, unless one of them is an additional `add_table`.
        • If no fixes are needed, return "processChanges": [].
        • No extra text outside JSON, no triple backticks or code fencing.
        • Finish immediately after the final }} character.

        **Reminder – Traceability waiver (early artifacts)**
        Same rule as Analysis-workflow step 3: skip *only* traceability gaps for artifacts 1.1.0 → 1.1.4; other gap types remain valid.

        ### STOP-CHECK before JSON
        • rootCauses ≤ 20 • lessons_learned ≤ 20 • processChanges ≤ 5
        • Process changes are a last resort: implement only when the lesson/root cause pair cannot be implemented using the current tables/table structure, or when table-specific instructions directly contradict the lesson.
        • For every i, the locator prefix of lessons_learned[i] equals that of rootCauses[i]; **locators must be in the current phase (except global‑xx)**. Sorting must be applied to pairs jointly
        • Skip gaps whose “Related Reqs” cell is empty **and** artifactIndex starts with 1.1.0–1.1.4 **AND ensure none of those appear in rootCauses, lessons_learned, or processChanges**
        • Max **one** processChanges object per artifact unless type == add_table
        • For add_columns: abort if column already exists (case / punctuation insensitive)
        • If **no open issues in issues_text** → **no issue-based pairs**
        • After expanding multi‑artifact placements (Step 5), re‑check caps **and order/numbering**: total pairs ≤ 20; processChanges ≤ 5
        • If any rule fails → regenerate silently

        Return JSON with this structure:

        {{
          "rootCauses": [],
          "lessons_learned": [],
          "processChanges": []
        }}

        ────────────────────────  EXAMPLES  ───────────────────────
        (Templates only – never output verbatim or structure)

        ★ Combined example – few changes, many observations
        {{
          "rootCauses": [
            "global-1: REST/JSON chosen because simpler firewall",          // *DO not output this*: CRUMB → change
            "global-2: UUIDv7 IDs adopted because sortable, time-based",            // *DO not output this*: CRUMB (no change)
            "global-3: Prometheus monitoring selected across DevSecOps artifacts - improves observability", // *DO not output this*: CRUMB (no change)
            "global-4: AES-256 encryption selected because secures user data",               // *DO not output this*: CRUMB (no change)
            "global-5: Same KPI defined differently across artifacts - cross-artifact drift",
            "3.1.5: Rate-limit policy missing (Rate-Limit Policy column)",                    // *DO not output this*: ISSUE → change
            "1.1.7: Feedback loop frequency undefined (Frequency column)",                    // *DO not output this*: ISSUE (no change)
            "1.2.4: Mitigation recommendations vague"                                         // *DO not output this*: ISSUE (no change)
          ],

          "lessons_learned": [
            "global-1: Use REST/JSON for all backend and frontend APIs to simplify firewalls",
            "global-2: Adopt UUIDv7 for identifiers across services for ordering and analytics",
            "global-3: Standardise Prometheus monitoring across environments for unified metrics",
            "global-4: Keep AES-256 as default encryption for data-at-rest assets to secure user data",
            "global-5: Harmonise KPI definition and unit across artifacts 2.1.3 (SSOT) and 3.1.2",
            "3.1.5: Add rate-limit policy to every API interface",                            // *DO not output this*: **PAIR-PREFIX RULE enforced**
            "1.1.7: Specify exact feedback loop cadence per sprint",                          // *DO not output this*: **PAIR-PREFIX RULE enforced**
            "1.2.4: Make mitigations actionable with numeric targets"                         // *DO not output this*: **PAIR-PREFIX RULE enforced**
          ],

          "processChanges": [
            {{ "type": "modify_instructions",                 // *DO not output this*: linked to first CRUMB pair
              "artifactIndex": "1.1.1",
              "new_instructions": "Declare REST/JSON as mandatory API style for this module" }},
            {{ "type": "add_columns",                         // *DO not output this*: linked to first ISSUE pair
              "artifactIndex": "3.1.5",
              "columns": ["Rate-Limit Policy"] }}
          ]
        }}

        ───────────────────────────────────────────────────────────
        Example A — **no schema change needed** (most common type, use this by default)
        {{
          "rootCauses": [
            "global-1: REST/JSON chosen because simpler firewall"
          ],
          "lessons_learned": [
            "global-1: Standardise on REST/JSON project-wide because simpler firewall"
          ],
          "processChanges": []
        }}

        ───────────────────────────────────────────────────────────
        Example B — **modify_instructions only**
        {{
          "rootCauses": [
            "2.1.5: Rollback procedures undocumented for critical deployments"
          ],
          "lessons_learned": [
            "2.1.5: Document rollback steps to cut MTTR"                        // *DO not output this*: **PAIR-PREFIX RULE enforced**
          ],
          "processChanges": [
            {{ "type": "modify_instructions",
              "artifactIndex": "2.1.5",
              "new_instructions": "Add detailed rollback steps and success metric to each critical deployment" }}
          ]
        }}

        ───────────────────────────────────────────────────────────
        Example C — **add_columns** (simple extension)
        {{
          "rootCauses": [
            "3.2.6: Security metrics missing (Security Metrics column)"
          ],
          "lessons_learned": [
            "3.2.6: Link security metrics to requirements for traceability"             // *DO not output this*: **PAIR-PREFIX RULE enforced**
          ],
          "processChanges": [
            {{ "type": "add_columns",
              "artifactIndex": "3.2.6",
              "columns": ["Security Metrics"] }}
          ]
        }}

        ───────────────────────────────────────────────────────────
        Example D — **add_table** (rare; only when pipeline is fundamentally deficient)
        {{
          "rootCauses": [
            "global-1: Compliance evidence scattered across artifacts"
          ],
          "lessons_learned": [
            "global-1: Create unified Compliance Evidence Matrix to centralise audits"
          ],
          "processChanges": [
            {{ "type": "add_table",
              "artifactIndex": "4.0.9",
              "artifact_name": "Compliance Evidence Matrix",
              "artifact_type": "table",
              "artifact_columns": "Evidence_ID, Artifact, Control, Evidence_Link, Reviewer, Review_Date",
              "obligatory_rows": "All high-impact controls",
              "custom_instructions": "One row per control evidence; keep Evidence_ID unique",
              "depends_on": ["1.1.5", "3.2.4.2"] }}
          ]
        }}

        *Reminder:
        - Do not output issues by just rephrasing them/mirroring as is into issue-based root causes/lessons learned. Add value by clustering them/searching for root causes. Otherwise skip and do not emit such simply "restating" issues-based root causes - lessons learned. You must add value beyond issues; otherwise skip and do not emit.
        - Make lessons learned actionable.
        - Surface high-impact crumbs and cross-artifact issue-based root causes/lessons learned as global-xx.
        - for decision-based global pairs: cluster crumbs by exact‑match WHAT (case/space/punctuation‑normalized only); keep only major decisions, then emit as global‑xx first; In each decision pair, the WHAT and WHY must be clear, and the WHY fragment must be the shortest meaningful ASCII‑only verbatim substring from WHY. Specific decisions must propagate as separate global lessons.
        - When the same root cause spans multiple artifacts, emit it as one root cause - lessons learned pair with global-xx prefix.
        - Emit processChanges only when the lesson/root cause pair cannot be implemented using the current tables/table structure, or when table-specific instructions directly contradict the lesson.
        - Output exactly one syntactically-valid JSON object,  no comments, no trailing commas, and only printable ASCII characters. Each pair of lesson learned and corresponding root cause MUST have locator prefix.*
        No extra text outside JSON, no triple backticks or code fencing.
        """

        # ------------------------------------------------------------------
        # 7) Call the LLM & parse JSON safely
        # ------------------------------------------------------------------
        raw = self.llm_client.openai_cheap_api(prompt).strip()
        try:
            rr = json.loads(raw)
        except json.JSONDecodeError:
            rr = {"rootCauses": [], "lessons_learned": [], "processChanges": []}

        root_causes     = rr.get("rootCauses", []) or []
        lessons_learned = rr.get("lessons_learned", []) or []
        process_changes = (
            rr.get("processChanges", [])
            if isinstance(rr.get("processChanges"), list) else []
        )

        # ------------------------------------------------------------------
        # 8) Apply eligible process changes (unchanged)
        # ------------------------------------------------------------------
        for ch in process_changes:
            ctype = str(ch.get("type", "")).lower()

            if ctype in {"add_columns", "add_column"}:
                art_id = ch.get("artifactIndex") or ch.get("artifact_index")
                cols   = ch.get("columns") or ch.get("column")
                if art_id and cols:
                    cols_to_add = cols if isinstance(cols, list) else [cols]
                    self.add_columns_to_table(art_id, cols_to_add)
                    print(f"INFO: Added columns {cols_to_add} to artifact {art_id}")
                else:
                    print(f"WARNING: Invalid add_columns change: {ch}")

            elif ctype == "modify_instructions":
                art_id = ch.get("artifactIndex") or ch.get("artifact_index")
                instr  = ch.get("new_instructions") or ch.get("custom_instructions")
                if art_id and instr:
                    self.modify_artifact_instructions(art_id, instr)
                    print(f"INFO: Updated instructions for artifact {art_id}")
                else:
                    print(f"WARNING: Invalid modify_instructions change: {ch}")

            elif ctype == "add_table":
                new_id = ch.get("artifact_index") or ch.get("artifactIndex")
                if not new_id:
                    print(f"WARNING: add_table missing artifact_index: {ch}")
                    continue

                self.add_new_table(
                    row_number          = ch.get("row_number", 99),
                    artifact_index      = new_id,
                    artifact_name       = ch.get("artifact_name", "New Artifact"),
                    artifact_type       = ch.get("artifact_type", "table"),
                    artifact_columns    = ch.get("artifact_columns", ""),
                    obligatory_rows     = ch.get("obligatory_rows", ""),
                    custom_instructions = ch.get("custom_instructions", ""),
                    depends_on          = ch.get("depends_on", [])
                )

                target_phase_idx = self.phase_index_map.get(phase_name, 0)
                for dep in ch.get("depends_on", []):
                    for idx, ph in enumerate(self.sim_config["phases"]):
                        if dep in ph.get("tableList", []):
                            target_phase_idx = max(target_phase_idx, idx)
                self.sim_config["phases"][target_phase_idx]["tableList"].append(new_id)
                tgt_phase = self.sim_config["phases"][target_phase_idx]["phaseName"]
                print(f"INFO: Added new artifact '{new_id}' to phase '{tgt_phase}'")

            else:
                print(f"INFO: Ignored unsupported process change type '{ctype}'")

        # ------------------------------------------------------------------
        # 9) Persist lessons so the writer LLM can consume them
        # ------------------------------------------------------------------
        key = (macro_iter_idx, phase_name, mini_iter_idx)      # (macro, phase, mini)
        self._lessons_log = getattr(self, "_lessons_log", {})  # create store if absent
        self._lessons_log[key] = lessons_learned or []         # may be empty

        # ————————————————— DEBUG —————————————————
        print(
            f"retrospective_problem|RETRO|SAVE|key={key}"
            f"|n_saved={len(lessons_learned)}",
            file=sys.stderr
        )

        # ------------------------------------------------------------------
        # 10) Build and return a short textual summary
        # ------------------------------------------------------------------
        summary_lines = ["Root causes identified:"]
        for rc in root_causes:
            summary_lines.append(f"- {rc}")
        summary_lines.append("\nLessons learned:")
        for ll in lessons_learned:
            summary_lines.append(f"- {ll}")

        return "\n".join(summary_lines)









    @staticmethod
    def convert_dependency_json_to_text(dependency_json: dict) -> str:
        lines = []
        client_spec = dependency_json.get("clientSpec", "")
        lines.append(f"ClientSpec:\n{client_spec}\n")
        for dep in dependency_json.get("dependencies", []):
            art_idx = dep.get("artifactIndex", "unknown")
            art_name = dep.get("artifactName", "(no name)")
            lines.append(f"--- DEPENDENCY: Artifact {art_idx} ({art_name}) ---")
            columns = dep.get("columns", [])
            rows = dep.get("rows", [])
            for row in rows:
                row_text = " | ".join(str(row.get(col, "")) for col in columns)
                lines.append(row_text)
        return "\n".join(lines)

    def gather_artifact_and_global_resolved_issues(self, artifact_index):
        """
        Returns two short bullet-list strings:
          1) artifact_specific_bullets => issues that have been resolved in *this* artifact
            (even if reopened globally for a different artifact).
          2) other_artifacts_bullets   => issues globally resolved in some other artifact,
            or still globally "Resolved" if it was never fixed here.

        We consider:
          - local_resolved = (artifact_index in record["resolvedInArtifacts"])
          - globally_resolved = (record["status"] == "Resolved")

        For each gap that meets either criterion, we build a bullet with:
          "- GapID=xxx: shortDescription => recommendation"

        If none are found, we return "No resolved issues..." for each category.
        """

        artifact_specific_lines = []
        other_artifacts_lines   = []

        # We'll iterate over issue_first_seen_iteration to see which issues are resolved.
        for gap_id, record in self.issue_first_seen_iteration.items():
            if not isinstance(record, dict):
                continue

            # If the record is missing the new field, treat it as empty set
            resolved_in_arts = record.get("resolvedInArtifacts", set())

            local_resolved    = (artifact_index in resolved_in_arts)
            globally_resolved = (record.get("status") == "Resolved")

            # If it's neither locally nor globally resolved, skip it
            if not (local_resolved or globally_resolved):
                continue

            short_desc = record.get("shortDescription", "").strip()
            recommendation = record.get("recommendation", "").strip()
            bullet_str = f"- GapID={gap_id}: {short_desc} => {recommendation}"

            if local_resolved:
                # This artifact once fixed the gap (do not reintroduce here)
                artifact_specific_lines.append(bullet_str)
            else:
                # It is "Resolved" globally but not specifically here
                other_artifacts_lines.append(bullet_str)

        if artifact_specific_lines:
            artifact_specific_bullets = "\n".join(artifact_specific_lines)
        else:
            artifact_specific_bullets = "No resolved issues specific to this artifact."

        if other_artifacts_lines:
            other_artifacts_bullets = "\n".join(other_artifacts_lines)
        else:
            other_artifacts_bullets = "No resolved issues from other artifacts."

        return artifact_specific_bullets, other_artifacts_bullets



    def fetch_and_update_artifact(
        self,
        macro_iter_idx: int,
        phase_name: str,
        mini_iter_idx: int,
        table_info: Dict[str, Any],
        previous_artifact_dict: Dict[str, Any]
    ) -> Tuple[Dict[str, Any], str]:
        """
        Creates or updates an artifact (student prompt) with carefully isolated context.

        New in this version
        -------------------
        • Emits the **primary-key column(s)** for the current table  inside the LLM prompt so the model
          knows which field must stay globally unique.

        Legacy guarantees (unchanged)
        ------------------------------
        • Carries over ONLY this artifact's unresolved issues from the appropriate
          previous iteration(s).
        • Highlights any critical/high-severity issues once at the top (NFR-4).
        • Excludes issues from other artifacts in the same mini-iteration (NFR-5).
        • Respects cross-artifact routing if 'targetArtifactIndex' == this artifact
          (FR-20).
        • Prevents excessive issue details (no full history) to avoid output bloat.
        """

        artifact_index: str = table_info["Artifact_index"]
        artifact_name: str = table_info["Artifact_name"]
        previous_artifact_text: str = json.dumps(previous_artifact_dict, indent=2)

        # ---------------------------------------------------------
        # (1) Gather dependency JSON, then convert to text summary
        # ---------------------------------------------------------
        dependency_json: Dict[str, Any] = self.gather_dependencies_as_json(artifact_index)
        table_dependencies_text: str = self.convert_dependency_json_to_text(dependency_json)


        # ---------------------------------------------------------
        # (2) Retrieve lessons from the *immediately relevant* step
        # ---------------------------------------------------------
        import re  # local import – safe, idempotent

        # ── 2a. Grab every raw lesson line from the preceding mini ──
        _raw_lessons: str = (
            self.get_lessons_for_new_mini(macro_iter_idx, phase_name, mini_iter_idx)
            or ""
        )
        # ————————————————— DEBUG —————————————————
        import sys
        print(
            f"retrospective_problem|WRITER|LESSON_RAW"
            f"|macro={macro_iter_idx}|phase={phase_name}"
            f"|mini={mini_iter_idx}|art={artifact_index}"
            f"|raw_lines={len(_raw_lessons.splitlines())}",
            file=sys.stderr
        )
        # ————————————————————————————————
        # ── 2b. Build tolerant regexes ─────────────────────────────
        # ── 2b. Strict artifact-ID regex  +  global detection ─────────
        _sep  = r"\s*[^\d\s]+\s*"                       # '.', '–', '·', etc.
        parts = list(map(re.escape, artifact_index.split(".")))   # ['1','1','6']
        core  = _sep.join(parts)                        # 1<sep>1<sep>6

        # (^|non-digit) 1<sep>1<sep>6 (?! another <sep>digits) (non-digit|$)
        #  → exact dotted sequence, forbids children/cousins.
        _this_idx_re = re.compile(
            rf"(?:^|\W){core}(?!{_sep}\d+)(?:\W|$)"
        )

        # “looks like some artifact index”  (≥2 digit groups separated)
        _any_idx_re  = re.compile(r"\d+(?:\s*[^\d\s]+\s*\d+)+")

        # ── 2c. Keep either (i) this artifact’s advice  or  (ii) global ──
        _selected: list[str] = []
        for _ln in _raw_lessons.splitlines():
            _strip = _ln.strip()
            if not _strip:                     # blank line → skip
                continue

            # (i) exact artifact match
            if _this_idx_re.search(_strip):
                _selected.append(_ln)
                continue

            # (ii) global line – contains *no* artifact ID at all
            if not _any_idx_re.search(_strip):
                _selected.append(_ln)

        # ————————————————— DEBUG —————————————————
        print(
            f"retrospective_problem|WRITER|LESSON_SELECTED"
            f"|macro={macro_iter_idx}|phase={phase_name}"
            f"|mini={mini_iter_idx}|art={artifact_index}"
            f"|sel_lines={len(_selected)}",
            file=sys.stderr
        )
        # ————————————————————————————————

        previous_lessons_text: str = "\n".join(_selected) if _selected else "None"

        # ---------------------------------------------------------
        # (3) Identify unresolved issues from the prior iteration
        # ---------------------------------------------------------
        phases_list: List[str] = [p["phaseName"] for p in self.sim_config.get("phases", [])]
        phase_idx: int = phases_list.index(phase_name) if phase_name in phases_list else -1
        prev_issues: List[Dict[str, Any]] = []

        if mini_iter_idx > 1:
            # (A) Previous mini-iteration in the same phase, same artifact
            prev_issues = (
                self.feedback_storage
                .get(macro_iter_idx, {})
                .get(phase_name, {})
                .get(mini_iter_idx - 1, {})
                .get(artifact_index, [])
            )
        else:
            # mini_iter_idx == 1: pull open issues from previous phase or macro
            if phase_idx > 0:
                prev_phase_name: str = phases_list[phase_idx - 1]
                prev_phase_info: Dict[str, Any] = next(
                    (ph for ph in self.sim_config["phases"] if ph["phaseName"] == prev_phase_name),
                    None
                )
                if prev_phase_info:
                    last_mini_prev_phase: int = prev_phase_info.get("miniIterations", 1)
                    prev_phase_issues: List[Dict[str, Any]] = (
                        self.feedback_storage
                        .get(macro_iter_idx, {})
                        .get(prev_phase_name, {})
                        .get(last_mini_prev_phase, {})
                        .get(artifact_index, [])
                    )
                    for iss in prev_phase_issues:
                        if iss.get("knownIssue") in {"NewIssue", "KnownIssue", "InProgress"} and \
                          not any(existing.get("gapID") == iss.get("gapID") for existing in prev_issues):
                            prev_issues.append(iss)

            if macro_iter_idx > 1:
                # (C) Cross-macro carry-over: unresolved from final iteration of previous macro
                prev_macro_idx: int = macro_iter_idx - 1
                artifact_phase_idx_prev = next(
                    (idx for idx, ph in enumerate(self.sim_config["phases"])
                    if artifact_index in ph.get("tableList", [])),
                    None
                )
                if artifact_phase_idx_prev is not None:
                    artifact_phase_name_prev: str = phases_list[artifact_phase_idx_prev]
                    artifact_phase_info_prev: Dict[str, Any] = self.sim_config["phases"][artifact_phase_idx_prev]
                    last_mini_prev_phase: int = artifact_phase_info_prev.get("miniIterations", 1)
                    prev_art_issues_prev_macro: List[Dict[str, Any]] = (
                        self.feedback_storage
                        .get(prev_macro_idx, {})
                        .get(artifact_phase_name_prev, {})
                        .get(last_mini_prev_phase, {})
                        .get(artifact_index, [])
                    )
                    for iss in prev_art_issues_prev_macro:
                        if iss.get("knownIssue") in {"NewIssue", "KnownIssue", "InProgress"} and \
                          not any(existing.get("gapID") == iss.get("gapID") for existing in prev_issues):
                            prev_issues.append(iss)

        # (D) Exclude issues from other artifacts; keep cross-artifact ones that target us
        prev_issues = [
            iss for iss in prev_issues
            if (not iss.get("targetArtifactIndex") or
                iss["targetArtifactIndex"] == artifact_index)    # routed to me
              and artifact_index in (iss.get("affectedArtifacts") or [])
        ]

        unresolved_prev_issues: List[Dict[str, Any]] = [
            iss for iss in prev_issues if iss.get("knownIssue") in {"NewIssue", "KnownIssue", "InProgress"}
        ]

        # ---------------------------------------------------------
        # (4) Prepare sample data snippet if present
        # ---------------------------------------------------------
        sample_data_snippet: str = json.dumps(table_info.get("Sample Data Rows", []), indent=2)

        # ---------------------------------------------------------
        # (5) Highlight critical/high-severity issues once
        # ---------------------------------------------------------
        highlighted_msg: str = self.highlight_critical_issues(unresolved_prev_issues)
        if highlighted_msg.startswith("IMPORTANT"):
            unresolved_prev_issues = [
                iss for iss in unresolved_prev_issues
                if iss.get("impact", "").lower() not in {"critical", "high"}
            ]

        # ---------------------------------------------------------
        # (6) Trim the unresolved list to avoid huge output
        # ---------------------------------------------------------
        trimmed_unresolved: List[Dict[str, Any]] = [
            {
                "gapID": iss["gapID"],
                "gapType": iss.get("gapType", "Other"),
                "shortDescription": iss.get("shortDescription", ""),
                "impact": iss.get("impact", "Medium"),
                "knownIssue": iss.get("knownIssue", "NewIssue"),
                "recommendation": iss.get("recommendation", "")
            }
            for iss in unresolved_prev_issues
        ]
        unresolved_json_str: str = json.dumps(trimmed_unresolved, indent=2)


        # ---------------------------------------------------------
        # (7) Build the LLM prompt for artifact creation/update
        # ---------------------------------------------------------
        columns_list: List[str] = [col.strip() for col in table_info["Artifact_columns"].split(",")]

        # ►► NEW: primary-key bullet ◄◄
        pk_raw = getattr(self, "artifact_key_map", {}).get(artifact_index) \
                 or self.sim_config.get("artifact_key_map", {}).get(artifact_index)

        if isinstance(pk_raw, (list, tuple, set)):
            primary_key_col = ", ".join(sorted(str(col) for col in pk_raw))
        else:
            primary_key_col = str(pk_raw or "")


        artifact_specific_bullets, other_artifacts_bullets = \
            self.gather_artifact_and_global_resolved_issues(artifact_index)

        table_prompt: str = f"""
(<start of instruction block:>)
# Agent Reminders
 • Produce exactly one compliant JSON artifact in this turn.
 • If information is missing and can not be safely infered, log the gap in metadata instead of guessing.
 • Think step-by-step privately in your scratch-pad before filling rows.
 • For any **metric-like field**, apply a **two-tier policy**:
   – **Decision metrics**: **prefer** a quantitative KPI (statistic + numeric threshold + unit + time window); add population/source when available.
   – **Vanity/trend metrics**: provide a clear, quantitative descriptor; thresholds are **optional** unless explicitly mandated.

# Role: you are a *software engineer* and *implementation author* of *current artifact*, who loves turning fuzzy ideas into rock-solid, testable designs.
 • We are currently at iteration (macro={macro_iter_idx}, phase={phase_name}, mini={mini_iter_idx}).

# Objective: to create or recreate *current artifact* {artifact_index} ({artifact_name}) from client specifications, previous artifact version, dependencies, lessons learned and open issues:
 1 Analyse scope → 2 Activate domain context → 3 Isolate spec/dependency facts → 4 Detect blind spots/ambiguities and infer safe defaults via silent scratch-pad → 5 Organise data into the table’s exact columns → 6 Deduplicate while closing CRITICAL/HIGH gaps and blocking regressions → 7 Map every necessary entity to primary-keyed rows at high granularity → 8 Integrate all decisions + metadata → 9 Output the compliant JSON artifact.

# ENGINEERING MINDSET – apply before typing any row
 • Systems-thinking lens – see artifact as part of a larger architecture.
 • Spec-wins but Challenge Gaps – uphold client spec, flag omissions.
 • ClientSpec+Special‑instructions supremacy & tie‑breakers – treat the original client specifications **and Special instructions** as ground truth; on ambiguity or conflicts with dependencies/lessons/issues, consult them first; if still unclear, prefer non‑speculative defaults or log an `unresolvedNotes` gap (do not invent new requirements).
 • Proactive Ambiguity Resolution – infer safe, industry‑standard defaults **when in scope** and data is missing.
 • Data‑Driven & Measurable – favour quantifiable targets, verifiable metrics **when in scope**.
 • Risk-First Attitude – default to least-privilege, secure, fault-tolerant choices.
 • DRY + KISS – avoid duplication; keep every cell succinct and specific.
 • Quality Baselines – embed CIA, SOLID‐S, and performance envelopes where relevant, via concrete system properties; avoid checklist phrasing.
 • Trace‑When‑In‑Scope – add trace links where a trace column exists **and is in scope** for the phase/artifact **and carry referenced constants**.
 • Continuous-Improvement – fold lessons learned into current design without regressions.

# ANTI‑OVERSPECIFICATION & ANTI‑LOCK‑IN (global)
 • Default to capability‑based nouns (e.g., “OIDC IdP”, “S3‑compatible object storage”, “SQL RDBMS”).
 • Do not name vendors, paid SKUs, or single‑cloud managed services before an ADR explicitly approves them,
   unless they appear in original client specifications (as the only option) or in a Critical/High bullet.
 • Prefer portable standards (e.g., OIDC, OAuth 2.1, OpenMetrics, S3 API, SQL RDBMS) when a choice is needed.
 • If Sample data rows mention vendors, treat them as examples; replace with capability nouns.
 • Overspecification = naming a vendor/product/non‑portable API where the spec doesn’t require it and a
   standards‑based capability noun exists.
 • Vendor names and tech‑locks are allowed only when the client specification explicitly mandates a single vendor/technology (not merely as an example). In that case, use a capability noun followed by the lock in parentheses, e.g., "S3‑compatible object storage (required: AWS S3)". Define ADR on first use: Architecture Decision Record (ADR).
 • Decision timing: postpone tool/vendor picks to backlog phase (current phase is {phase_name}).

# #Cell fill policy
Never leave a cell blank. If a column truly does not apply to this row or you cannot safely supply a concrete value, write exactly one of these tokens (case sensitive):
•	N/A — column truly does not apply to this row
•	Not required — column is applicable in general, but the spec makes it optional for this row
•	Insufficient data — spec/dependencies don’t give enough to set a value safely
•	TBD — a required value is known to be needed but not yet decided
Semantics:
N/A = not relevant • Not required = optional here • Insufficient data = unknown due to missing inputs • TBD = known required, undecided

## **MANDATORY-FIX RULE**
*If the {{highlighted_msg}} block contains any **CRITICAL** or **HIGH**-severity bullets* you **must** for **each** bullet:
1. **Implement** the recommended action **or** leave it unresolved **only** when blocked, in which case add a key-value entry under `metadata.unresolvedNotes` exactly as specified in Step B.
2. Record the bullet in the **Progress Tracker** with the same `GapID` and mark status **Resolved**, **Partially**, or **Unresolved** as appropriate.
 (This rule has equal precedence with “Spec-wins”; obey both even if they conflict with other guidance.) Update row content, don’t add commentary
 • If a CRITICAL/HIGH bullet clearly belongs to **another artifact**, do **not** duplicate that content here.  Instead, leave the gap *Unresolved* and add an entry under `metadata.unresolvedNotes` using the **cross-artifact scope** reason pattern described in Step B.
 • If a CRITICAL/HIGH fix conflicts with the client spec:
    – Do **not** implement the fix.
    – Log the gap in `metadata.unresolvedNotes` with reason "spec conflict".

## ⚙️ DECISION-&-INFO-CRUMB RULE (global)
*INTERNAL — never emit the scratch-pad*

When you must invent **any numeric threshold, enumerated option or tooling/architecture choice**:
 1. Draft ≥ 2 candidate rows with **Perf / Cost / Maintainability / Security** scores 1-5.
 2. Pick the winner (highest Total  →  highest Security  →  lowest Cost).
 3. DO NOT print the draft table.
 4. Fill the official artifact only with the winning figure/option.
 5. **Also** detect passive facts that (a) alter behaviour of ≥ 1 earlier artifact in the next macro/phase **and** (b) are absent from the upstream spec blocks — see the 13-item trigger list below.
 6. For every decision *or* info-trigger, append **1-5 crumbs** in `metadata.notesFromLLM`, separated by `" | "`.
  • Format: `# DEC-<nn>: <WHAT> — <WHY>`  (no trailing pipes)
  • `<WHAT>`  = reusable noun phrase **≤ 6 words** (*do **not** add artifact IDs*).
  • `<WHY>`   = one short motive (≤ 8 words) starting with a verb.
  • Max 65 characters per crumb.
  • Use exactly one em-dash (—); no trailing pipes.
  • Number <nn> chronologically per artifact (01, 02 …); restart at each call.
  • **Uniqueness guard**: emit a crumb **only once per iteration** — if an identical `<WHAT>` already exists in dependencies **or previous artifact version**, **skip it and do not increment the counter**.
  • Always include at least one crumb; if none qualify use `# DEC-00: no cross-artifact impact — FYI`.
  • Example: `# DEC-01: REST/JSON chosen — simpler firewall | # DEC-02: UUIDv7 identifiers — sortable, time-based`
  • The **last crumb must not end with `|`**.

## INFO-CRUMB TRIGGERS (emit when any row causes one):
  1 Contract shape changed   2 Schema-migration pattern   3 Trace header/ID
  4 Identifier strategy      5 Crypto/Compliance rule     6 Perf envelope
  7 Ordering/Idempotency     8 Tool/runtime pin           9 Deprecation clock
 10 Business constant        11 Data-quality rule        12 Shard/Partition key
 13 Log/Audit format
### INFO-CRUMB REMINDER
 • Always emit ≥ 1 and ≤ 5 crumbs.
 • Never duplicate an existing crumb from another artifact in the same macro-iteration.
 • Missing crumb for a fired trigger ⇒ High-severity gap.

##⚠️  **Quality Gate Notice**
 • After you submit your JSON, a *senior reviewer LLM* will score it with the rubric below.
 • If your score is < 7 / 10, you will be asked to redo the artifact.
 • Therefore, meet every rubric point **on the first try**.

### EVALUATION RUBRIC *(do **not** output this rubric)*
 • 10 / 10  All Critical + High CLOSED **in scope**  + ≥ 80 % of Med/Low CLOSED **in scope**
 •  7 / 10  All Critical CLOSED, some High remain
 • ≤ 4 / 10  Any Critical issue still open or re-introduced
(The grader is strict and reward-based; aim for 10/10.)


## PROGRESS TRACKER (fill before Step A & update before JSON)
| GapID | Status (Resolved/Partially/Unresolved) | One-line Fix |
|-------|----------------------------------------|--------------|
Fill the table above **before you start step A** and update it again just before sending the JSON.
**Internal use only – never include the table in your final answer.**
(Example row – delete the whole table before sending JSON):
| 7f3942 | Resolved | Add timestamp |
(Delete the entire table before sending your JSON ─ do **not** leave any sample row.)
**Tracker enforcement — complete it only when CRITICAL/HIGH bullets exist. Remove the whole table before emitting JSON.**


# EXECUTION STEPS  (follow A → I)
 A  **Analyse & Align**
   1. Clarify purpose & audience – note the table’s intent in your private scratch-pad.
   2. Collect source knowledge – pull specs, dependencies, prior artifacts, data samples; discard off-scope info.
   3. Model the domain – list entities → attributes and choose correct row granularity.
   4. Design column set & primary key – one unique fact per column; PK minimal and stable.
   5. Apply **Spec-wins** (treat “optional” spec bullets as *must* but mark them *(optional)* in rows).
 B  Resolve all unresolved issues listed above **(any severity)** including every CRITICAL/HIGH bullet per the MANDATORY-FIX RULE (skip if “None”); aim for a 10/10 rubric score and update the Progress Tracker.
   • **ONLY** if a gap is truly blocked, leave it *Unresolved* and add an entry in `metadata.unresolvedNotes` using: `"<gapID>": "<≤120-char reason this gap cannot be fixed right now>"`
   • If gap is not applicable to current artifact or false (reviewer mistake), consider it blocked and do not resolve it.
   • Do **not** include the `GapID=` prefix.
   • List **only** gaps that are still blocked. If none are blocked, omit the `unresolvedNotes` key entirely.
     Acceptable reason patterns (choose **one** per gap; list not exhaustive):
       – conflicting instructions inside this prompt (e.g. spec A demands anonymity; spec B demands user IDs)
       – spec / dependency gap (e.g. encryption algorithm or success metric not supplied)
       – upstream artifact not generated yet in this macro/phase (e.g. dependency table still missing)
       – cross-artifact scope (bullet targets a different artifact that this update cannot fix)
   • **If a mandatory foreign-key value cannot be resolved from declared dependencies,** omit the entire row **and** add  `"<row-locator>": "missing FK <column> – upstream row absent"` to `metadata.unresolvedNotes`.
 C  Prevent re-opening globally resolved issues (skip if “None”).
 D  Apply relevant lessons learned (**owned by this artifact**; skip if “None”, not applicable, or false).
 E  Sync with updated dependencies (respecting the Spec-wins rule; skip if “None”).
 F  **Deduplicate & Normalise**
   • Merge or remove duplicate / obsolete rows; keep primary-key uniqueness.
   • Normalise names & units – apply canonical vocab **consistent with previous version of artifact, dependencies, client specifications**, SI/IEC units, tidy enums, merge synonyms.
   • Run internal checks – PK uniqueness, no blank mandatory cells, logical bounds (start ≤ end, % ≤ 100).
 G  **Requirement Coverage & Gap-Filling**
   Ensure every “must / shall / at least” requirement maps to one row or column; add **only** what is missing. **Do not add rows solely as examples.**
   • If a spec bullet uses *should / may / could / optional*, add a row **only when this artifact is the natural owner** of that item (e.g. UI spec → UI table).
     – If the requirement clearly belongs to another artifact, skip it here and rely on that artifact to cover it.
     – If you add the row but lack concrete figures, run the **DECISION-SCRATCHPAD** to select a sensible default. Use `[PLACEHOLDER-AUTO]` only when no safe, non-speculative default exists.
   • When the spec mandates a capability yet omits **specific values or choices** (e.g. “host on a free provider”, “provide licence attribution”):
       1. First attempt to decide a reasonable industry default via the scratch-pad (e.g. Vercel Free, MIT-style licence-attribution workflow).
       2. If even the scratch-pad cannot yield a defensible choice, add the row with `[PLACEHOLDER-AUTO]` *and* an inline comment explaining why a placeholder was unavoidable.
   • If you later decide on a value, replace every `[PLACEHOLDER-AUTO]` cell in that row with the chosen value.
   • For every row that contains a **“Related Reqs”, “Trace”, “Req ID”** or similar column, populate that cell with **only** a Requirement-ID (`FR-`, `NFR-`, `US-`, etc.).
     – If no suitable ID exists after diligent search, insert `[PLACEHOLDER-AUTO]` and comment “awaiting upstream requirement”.
H  Sort rows ascending by the primary-key column/columns unless *Special instructions* say otherwise.
I  **Quality-assure & Output**
   1. Quality-assure & iterate – run the Quick Self-Check; confirm no banned meta words, row count ≤ 200, etc.
   2. Output the JSON schema shown below.

# STYLE & SIZE RULES
  • Telegraphic style — imperative or noun phrases; each **text** field ≤ 120 chars incl. spaces. (If Special instructions demand prose, this overrides the limit **only** for the named columns.)
  • Do **not** reuse sample nouns/IDs unless they also appear in the client specification.
  • Ignore any sample columns not present in the column list.
  • Maximum rows: **200**.
  • "notesFromLLM" (metadata) is **required**; 1-5 crumbs, total ≤ 200 chars (**reviewer enforces**).
  • No full sentences unless Special instructions require them.
  • 💡 **Domain-only rule** – Every **row cell** must describe an *observable product/property* (UI element, API call, metric, control, etc.).
     ✗ Never include in table meta‑process wording such as “apply lessons”, “update dependencies”, “resolve issue”, “prevent re‑emergence”, “align with spec”, “checklist:”, etc..
     ✗ Never copy or paraphrase text from MANDATORY-FIX bullets.
     ✓ Close a gap by **editing the concrete domain data**, not by narrating the fix.
  • This rule also applies to *any* columns: describe what the **system** does, not what *you, the engineer* will do.
  • If you add a “# chosen:… ” breadcrumb, place it **only** in metadata.notesFromLLM (never as free-text after or before JSON).
  • If any trigger (see INFO‑CRUMB list) fired, verify the matching crumb is present in `metadata.notesFromLLM` **after composing rows**.
  • Use strict SI (kB, ms, C) and IEC binary prefixes (KiB, MiB) for sizes; never imperial.
  • Timestamps: ISO-8601 UTC (`YYYY-MM-DDThh:mm:ssZ`). Durations: ISO-8601 (`PT3H15M`, `P7D`).
  • Numbers: period as decimal separator, no thousands separator; ≤ 4 decimal places unless higher precision is required.
  • Safe ASCII symbols only.
  • **Row‑type invariant** - All rows must represent the **same entity type** for this artifact; keep it consistent across every row.
(<end of instruction block>)

(<start of project data block:>)
# Project-specific data:

## Key project-specific data
  • Artifact number: {table_info["row_number"]}
  • Artifact index:  {artifact_index}
  • Artifact name:   {artifact_name}
  • Artifact type:   {table_info["Artifact_type"]}
  • Columns (exact order): {table_info["Artifact_columns"]}
  • Column‑sequence expansion (hard rule): If the column list shows a repeat pattern like
    “Action 1, Action 2, ..., Action n”, treat it as **expandable**, implement as many as needed.
  • Primary-key column(s): {primary_key_col}  → values **must be unique**; create new IDs if collisions occur. If **Special instructions** mentions primary key with multiple columns, **Special instructions** win.
  • Obligatory rows: {table_info["Obligatory_rows"]}
  • Sample data rows for another project (replace any 'TBD' with meaningful data if you reuse):
    {sample_data_snippet}

## **Special instructions**: {table_info["custom_instructions"] or "None"}

## LESSONS LEARNED/major decisions from previous iterations (implement each if correct and applicable)
{previous_lessons_text or "None"}

## Critical/High-severity issues (implement each recommendation if correct and applicable)
{highlighted_msg or "None"}

## Artifact-specific UNRESOLVED MED / LOW issues (implement each recommendation if correct and applicable)
{unresolved_json_str or "None"}

## Artifact-specific RESOLVED ISSUES (DO NOT re-introduce)
{artifact_specific_bullets or "None"}

## RESOLVED ISSUES in another artifacts (avoid re-opening)
{other_artifacts_bullets or "None"}

## PREVIOUS ARTIFACT VERSION (build on this; if “None”, create from scratch)
{previous_artifact_text or "None"}

## DEPENDENCIES (reflect any required updates in the new artifact)
{json.dumps(dependency_json, indent=2) if dependency_json else "None"}
(<end of project data block>)

(<start of additional instructions block:>)
# QUICK SELF-CHECK BEFORE JSON
  • Internal consistency – ensure no two rows/cells contradict each other and every identifier used in one place resolves unambiguously elsewhere in this artifact.
  • Column‑set guard – whenever a column belongs to a mandatory pair/triplet (e.g. ID ↔ Description ↔ Related Reqs), make sure **all** partner columns are non‑empty **unless Special instructions allow blank** (use `[PLACEHOLDER-AUTO]` only when truly unknown).
  • Sanity scan – reject impossible values (negative latency, success > 100 %, mutually exclusive limits, dates before 1970-01-01 or far beyond project horizon, etc.).
  • Identifier sanity – verify every `FR-* / NFR-* / US-*` value follows the correct pattern **and** references an existing upstream requirement **and** uses correct identifier from upstream requirement for full traceability.
  • Row-count cap – ensure total rows **≤ 200**.
  • Verify every cell in a column whose header contains “Metric”/“Metrics” is quantitative; otherwise omit the row and add an unresolvedNote.

# ASSERT all columns present, PKs unique, no blank mandatory cells, all rows are populated (unless>200).

        ─────────────  JSON OUTPUT SPEC  ─────────────
        Return **exactly one** valid JSON object of this form **and nothing else** (do **not** include the rubric or tracker):

        {{
          "artifactIndex": "{artifact_index}",
          "artifactName": "{artifact_name}",
          "columns": {json.dumps(columns_list)},
          "rows": [
            {{
              "<columnName>": "<value>"
            }}
          ],
          "metadata": {{
            "notesFromLLM": ""
            /* omit the line below entirely when no gaps remain blocked */
            "unresolvedNotes": {{}}
          }}
        }}

        // Each key in the object inside "rows" **must** be one of the column names listed above.
        // Add the "unresolvedNotes" property **only** when at least one gap remains blocked.
        // Example for unresolvedNotes entry:
        //   "unresolvedNotes": {{ "7f3942": "Spec conflict: anonymity vs user IDs" }}

        // Simplified Example (delete in real run)
        {{
          "artifactIndex": "12",
          "artifactName": "API-Spec",
          "columns": ["id","verb","path","successCode"],
          "rows": [
            {{ "id":"END-01", "verb":"GET", "path":"/health", "successCode":"200" }}
          ],
          "metadata": {{ "notesFromLLM": " DEC-01: XXX chosen — to comply with... | # DEC-02: YYY identifiers — sortable and time-based" }}
        }}

# Before sending JSON, confirm:
 • Every client-specification bullet / numbered rule maps to at least one row/column.
 • Every CRITICAL/HIGH bullet (if any) is either implemented or logged in `metadata.unresolvedNotes`.
 • If correct and applicable, all open issues and lessons learned must be implemented.
 • No duplicate or obsolete rows remain; PKs are unique; row count ≤ 200.
 • Run a self-check: replace any banned meta words (“apply”, “update deps”, “resolve issue”, “align with spec”, etc.) found in **rows** with concrete domain content.
 • If a column name contains “Related” or “Trace”, its value must be **non-empty** whenever a CRITICAL/HIGH bullet demands trace links; otherwise treat the gap as Unresolved.
 • For **decision** metrics, verify presence of statistic, threshold, unit, and window; add population/source when available.
 • For **vanity/trend** metrics, a quantitative descriptor is sufficient unless the spec mandates a threshold.

 • `metadata.notesFromLLM` must hold 1-5 crumbs (each ≤ 65 chars, total ≤ 200 chars) recording new decisions/info-triggers.

# Objective reminder: to create or recreate *current artifact* {artifact_index} ({artifact_name}) from client specifications, dependencies, lessons and open issues:
 1 Analyse scope → 2 Activate domain context → 3 Isolate spec/dependency facts → 4 Detect blind spots/ambiguities and infer safe defaults via silent scratch-pad → 5 Organise data into the table’s exact columns → 6 Deduplicate while closing CRITICAL/HIGH gaps (if corrrect and applicable) and blocking regressions → 7 Map every necessary entity to primary-keyed rows at high granularity → 8 Integrate all decisions + metadata → 9 Output the compliant JSON artifact.

# **Final Check Reminder** – The senior reviewer will re-run the rubric. If *any* Critical/High gap remains open, or < 80 % of Med/Low closed (while being correct and applicable), you will be required to redo this iteration.

# No extra text outside JSON, no triple backticks or code fencing.

# Stop after outputting the JSON object and nothing else.
        """


        # ---------------------------------------------------------
        # (8) Call the LLM, parse the JSON
        # ---------------------------------------------------------
        parsed_artifact: Dict[str, Any] = self.llm_client.get_json_artifact_with_retries(table_prompt)
        if not isinstance(parsed_artifact, dict) or "columns" not in parsed_artifact or "rows" not in parsed_artifact:
            parsed_artifact = {
                "artifactIndex": artifact_index,
                "artifactName": artifact_name,
                "columns": [],
                "rows": [],
                "metadata": {
                    "notesFromLLM": "ERROR: Invalid or truncated JSON returned from LLM."
                }
            }

        # ---------------------------------------------------------
        # (9) Persist the new version
        # ---------------------------------------------------------
        (self.artifact_versions
            .setdefault(macro_iter_idx, {})
            .setdefault(phase_name, {})
            .setdefault(mini_iter_idx, {}))[artifact_index] = parsed_artifact

        # Return the new artifact and a human-readable dependency summary
        return parsed_artifact, table_dependencies_text





# =========================
# D) Top-level Execution
# =========================
def orchestrate_process() -> None:
    # 1 ── Ask for all required files in a single dialog
    uploaded = files.upload()                    # {filename: bytes}

    # 2 ── Enforce ONE non‑empty specification file (.txt or .docx)
    spec_files = [f for f in uploaded if f.lower().endswith(('.txt', '.docx'))]
    if len(spec_files) != 1:
        raise ValueError(
            "Upload exactly one specification file with extension .txt or .docx."
        )
    spec_file = spec_files[0]

    if spec_file.lower().endswith(".txt"):
        with open(spec_file, "r", encoding="utf-8") as sf:
            spec_text = sf.read().strip()
    else:                                         # .docx
        try:
            from docx import Document             # only import if needed
        except ImportError as e:
            raise ImportError(
                "python‑docx must be installed to read .docx specification files."
            ) from e
        doc = Document(spec_file)
        # keep blank lines between paragraphs to preserve headings / spacing
        spec_text = "\n\n".join(p.text for p in doc.paragraphs).strip()

    if not spec_text:
        raise ValueError(f"The specification file '{spec_file}' is empty.")

    # Make the text globally visible to DevOpsSimulation.__init__()
    builtins.CLIENT_SPEC = spec_text

    # 3 ── Load mandatory artifact data (same behaviour as original code)
    with open("artifact_data.json", "r", encoding="utf-8") as f:
        artifact_data = json.load(f)

    # 4 ── Load optional simulation configuration
    sim_config = {
        "backwardCompatibilityMode": True,
        "macroIterations": 1,
        "phases": []
    }
    if "simulation_config.json" in uploaded:
        with open("simulation_config.json", "r", encoding="utf-8") as cf:
            sim_config = json.load(cf)

    # 5 ── Run the simulation
    sim = DevOpsSimulation(artifact_data=artifact_data, sim_config=sim_config)
    sim.run_simulation()

    # 6 ── Offer the usual output files for download
    for fname in [
        "iteration_metrics.csv",
        "iteration_summary_metrics.csv",
        "mini_iteration_summary_metrics.csv",
        "issue_lifecycle.csv",
        "output_multi_iter.docx",
        "teacher_review_output_multi_iter.docx",
    ]:
        files.download(fname)
ensure_nltk_resources()
# Execute
orchestrate_process()